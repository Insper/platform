{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#plataformas-microsservicos-e-apis","title":"Plataformas, Microsservi\u00e7os e APIs","text":"<ul> <li> <p>2026.1</p> </li> <li> <p></p> <p>2025.2</p> </li> <li> <p></p> <p>2025.1</p> </li> <li> <p></p> <p>2024.1</p> </li> </ul> Info <p>Carga Hor\u00e1ria: 80</p> <p>Semestre: 5\u00ba per\u00edodo</p>"},{"location":"#ementa","title":"Ementa","text":"<p>Conceitos de Aplica\u00e7\u00f5es em Mon\u00f3l\u00edto e Microservi\u00e7os; Conteineriza\u00e7\u00e3o; Padr\u00f5es de Constru\u00e7\u00e3o de Softwares (Design Patterns); Monitoramento e Rastreabilidade de Aplica\u00e7\u00f5es; Seguran\u00e7a (autentica\u00e7\u00e3o e autoriza\u00e7\u00e3o); Mensageria; Dados Distribu\u00eddos; Orquestra\u00e7\u00e3o de computa\u00e7\u00e3o em nuvem, sistemas de gerenciamento, monitoramento e configura\u00e7\u00e3o de recursos virtualizados; Integra\u00e7\u00e3o entre Desenvolvimento e Opera\u00e7\u00e3o; Utiliza\u00e7\u00e3o de Plataformas em Nuvem para Produ\u00e7\u00e3o (Cloud Computing); Aspectos de automa\u00e7\u00e3o de gest\u00e3o de sistema em cloud \u2013 DevOps. Serverless computing \u2013 FaaS - function as a service; Utiliza\u00e7\u00e3o da Plataforma como Produto para Neg\u00f3cios: Infraestrutura como Servi\u00e7o (IaaS), Plataforma como Servi\u00e7o (PaaS) e Software como Servi\u00e7o (SaaS). Gest\u00e3o de n\u00edveis de servi\u00e7o (SLA - Service Level Agreement). Custos de projeto e de opera\u00e7\u00e3o de sistemas em cloud.</p>"},{"location":"#objetivos","title":"Objetivos","text":"<p>Ao final da disciplina o aluno ser\u00e1 capaz de:</p> <ol> <li>Tomar decis\u00f5es a respeito da escolha de estrat\u00e9gias de arquiteturas para o emprego de problemas computacionais;</li> <li>Implementar e interconectar aplica\u00e7\u00f5es computacionais para a constru\u00e7\u00e3o de plataformas de alto desempenho: escalabilidade por meio do uso de t\u00e9cnicas de computa\u00e7\u00e3o em nuvem;</li> <li>Administrar um sistema de gerenciamento de nuvem, provisionando a infraestrutura necess\u00e1ria como um servi\u00e7o;</li> <li>Construir, com o aux\u00edlio de frameworks, solu\u00e7\u00f5es de plataformas completas e integradas de forma profissional;</li> <li>Arquitetar e implementar linhas de produ\u00e7\u00f5es de softwares robustos (CI/CD);</li> <li>Analisar, projetar e especificar uma solu\u00e7\u00e3o de computa\u00e7\u00e3o em nuvem mista baseada em hardware, software e redes para atender aos requisitos de determinado pacto de n\u00edvel de servi\u00e7o (SLA);</li> <li>Planejar e analisar o uso de plataformas empresariais como subs\u00eddio para cria\u00e7\u00e3o de novos neg\u00f3cios (PaaS).</li> </ol>"},{"location":"#conteudo-programatico","title":"Conte\u00fado Program\u00e1tico","text":"<ol> <li>Conceitos de Arquitetura e Microsservi\u00e7os;</li> <li>Microsservi\u00e7os com Interface API - RESTful;</li> <li>Introdu\u00e7\u00e3o a Cont\u00eaineres;</li> <li>Introdu\u00e7\u00e3o e Implementa\u00e7\u00e3o de Design Patterns;</li> <li>Apresenta\u00e7\u00e3o de Design Patterns mais Complexos: Seguran\u00e7a, Mensageria, Cache, etc;</li> <li>Fundamentos de Computa\u00e7\u00e3o em Nuvem.</li> <li>Orquestra\u00e7\u00e3o, Implementa\u00e7\u00e3o e Monitoramento de Ambientes Virtualizados e Distribu\u00eddos;</li> <li>Infraestrutura como um Servi\u00e7o.</li> <li>Redes Definidas por Software;</li> <li>Software como um Servi\u00e7o;</li> <li>Gest\u00e3o de N\u00edveis de Servi\u00e7o.</li> </ol>"},{"location":"#bibliografia-basica","title":"Bibliografia B\u00e1sica","text":"<p>Livros:</p> <ol> <li> <p>ROMAN, Ed; AMBLER, Scott W.; JEWELL, Tyler. Dominando Enterprise Javabeans. Porto Alegre: Bookman, 2004. E-book. ISBN 9788577804061. Dispon\u00edvel em: https://integrada.minhabiblioteca.com.br/#/books/9788577804061. Acesso em: 30 de maio de 2023.</p> </li> <li> <p>ALVES, William Pereira. Java para Web - Desenvolvimento de Aplica\u00e7\u00f5es. S\u00e3o Paulo: \u00c9rica, 2015. E-book. ISBN 9788536519357. Dispon\u00edvel em: https://integrada.minhabiblioteca.com.br/#/books/9788536519357. Acesso em: 30 de maio de 2023.</p> </li> <li> <p>FREEMAN, Emily. DevOps Para Leigos. Rio de Janeiro: Editora Alta Books, 2021. E-book. ISBN 9788550816661. Dispon\u00edvel em: https://integrada.minhabiblioteca.com.br/#/books/9788550816661. Acesso em: 30 de maio de 2023.</p> </li> </ol>"},{"location":"#bibliografia-complementar","title":"Bibliografia Complementar","text":"<p>Livros:</p> <ol> <li> <p>XU, A., System Design Interview - An insider's guide, 1\u00aa ed., Independently Published, 2020.</p> </li> <li> <p>MARTIN, R. C., Arquitetura Limpa: o guia do artes\u00e3o para estrutura e design de software, 1\u00aa ed., Alta Books, 2018.</p> </li> <li> <p>PARKER, G. G.; VAN ALSTYNE, M. W.; CHOUDARY, S. P., Plataforma: a revolu\u00e7\u00e3o da estrat\u00e9gia, 1\u00aa ed., Alta Books, 2018.</p> </li> <li> <p>SEHGAL, N. K.; BHATT, P. C. P.; ACKEN J. M., Cloud Computing with Security and Scalability.: Concepts and Practices, 3\u00aa ed., Springer, 2023.</p> </li> <li> <p>KRIEF, M., Learning DevOps: A comprehensive guide to accelerating DevOps culture adoption with Terraform, Azure DevOps, Kubernetes, and Jenkins, 2\u00aa ed., Packt Publishing, 2022.</p> </li> <li> <p>GAMMA, E.; HELM, R.; JOHNSON, R., VLISSIDES, J., Design Patterns: Elements of Reusable Object-Oriented Software, 1\u00aa ed., Addison-Wesley Professional, 1994.</p> </li> <li> <p>SANTANA, E. F. Z., Back-end Java: Microsservi\u00e7os, Spring Boot e Kubernetes, Casa do C\u00f3digo, 2021. Material.</p> </li> <li> <p>SANTANA, E. F. Z., Apache Kafka e Spring Boot: Comunica\u00e7\u00e3o ass\u00edncrona entre microsservi\u00e7os, Casa do C\u00f3digo, 2022. Material.</p> </li> <li> <p>VERONEZ, F., Canal do YouTube.</p> </li> </ol> <p>Artigos:</p> <ul> <li> <p>XU, A. et al.. ByteByteGo - System Design 101. Dispon\u00edvel em: https://github.com/ByteByteGoHq/system-design-101. Acesso em: 19 dezembro 2023.</p> </li> <li> <p>Spring. Spring Cloud. Dispon\u00edvel em: https://spring.io/projects/spring-cloud. Acesso em: 19 dezembro 2023.</p> </li> <li> <p>CHOI, K., Software Engineering Blogs. Dispon\u00edvel em: https://github.com/kilimchoi/engineering-blogs. Acesso em: 20 dezembro 2023.</p> </li> <li> <p>Ghemawat, S. et al.. Towards Modern Development of Cloud Applications.  Proceedings of the 19th Workshop on Hot Topics in Operating Systems, 2023 - p. 110-117. Association for Computing Machinery, Providence, RI, USA. Dispon\u00edvel em: doi:10.1145/3593856.3595909. Acesso em: 05 fevereiro de 2024.</p> </li> </ul>"},{"location":"disclaimer/","title":"Disclaimer","text":""},{"location":"disclaimer/#contributors","title":"Contributors","text":"Name Humberto Sandmann Fabio Roberto de Miranda Raul Ikeda Maciel Calebe Vidal Eduardo Felipe Zambom Santana"},{"location":"disclaimer/#source","title":"Source","text":"<p>Circa of 70% of the whole conceptual texts were generated by ChatGPT nonetheless all of them were revised by the editor. The sections of handout was produced by the contributors.</p>"},{"location":"appendix/development-setup/","title":"Development Setup","text":"<p>This environment setup guide will help you configure your development environment for the course. Follow the steps below to get started.</p> <p>The prerequisites for this course include:</p> <ol> <li>Git: Version control system to manage your code.</li> <li>Docker: Containerization platform to run applications in isolated environments.</li> <li>Java: Programming language for backend development.</li> <li>Maven: Package and build automation tool for Java projects.</li> </ol>"},{"location":"appendix/development-setup/#git","title":"Git","text":"<p>Git is a distributed version control system that allows you to track changes in your code and collaborate with others. To install Git, follow the instructions for your operating system:</p>  Windows macOS Linux <p>Download and install Git from git-scm.com.</p> <p>Install Git using Homebrew with the command:</p> <pre><code>brew install git\n</code></pre> <p>Install Git using your package manager, e.g.,</p> <pre><code>sudo apt update\nsudo apt install git\n</code></pre> <p>for Debian-based systems.</p>"},{"location":"appendix/development-setup/#docker","title":"Docker","text":"<p>Docker is a platform that allows you to develop, ship, and run applications in containers. Containers are lightweight, portable, and provide a consistent environment across different systems. To install Docker, follow the instructions for your operating system:</p> <p>To install Docker Engine, see Install Docker Engine.</p>"},{"location":"appendix/development-setup/#java","title":"Java","text":"<p>Java is a widely-used programming language for building backend applications. To install Java, follow the instructions for your operating system:</p>  Windows macOS Linux <p>Download and unzip the OpenJDK.</p> <p>Preferably, use a LTS (Long-Term Support) version like OpenJDK 21 or 25.</p> <p>After the installation, please set the <code>JAVA_HOME</code> environment variable to the JDK installation path.</p> <p>Also, add the <code>bin</code> directory of the JDK installation path to your <code>PATH</code> environment variable.</p> <p>Install Java using Homebrew with the command:</p> <pre><code>brew install openjdk\n</code></pre> <p>Install Java using your package manager, e.g.,</p> <pre><code>sudo apt update\nsudo apt install openjdk-21\n</code></pre> <p>for Debian-based systems.</p>"},{"location":"appendix/development-setup/#maven","title":"Maven","text":"<p>Maven is a build automation tool primarily used for Java projects. It helps manage project dependencies, build processes, and documentation. To install Maven, follow the instructions for your operating system:</p>  Windows macOS Linux <p>Download and unzip the Maven binary.</p> <p>After the installation, please set the <code>MAVEN_HOME</code> environment variable to the Maven installation path.</p> <p>Also, add the <code>bin</code> directory of the Maven installation path to your <code>PATH</code> environment variable.</p> <p>Install Maven using Homebrew with the command:</p> <pre><code>brew install maven\n</code></pre> <p>Install Maven using your package manager, e.g.,</p> <pre><code>sudo apt update\nsudo apt install maven\n</code></pre> <p>for Debian-based systems.</p>"},{"location":"appendix/git-submodules/","title":"Git Submodules","text":"<p>Git submodules allow you to include one Git repository inside another as a subdirectory. This is useful when your project depends on external libraries, shared components, or separate sub-projects that should maintain their own independent version history.</p> <p>The main repository is called the superproject, and the included repositories are submodules.</p> <p>Submodules are pinned to a specific commit (not a branch by default), which gives very stable and reproducible dependencies \u2014 but it also means they don't update automatically.</p>"},{"location":"appendix/git-submodules/#official-best-starting-point","title":"Official / Best Starting Point","text":"<p>The canonical explanation is in the official Git book: https://git-scm.com/book/en/v2/Git-Tools-Submodules</p> <p>Here is a clear, practical summary of how to use them in 2026 (commands are still the same as in recent years).</p>"},{"location":"appendix/git-submodules/#1-adding-a-submodule","title":"1. Adding a submodule","text":"<pre><code># From inside your main (superproject) repository\ngit submodule add https://github.com/username/account.git api/account\n#               or ssh:  git@github.com:username/account.git api/account\n\n# You can also specify a custom path\ngit submodule add https://github.com/chaconinc/order.git api/order\n</code></pre> <p>This does: - Clones the repository into the specified folder - Adds an entry to <code>.gitmodules</code> (a file that gets committed) - Stages a special \"gitlink\" entry in the index (the submodule commit pointer)</p> <p>After running this, commit the change:</p> <pre><code>git commit -m \"Add Account and Order as submodules\"\n</code></pre> <p>You now have a new file <code>.gitmodules</code> looking something like this:</p> <pre><code>[submodule \"api/account\"]\n    path = api/account\n    url = https://github.com/username/account.git\n[submodule \"api/order\"]\n    path = api/order\n    url = https://github.com/chaconinc/order.git\n</code></pre>"},{"location":"appendix/git-submodules/#2-cloning-a-project-that-contains-submodules","title":"2. Cloning a project that contains submodules","text":"<p>Other people (or you on a new machine) need extra steps:</p> <pre><code>git clone --recursive https://github.com/yourname/yourproject.git\n</code></pre> <p>This clones everything, including all submodules.</p> <p>Alternative (if you already cloned normally):</p> <pre><code>git submodule init\ngit submodule update\n# or more commonly in one line:\ngit submodule update --init --recursive\n</code></pre> <p>The <code>--recursive</code> flag is very important if your submodules contain submodules themselves.</p>"},{"location":"appendix/git-submodules/#3-working-inside-updating-a-submodule","title":"3. Working inside / updating a submodule","text":"<pre><code>cd api/account          # go into the submodule folder\n\ngit checkout main        # or whatever branch you want\ngit pull origin main\n\n# Now you're on a branch and can make changes\n# After you're done developing \u2192 commit &amp; push inside the submodule\ncd ..                    # back to superproject\n\ngit add api/account api/order     # record the new commit hash\ngit commit -m \"Update submodules to latest main\"\ngit push\n</code></pre>"},{"location":"appendix/git-submodules/#4-pulling-updates-to-submodules-most-common-workflow","title":"4. Pulling updates to submodules (most common workflow)","text":"<p>To bring submodules up to the commits recorded in the superproject:</p> <pre><code>git pull                # normal pull of superproject\ngit submodule update --init --recursive\n</code></pre> <p>If you want to update submodules to latest remote (and record new commits):</p> <pre><code>git submodule update --remote --merge   # or --rebase\n# then commit the updated pointer in the superproject\ngit add .\ngit commit -m \"Update all submodules to latest\"\n</code></pre>"},{"location":"appendix/git-submodules/#5-quick-reference-most-useful-commands","title":"5. Quick reference \u2014 most useful commands","text":"What you want to do Command Add new submodule <code>git submodule add &lt;url&gt; [path]</code> Clone repo + all submodules <code>git clone --recursive &lt;url&gt;</code> Init + fetch submodules after normal clone <code>git submodule update --init --recursive</code> Update to recorded commits <code>git submodule update --recursive</code> Update submodules to latest remote <code>git submodule update --remote [--merge or --rebase]</code> Run command in every submodule <code>git submodule foreach 'git status'</code> Remove a submodule (modern Git) <code>git submodule deinit -f path/to/sub</code><code>rm -rf .git/modules/path/to/sub</code><code>git rm -f path/to/sub</code>"},{"location":"appendix/git-submodules/#important-warnings-best-practices-20242026-style","title":"Important Warnings &amp; Best Practices (2024\u20132026 style)","text":"<ul> <li>Submodules are intentionally static \u2014 they won't surprise you by changing.</li> <li>Many teams now prefer subtree, monorepo, package managers (npm, cargo, go modules, etc.), or Git worktrees instead of submodules when possible.</li> <li>Always document in README how to clone: <code>git clone --recursive \u2026</code>   or <code>git clone \u2026 &amp;&amp; git submodule update --init --recursive</code></li> <li>Avoid making changes directly in the submodule folder unless you really intend to contribute upstream.</li> <li>Use <code>--recursive</code> almost always \u2014 nested submodules are common.</li> <li>If many people complain about submodules \u2192 consider alternatives.</li> </ul> <p>Content created by Grok and edited for the course.</p>"},{"location":"appendix/network/","title":"Network","text":"<p>The internet is a global network of interconnected computers and servers that communicate with each other using standardized protocols. It allows users to access and share information, communicate with others, and perform various online activities. This global networks was developed in the late 1960s with the goal of creating a resilient and decentralized communication system. Over the years, the internet has evolved and standards have been established to ensure interoperability and security.</p> <p>In the initial os 80s, the TCP/IP, RFC 791<sup>5</sup>, protocol suite was developed, which became the foundation of the internet. This protocol suite allows for the transmission of data packets across the network and enables communication between different devices and networks. The basic premise of the internet is that each device connected to the network is assigned a unique IP address, which allows it to send and receive data. When a user wants to access a website or send an email, their device sends a request to the appropriate server using the IP address. The server then processes the request and sends the requested data back to the user's device.</p>"},{"location":"appendix/network/#public-networks-internet","title":"Public Networks (Internet)","text":"<p>To reach a server on the internet, its computer (the computer where the server is hosted) needs to know its IP address, a Public IP address. When the TCP/IP protocol suite was developed, the number of available IP addresses was limited, and it became clear that a more efficient way to manage IP addresses was needed. The IPv4 protocol, which uses 32-bit addresses, was initially used, but it has a limited number of available addresses (approximately 4.3 billion).</p> <p>As the internet grew, it became clear that this was not sufficient to accommodate the increasing number of devices and servers. This led to the development of the IPv6 protocol, which uses 128-bit addresses and provides a much larger address space (approximately 3.4 x 10^38 addresses). However, the transition from IPv4 to IPv6 has been slow, and many devices and servers still use IPv4 addresses - IPv6 Adoption.</p> <p>Thefore, to allow devices with private IP addresses (which are not routable on the internet) to communicate with servers on the internet, a technique called Network Address Translation (NAT) is used. NAT allows multiple devices on a local network to share a single public IP address when accessing the internet. This is done by translating the Private IP<sup>3</sup> addresses of the devices to the public IP address of the NAT device (such as a router) when sending requests to the internet, and translating the responses back to the appropriate private IP addresses when receiving data from the internet.</p>"},{"location":"appendix/network/#private-networks","title":"Private Networks","text":"<p>Private networks are networks that are not directly accessible from the public internet. They are used to isolate resources and provide a secure environment for communication between devices. In the context of Docker, private networks allow containers to communicate with each other without exposing their services to the outside world.</p> <pre><code>---\ntitle: Network Address Translation (NAT)\n---\nflowchart TB\n    host1@{ shape: docs, label: \"Host 1\"} ---|Public IP| internet([Internet])\n    host2@{ shape: docs, label: \"Host 2\"} ---|Public IP| internet([Internet])\n    host3@{ shape: docs, label: \"Host 3\"} ---|Public IP| internet([Internet])\n    internet((Internet)) ---|Public IP| router1((Border Router&lt;br&gt;NAT&lt;br&gt;10.0.0.0/8))\n    router1 ---|Private IP| device1([Device 1])\n    router1 ---|Private IP| device2([Device 2])\n    router1 ---|Private IP| device3([Device 3])\n    router1 ---|Private IP| router2((Router&lt;br&gt;NAT&lt;br&gt;172.16.0.0/12))\n    router2 ---|Private IP| router3((Router&lt;br&gt;NAT&lt;br&gt;192.168.0.0/16))\n    router2 ---|Private IP| router4((Router&lt;br&gt;NAT&lt;br&gt;192.168.0.0/16))\n    router2 ---|Private IP| device4([Device 4])\n    router2 ---|Private IP| device5([Device 5])\n    router3 ---|Private IP| device6([Device 6])\n    router3 ---|Private IP| device7([Device 7])\n    router4 ---|Private IP| device8([Device 8])\n    router4 ---|Private IP| device9([Device 9])\n    classDef internet fill:#ccf\n    classDef router fill:#fcc\n    classDef device fill:#cfc\n    class internet internet\n    class router1,router2,router3,router4 router\n    class device1,device2,device3,device4,device5,device6,device7,device8,device9 device</code></pre> The diagram illustrates a network setup with multiple routers and devices, where each router uses Network Address Translation (NAT) to manage private IP addresses. The internet is connected to the first router (the border router), which has a public IP address, while the other routers and devices use private IP addresses within their respective subnets. <p>Private networks are defined by specific IP address ranges that are reserved for private use. These ranges are not routable on the public internet, ensuring that devices within a private network can communicate securely without interference from external networks.</p>"},{"location":"appendix/network/#reserved-ipv4-addresses","title":"Reserved IPv4 Addresses <sup>4</sup>","text":""},{"location":"appendix/network/#general-reserved-ipv4-addresses","title":"General Reserved IPv4 Addresses","text":"Address block (CIDR) Address range Number of addresses Scope Description 0.0.0.0/8 0.0.0.00.255.255.255 16.777.216 Software Current (local, \"this\") network 10.0.0.0/8 10.0.0.010.255.255.255 16.777.216 Private network Used for local communications within a private network 100.64.0.0/10 100.64.0.0100.127.255.255 4.194.304 Private network Shared address space for communications between a service provider and its subscribers when using a carrier-grade NAT 127.0.0.0/8 127.0.0.0127.255.255.255 16.777.216 Host Used for loopback addresses to the local host 169.254.0.0/16 169.254.0.0169.254.255.255 65.536 Subnet Used for link-local addresses between two hosts on a single link when no IP address is otherwise specified, such as would have normally been retrieved from a DHCP server 172.16.0.0/12 172.16.0.0172.31.255.255 1.048.576 Private network Used for local communications within a private network 192.0.0.0/24 192.0.0.0192.0.0.255 256 Private network IETF Protocol Assignments, DS-Lite (/29) 192.0.2.0/24 192.0.2.0192.0.2.255 256 Documentation Assigned as TEST-NET-1, documentation and examples 192.88.99.0/24 192.88.99.0192.88.99.255 256 Internet Reserved. Formerly used for IPv6 to IPv4 relay (included IPv6 address block 2002::/16). 192.168.0.0/16 192.168.0.0192.168.255.255 65.536 Private network Used for local communications within a private network 198.18.0.0/15 198.18.0.0198.19.255.255 131.072 Private network Used for benchmark testing of inter-network communications between two separate subnets 198.51.100.0/24 198.51.100.0198.51.100.255 256 Documentation Assigned as TEST-NET-2, documentation and examples 203.0.113.0/24 203.0.113.0203.0.113.255 256 Documentation Assigned as TEST-NET-3, documentation and examples 224.0.0.0/4 224.0.0.0239.255.255.255 268.435.456 Internet In use for multicast (former Class D network) 233.252.0.0/24 233.252.0.0233.252.0.255 256 Documentation Assigned as MCAST-TEST-NET, documentation and examples (This is part of the above multicast space.) 240.0.0.0/4 240.0.0.0255.255.255.254 268.435.455 Internet Reserved for future use (former Class E network) 255.255.255.255/32 255.255.255.255 1 Subnet Reserved for the \"limited broadcast\" destination address"},{"location":"appendix/network/#private-ipv4-addresses","title":"Private IPv4 Addresses <sup>2</sup>","text":"Address block (CIDR) Address range Number of addresses Scope Description 10.0.0.0/8 10.0.0.010.255.255.255 16.777.216 Private network Used for local communications within a private network 172.16.0.0/12 172.16.0.0172.31.255.255 1.048.576 Private network Used for local communications within a private network 192.168.0.0/16 192.168.0.0192.168.255.255 65.536 Private network Used for local communications within a private network <ol> <li> <p>List of reserved IP addresses \u21a9</p> </li> <li> <p>RFC 1918 - Address Allocation for Private Internets \u21a9</p> </li> <li> <p>Private Network \u21a9</p> </li> <li> <p>Reserved IP Addresses \u21a9</p> </li> <li> <p>RFC 791 - Internet Protocol \u21a9</p> </li> <li> <p>IPv6 Adoption: A resource that tracks the adoption of IPv6 across the internet, providing statistics and insights into the transition from IPv4 to IPv6.\u00a0\u21a9</p> </li> </ol>"},{"location":"appendix/ohmyzsh/","title":"Oh My Zsh","text":"<p>Install:</p> <pre><code>sudo apt install zsh\nchsh -s $(which zsh)\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n</code></pre> <p>Plugins:</p> <pre><code>git clone https://github.com/zsh-users/zsh-syntax-highlighting ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\ngit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\ngit clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf &amp;&amp; ~/.fzf/install\n</code></pre> <p>Edit the file <code>~/.zshrc</code> at home's folder:</p> <pre><code>nano ~/.zshrc\n</code></pre> ~/.zshrc<pre><code>ZSH_THEME=\"afowler\"\nplugins=(\n  git\n  zsh-syntax-highlighting\n  zsh-autosuggestions\n  fzf\n)\n</code></pre> <p>Reference:</p> <ul> <li>Oh My Zsh</li> </ul>"},{"location":"appendix/others/","title":"Others","text":""},{"location":"appendix/others/#architectures","title":"Architectures","text":"<p> Clojure and Datomic Studies with Docker and Kafka by Pelichero, F.</p>"},{"location":"appendix/others/#spring-boot","title":"Spring Boot","text":"<p>Spring Boot - Supported Versions</p>"},{"location":"appendix/others/#security","title":"Security","text":"<p>The Heartbleed Bug</p> <p>The HTTPS-Only Standard</p> <p>Let's Encrypt</p>"},{"location":"appendix/others/#interesting-articles","title":"Interesting Articles","text":"<p>RFC 9562 - Universally Unique IDentifiers (UUIDs)</p> <p>RFC 9457 - Problem Details for HTTP APIs</p>"},{"location":"appendix/rest-vs-graphql/","title":"REST vs GraphQL","text":""},{"location":"appendix/rest-vs-graphql/#rest-vs-graphql","title":"REST vs GraphQL","text":"Source: System Design 101 - REST API vs. GraphQL <ol> <li> <p>XU, A., System Design 101.\u00a0\u21a9</p> </li> <li> <p> REST.\u00a0\u21a9</p> </li> <li> <p> GraphQL.\u00a0\u21a9</p> </li> </ol>"},{"location":"appendix/rsa/","title":"RSA Algorithm","text":""},{"location":"appendix/rsa/#generating-the-rsa-keys","title":"Generating the RSA Keys","text":"Part 1Part 2 <p> The RSA Encryption Algorithm (1 of 2: Generating the Keys)</p> <p></p> <p> The RSA Encryption Algorithm (2 of 2: Generating the Keys)</p> <p></p>"},{"location":"appendix/versioning-rest-apis/","title":"Versioning REST APIs","text":""},{"location":"appendix/versioning-rest-apis/#versioning-rest-api","title":"Versioning REST API","text":"<ol> <li> <p>Jacky, Versioning RESTful APIs with Spring Boot: A Step-by-Step Guide in 5 minutes.\u00a0\u21a9</p> </li> </ol>"},{"location":"classes/api/","title":"Documentation","text":""},{"location":"classes/api/#documentation","title":"Documentation","text":""},{"location":"classes/api/#swagger","title":"Swagger","text":"mavengradle <pre><code>&lt;dependency&gt;\n&lt;/dependency&gt;\n</code></pre> <pre><code>\n</code></pre> <p>```javascript I'm A tab console.log('Code Tab A'); </p><pre><code>```javascript I'm tab B\nconsole.log('Code Tab B');\n</code></pre><p></p> CC++ <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <p>https://www.baeldung.com/spring-rest-openapi-documentation</p>"},{"location":"classes/architectures/","title":"Index","text":""},{"location":"classes/architectures/#clean-architecture","title":"Clean Architecture","text":"<p>Total desacoplamento das regras de neg\u00f3cios das camadas de interface:</p> <p> </p> Source: The Clean Code Blog <p>Em nossa arquitetura:</p> <pre><code>flowchart LR\n  subgraph Controller\n    direction TB\n    Interface:::adapter\n    RecordIn:::adapter\n    RecordOut:::adapter\n  end\n  subgraph Case\n    direction TB\n    Service:::case\n    DTO:::case\n  end\n  subgraph Entity\n    direction TB\n    Repository:::entity\n    Table:::entity\n  end\n\n  Interface --&gt; RecordIn\n  Interface --&gt; RecordOut\n\n  Controller &lt;--&gt; parser[\"Parser\"] &lt;--&gt; Case\n\n  Service --&gt; DTO\n\n  Case &lt;--&gt; mapper[\"Mapper\"] &lt;--&gt; Entity\n\n  Repository --&gt; Table\n\n  classDef adapter fill:#6f6\n  classDef case fill:#f99\n  classDef entity fill:#ff9\n</code></pre>"},{"location":"classes/architectures/#hexagonal-architecture","title":"Hexagonal Architecture","text":""},{"location":"classes/architectures/#referencias","title":"Refer\u00eancias:","text":"<ol> <li> <p> Criando um projeto Spring Boot com Arquitetura Limpa by Giuliana Silva Bezerra</p> <p> \u21a9</p> </li> <li> <p> Clean Architecture: A Craftsman's Guide to Software Structure and Design \u21a9</p> </li> <li> <p> Como se faz DevOps: Organizando pessoas, dos silos aos times de plataforma \u21a9</p> </li> </ol>"},{"location":"classes/cloud/","title":"Index","text":""},{"location":"classes/cloud/gitactions/","title":"Gitactions","text":""},{"location":"classes/cloud/gitactions/#github-actions","title":"GitHub Actions","text":"<p>GitHub Actions is a feature of GitHub that allows you to automate, customize, and execute your software development workflows right in your repository. </p> <p>With GitHub Actions, you can build, test, and deploy your code directly from GitHub. It provides world-class support for Continuous Integration/Continuous Deployment (CI/CD). </p> <p>In addition, GitHub Actions allows you to automate other aspects of your development workflow such as assigning code reviews, managing branches, and triaging issues.</p>"},{"location":"classes/cloud/terraform/","title":"Terraform","text":""},{"location":"classes/cloud/terraform/#infrastructure-as-code-iac","title":"Infrastructure as Code (IaC)","text":"<p>Infrastructure as Code (IaC) is a method of managing and provisioning computing infrastructure through machine-readable definition files, rather than physical hardware configuration or interactive configuration tools. </p> <p>The IT infrastructure managed by this comprises both physical equipment, such as bare-metal servers, as well as virtual machines, and associated configuration resources. The definitions may be in a version control system. It can use either scripts or declarative definitions, rather than manual processes, but the term is more often used to promote declarative approaches.</p>"},{"location":"classes/cloud/terraform/#pros","title":"Pros","text":"<ul> <li>Automatization of creation of an infrastructure;</li> <li>Standardization of platforms;</li> <li>Replication of infrastructure.</li> </ul> <pre><code>|- .github\n|  |- workflows\n|- s3-bucket-static\n   |- main.tf\n</code></pre> main.tf<pre><code>provider \"aws\" {\n    region = \"us-east-1\"\n}\n\nvariable \"bucket_name\" {\n    type = string\n}\n\nresource \"aws_s3_bucket\" \"static_site_bucket\" {\n    bucket = \"static-site-${var.bucket_name}\"\n\n    website {\n        index_document = \"index.html\"\n        error_document = \"404.html\n    }\n\n    tags = {\n        Name = \"Static Site Bucket\"\n        Environment = \"Production\"\n    }\n}\n\nresource \"aws_s3_public_access_block\" \"static_site_bucket\" {\n    bucket aws_s3_bucket.static_site_bucket.id\n\n    block_public_acls       = false\n    block_public_policy     = false\n    ignore_public_acls      = false\n    restrict_public_buckets = false\n}\n</code></pre>"},{"location":"classes/cloud/terraform/#alternatives","title":"Alternatives","text":"<ul> <li>AWS CloudFormation</li> <li>Ansible</li> <li>Vagrant</li> </ul>"},{"location":"classes/cloud/terraform/#additional-material","title":"Additional Material","text":"<ul> <li> <p> Criando Infra na AWS com Terraform (IaC) by Fernanda Kipper</p> <p></p> </li> </ul>"},{"location":"classes/cloud_service_models/","title":"Index","text":"<p>Cloud computing has revolutionized how organizations build, deploy, and scale applications. The three foundational service models\u2014Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS)\u2014represent layers of abstraction over physical hardware, each catering to different levels of control, management responsibility, and operational efficiency. These models form a stacked hierarchy, where higher layers build upon and abstract the complexities of lower ones.</p> <p>This article provides a deep technical and operational breakdown of each model, their interrelationships, shared responsibility boundaries, real-world use cases, and trade-offs. A visual diagram and authoritative references are included.</p>"},{"location":"classes/cloud_service_models/#1-infrastructure-as-a-service-iaas","title":"1. Infrastructure as a Service (IaaS)","text":""},{"location":"classes/cloud_service_models/#definition","title":"Definition","text":"<p>IaaS delivers virtualized computing resources over the internet. Users rent raw infrastructure\u2014servers, storage, networking, and virtualization\u2014on a pay-as-you-go basis.</p>"},{"location":"classes/cloud_service_models/#core-components","title":"Core Components","text":"Component Description Examples Compute Virtual machines (VMs) or bare-metal servers AWS EC2, Azure VMs, Google Compute Engine Storage Block, file, or object storage AWS S3, EBS; Azure Blob Storage Networking VPCs, load balancers, firewalls, DNS AWS VPC, Azure VNet Virtualization Hypervisors (e.g., KVM, Xen, VMware) Managed via provider APIs"},{"location":"classes/cloud_service_models/#management-responsibility-user","title":"Management Responsibility (User)","text":"<ul> <li>OS installation, patching, updates</li> <li>Middleware (web servers, databases)</li> <li>Application runtime and data</li> <li>Security configurations (firewalls, IAM)</li> </ul>"},{"location":"classes/cloud_service_models/#provider-responsibility","title":"Provider Responsibility","text":"<ul> <li>Physical data centers</li> <li>Power, cooling, hardware maintenance</li> <li>Host OS and hypervisor</li> <li>Network infrastructure</li> </ul>"},{"location":"classes/cloud_service_models/#deep-technical-insight","title":"Deep Technical Insight","text":"<ul> <li>Instance Types: Optimized for CPU, memory, GPU, or storage (e.g., AWS <code>c6g</code> for ARM Graviton).</li> <li>Billing Granularity: Per-second billing (post-2017 in major providers).</li> <li>Programmatic Control: Full root access via SSH/RDP; automation via Terraform, CloudFormation.</li> <li>High Availability: Multi-AZ deployments, auto-scaling groups.</li> </ul>"},{"location":"classes/cloud_service_models/#use-cases","title":"Use Cases","text":"<ul> <li>Lift-and-shift migrations</li> <li>Dev/test environments</li> <li>Disaster recovery</li> <li>High-performance computing (HPC)</li> </ul>"},{"location":"classes/cloud_service_models/#2-platform-as-a-service-paas","title":"2. Platform as a Service (PaaS)","text":""},{"location":"classes/cloud_service_models/#definition_1","title":"Definition","text":"<p>PaaS provides a managed application development and deployment platform. Developers focus on code; the provider manages the underlying infrastructure, OS, middleware, and runtime.</p>"},{"location":"classes/cloud_service_models/#core-components_1","title":"Core Components","text":"Layer Managed By Examples Runtime Provider Node.js, Python, Java, .NET Middleware Provider Message queues, caching (Redis) OS Provider Linux/Windows (patched automatically) Infrastructure Provider Auto-scaled compute, storage"},{"location":"classes/cloud_service_models/#management-responsibility-user_1","title":"Management Responsibility (User)","text":"<ul> <li>Application code</li> <li>Configuration (environment variables, scaling rules)</li> <li>Data (in managed DBs)</li> </ul>"},{"location":"classes/cloud_service_models/#provider-responsibility_1","title":"Provider Responsibility","text":"<ul> <li>Everything below the application layer</li> <li>Auto-scaling, load balancing, patching</li> <li>Build pipelines, CI/CD integration</li> </ul>"},{"location":"classes/cloud_service_models/#deep-technical-insight_1","title":"Deep Technical Insight","text":"<ul> <li>Stateless Architecture: Encourages 12-factor app design.</li> <li>Buildpacks / Containers: Heroku (buildpacks), Cloud Foundry, AWS Elastic Beanstalk, Azure App Service.</li> <li>Serverless Evolution: AWS Lambda, Azure Functions = PaaS extreme (no server management).</li> <li>Polyglot Support: Multiple language runtimes with zero-downtime deployments.</li> </ul>"},{"location":"classes/cloud_service_models/#use-cases_1","title":"Use Cases","text":"<ul> <li>Microservices deployment</li> <li>API backends</li> <li>Rapid prototyping</li> <li>Mobile app backends</li> </ul>"},{"location":"classes/cloud_service_models/#3-software-as-a-service-saas","title":"3. Software as a Service (SaaS)","text":""},{"location":"classes/cloud_service_models/#definition_2","title":"Definition","text":"<p>SaaS delivers fully functional software applications over the internet on a subscription basis. Users access via browser or API\u2014no installation or maintenance.</p>"},{"location":"classes/cloud_service_models/#core-components_2","title":"Core Components","text":"Component Managed By Examples Application Provider Gmail, Salesforce, Slack Data Provider (multi-tenant) Isolated logically Runtime &amp; Infra Provider Fully abstracted"},{"location":"classes/cloud_service_models/#management-responsibility-user_2","title":"Management Responsibility (User)","text":"<ul> <li>User accounts, permissions</li> <li>Data input and usage</li> <li>Integrations (via APIs)</li> </ul>"},{"location":"classes/cloud_service_models/#provider-responsibility_2","title":"Provider Responsibility","text":"<ul> <li>Everything: Code, servers, databases, security, updates, scaling</li> </ul>"},{"location":"classes/cloud_service_models/#deep-technical-insight_2","title":"Deep Technical Insight","text":"<ul> <li>Multi-Tenancy: Single instance serves all customers; data isolated via tenant IDs.</li> <li>Zero-Touch Updates: Continuous deployment with A/B testing.</li> <li>API-First Design: REST/GraphQL APIs for integration (e.g., Zapier, Salesforce APIs).</li> <li>Compliance Built-In: SOC 2, GDPR, HIPAA (provider-managed).</li> </ul>"},{"location":"classes/cloud_service_models/#use-cases_2","title":"Use Cases","text":"<ul> <li>CRM (Salesforce)</li> <li>Collaboration (Microsoft 365)</li> <li>HR (Workday)</li> <li>Analytics (Google Analytics)</li> </ul>"},{"location":"classes/cloud_service_models/#the-relationship-the-cloud-service-stack","title":"The Relationship: The Cloud Service Stack","text":"<p>The models are hierarchical and interdependent:</p> <pre><code>+------------------+\n|      SaaS        |  \u2190 Fully managed application\n+------------------+\n|      PaaS        |  \u2190 Development + runtime platform\n+------------------+\n|      IaaS        |  \u2190 Raw infrastructure\n+------------------+\n| On-Premises      |  \u2190 You manage everything\n+------------------+\n</code></pre>"},{"location":"classes/cloud_service_models/#key-relationships","title":"Key Relationships","text":"Relationship Explanation SaaS builds on PaaS SaaS providers use PaaS internally (e.g., Salesforce runs on Heroku-like PaaS). PaaS builds on IaaS PaaS orchestrates VMs, containers, and storage from IaaS (e.g., AWS Elastic Beanstalk uses EC2). IaaS is the foundation All cloud services run on virtualized hardware. Hybrid Scenarios Use IaaS for custom OS, PaaS for apps, SaaS for productivity."},{"location":"classes/cloud_service_models/#visual-diagram-cloud-service-responsibility-matrix","title":"Visual Diagram: Cloud Service Responsibility Matrix","text":"<p>Legend:</p> <ul> <li>Green: Managed by Provider</li> <li>Orange: Managed by User</li> <li>Pink: SaaS user manages only data/config</li> </ul>"},{"location":"classes/cloud_service_models/#comparison-table","title":"Comparison Table","text":"Feature IaaS PaaS SaaS Control High Medium Low Flexibility Highest High Lowest Time to Market Slow Fast Instant Scalability Manual/Automated Automatic Automatic Cost Model Pay for infra Pay for usage Pay per user/seat Maintenance User Provider Provider Examples AWS EC2, DigitalOcean Heroku, AWS Elastic Beanstalk Google Workspace, Dropbox"},{"location":"classes/cloud_service_models/#trade-offs-and-decision-framework","title":"Trade-offs and Decision Framework","text":"Scenario Recommended Model Need full OS control IaaS Building custom apps fast PaaS Need off-the-shelf software SaaS Compliance requires isolation IaaS or dedicated PaaS Startup MVP PaaS + SaaS tools Enterprise with legacy apps IaaS (lift-and-shift)"},{"location":"classes/cloud_service_models/#conclusion","title":"Conclusion","text":"<p>IaaS, PaaS, and SaaS are not competitors but complementary layers in the cloud ecosystem. Choosing the right model\u2014or combining them\u2014depends on control needs, development speed, operational overhead, and compliance requirements. Modern architectures often use all three: IaaS for custom workloads, PaaS for application logic, and SaaS for productivity and integration.</p> <p>Pro Tip: Use the shared responsibility model as your decision anchor\u2014the less you want to manage, the higher you go in the stack.</p> <p>Article by Grok (xAI) | November 05, 2025</p>"},{"location":"classes/cloud_service_models/#references","title":"References","text":"<ol> <li> <p>NIST Special Publication 800-145 \u2013 The NIST Definition of Cloud Computing https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-145.pdf \u21a9</p> </li> <li> <p>Mell, P., &amp; Grance, T. (2011) \u2013 NIST cloud model foundational paper.\u00a0\u21a9</p> </li> <li> <p>AWS Well-Architected Framework \u2013 Responsibility model https://aws.amazon.com/architecture/well-architected/ \u21a9</p> </li> <li> <p>Microsoft Azure Documentation \u2013 Shared Responsibility Model https://learn.microsoft.com/en-us/azure/security/fundamentals/shared-responsibility \u21a9</p> </li> <li> <p>Cloud Native Computing Foundation (CNCF) \u2013 PaaS evolution with Kubernetes https://www.cncf.io/ \u21a9</p> </li> </ol>"},{"location":"classes/cloud_service_models/visual_matrix/","title":"Visual matrix","text":"<pre><code>graph TD\n    subgraph On-Premises\n        direction TB\n        A1[Hardware] --&gt; A2[Virtualization]\n        A2 --&gt; A3[OS]\n        A3 --&gt; A4[Middleware]\n        A4 --&gt; A5[Application]\n        A5 --&gt; A6[Data]\n        style A1 fill:#ff9999,stroke:#333\n        style A2 fill:#ff9999,stroke:#333\n        style A3 fill:#ff9999,stroke:#333\n        style A4 fill:#ff9999,stroke:#333\n        style A5 fill:#ff9999,stroke:#333\n        style A6 fill:#ff9999,stroke:#333\n    end\n\n    subgraph IaaS\n        direction TB\n        B1[Hardware] --&gt; B2[Virtualization]\n        B2 --&gt; B3[OS]\n        B3 --&gt; B4[Middleware]\n        B4 --&gt; B5[Application]\n        B5 --&gt; B6[Data]\n        style B1 fill:#a8e6cf,stroke:#333\n        style B2 fill:#a8e6cf,stroke:#333\n        style B3 fill:#ffd3b6,stroke:#333\n        style B4 fill:#ffd3b6,stroke:#333\n        style B5 fill:#ffd3b6,stroke:#333\n        style B6 fill:#ffd3b6,stroke:#333\n    end\n\n    subgraph PaaS\n        direction TB\n        C1[Hardware] --&gt; C2[Virtualization]\n        C2 --&gt; C3[OS]\n        C3 --&gt; C4[Middleware]\n        C4 --&gt; C5[Application]\n        C5 --&gt; C6[Data]\n        style C1 fill:#a8e6cf,stroke:#333\n        style C2 fill:#a8e6cf,stroke:#333\n        style C3 fill:#a8e6cf,stroke:#333\n        style C4 fill:#a8e6cf,stroke:#333\n        style C5 fill:#ffaaa5,stroke:#333\n        style C6 fill:#ffaaa5,stroke:#333\n    end\n\n    subgraph SaaS\n        direction TB\n        D1[Hardware] --&gt; D2[Virtualization]\n        D2 --&gt; D3[OS]\n        D3 --&gt; D4[Middleware]\n        D4 --&gt; D5[Application]\n        D5 --&gt; D6[Data]\n        style D1 fill:#a8e6cf,stroke:#333\n        style D2 fill:#a8e6cf,stroke:#333\n        style D3 fill:#a8e6cf,stroke:#333\n        style D4 fill:#a8e6cf,stroke:#333\n        style D5 fill:#a8e6cf,stroke:#333\n        style D6 fill:#a8e6cf,stroke:#333\n    end\n\n    %% Legend\n    classDef provider fill:#a8e6cf,stroke:#333,color:#000\n    classDef user fill:#ffd3b6,stroke:#333,color:#000\n    classDef saas fill:#ffaaa5,stroke:#333,color:#000\n    class B1,B2,C1,C2,C3,C4,D1,D2,D3,D4,D5,D6 provider\n    class B3,B4,B5,B6,C5,C6 user\n    class A1,A2,A3,A4,A5,A6 user</code></pre>"},{"location":"classes/containerization/","title":"2. Containerization","text":"<p>When a server has so much traffic that it cannot handle it, the solution is to add more servers or increase the capacity of existing ones. This is called scalability.</p> <p>The scalability could be achieved:</p> <ul> <li> <p>by adding more servers to the system, which is known as horizontal scaling, or;</p> </li> <li> <p>by increasing the capacity of existing servers, which is known as vertical scaling.</p> </li> </ul> <p>Horizontal scaling allows for better fault tolerance and can handle more traffic, while vertical scaling can be more cost-effective for smaller applications. However, adding more servers can be a complex and time-consuming process, especially if the application is not designed to run in a distributed environment.</p> <p>Then, how can we ensure that our application can run consistently across different environments, such as development, testing, and production, without encountering issues related to dependencies, configurations, or compatibility?</p> <p>How to avoid the classical...</p> <p></p> <p>The answer is: CONTAINERIZATION.</p> <p>Docker is a platform and tool that enables developers to automate the deployment of applications inside lightweight, portable containers. Containers are a form of virtualization that packages an application and its dependencies together, ensuring consistency across different environments, from development to testing and production.</p> <p>Here are some key concepts and components of Docker:</p> <ul> <li>Containerization: Containers are lightweight, standalone, and executable packages that include everything needed to run a piece of software, including the code, runtime, libraries, and system tools. Containers isolate applications from their environment, making them portable and consistent across various systems.</li> <li>Docker Engine: This is the core component of Docker. It is a lightweight and portable runtime that can run containers on various operating systems, including Linux and Windows. The Docker Engine consists of a server, a REST API, and a command-line interface.</li> <li>Docker Image: An image is a lightweight, standalone, and executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and config files. Images are used to create containers.</li> <li>Dockerfile: A Dockerfile is a text file that contains instructions for building a Docker image. It specifies the base image, sets up the environment, installs dependencies, and configures the application.</li> <li>Registry: Docker images can be stored in registries, which are repositories for sharing and distributing container images. Docker Hub is a popular public registry, and organizations often use private registries to store and manage their proprietary images.</li> <li>Container Orchestration: Docker can be used in conjunction with container orchestration tools like Kubernetes or Docker Swarm to manage the deployment, scaling, and orchestration of containerized applications in production environments.</li> <li>Portability: One of Docker's key advantages is its portability. Since containers encapsulate everything an application needs to run, they can run consistently across different environments, reducing the \"it works on my machine\" problem often encountered in software development.</li> </ul> <p>Docker has become a widely adopted technology in the software development and deployment space due to its ease of use, portability, and the efficiency it brings to the development and deployment lifecycle. It has revolutionized the way applications are packaged, shipped, and deployed, making it easier for developers to build, test, and deploy applications in a more reliable and consistent manner.</p>"},{"location":"classes/containerization/#differences-between-docker-and-virtual-machines","title":"Differences between Docker and Virtual Machines","text":"<p>Docker containers and virtual machines (VMs) are both technologies used for virtualization, but they operate at different levels and have distinct characteristics. Here are the key differences between Docker containers and virtual machines:</p> Aspect Docker Containers Virtual Machines Architecture Containers share the host operating system's kernel and isolate the application processes from each other. Each container runs in its own user space but uses the host's kernel. VMs, on the other hand, run a complete operating system, including its own kernel, on top of a hypervisor. Each VM is essentially a full-fledged virtualized computer with its own resources. Resource Efficiency Containers are more lightweight and share the host OS kernel, which makes them more resource-efficient compared to VMs. Containers can start up quickly and consume fewer system resources. VMs have more overhead because each VM requires a full operating system and has its own kernel. This makes VMs less resource-efficient than containers. Isolation Containers provide process-level isolation, meaning that each container runs in its own process space, but they share the same OS kernel. This isolation is generally sufficient for most applications. VMs provide stronger isolation since each VM runs its own operating system and has its own kernel. This makes VMs a better choice in situations where strong isolation is a critical requirement. Portability Containers are highly portable because they encapsulate the application and its dependencies, ensuring consistency across different environments. VMs are less portable due to the larger size and complexity associated with bundling a full operating system with the application. Startup Time Containers can start up very quickly, typically in seconds, making them well-suited for microservices architectures and dynamic scaling. VMs generally have longer startup times, often measured in minutes, due to the time required to boot a full operating system. Resource Utilization Containers share the host OS resources, which can lead to higher density and more efficient resource utilization. VMs have a higher resource overhead because each VM requires its own set of resources, including memory, disk space, and CPU. Use Cases Containers are well-suited for microservices architectures, continuous integration/continuous deployment (CI/CD) pipelines, and scenarios where rapid deployment and scalability are crucial. VMs are suitable for scenarios that require strong isolation, compatibility with various operating systems, and where applications rely on specific OS configurations. <p> </p> Source: Docker Labs - Difference between VM and Containers <p>In summary, Docker containers and virtual machines have different levels of abstraction and are suitable for different use cases. Containers are lightweight, portable, and efficient, making them popular for modern application development and deployment practices. Virtual machines provide stronger isolation and are more suitable for scenarios where running multiple instances of different operating systems is necessary. The choice between Docker containers and virtual machines depends on the specific requirements of the application and the environment in which it will be deployed. To install Docker Engine, see Install Docker Engine.</p>"},{"location":"classes/containerization/#creating-a-simple-docker","title":"Creating a Simple Docker","text":"Command Description <code>docker run &lt;image&gt;</code> Runs a Docker container from an image. <code>docker ps</code> Lists running Docker containers. <code>docker ps -a</code> Lists all Docker containers, both running and stopped. <code>docker stop &lt;container&gt;</code> Stops a running Docker container. <code>docker rm &lt;container&gt;</code> Removes a Docker container. <code>docker images</code> Lists Docker images. <code>docker rmi &lt;image&gt;</code> Removes a Docker image. <code>docker pull &lt;image&gt;</code> Pulls a Docker image from a Docker registry. <code>docker build -t &lt;tag&gt; .</code> Builds a Docker image from a Dockerfile in the current directory. <code>docker exec -it &lt;container&gt; &lt;command&gt;</code> Executes a command in a running Docker container. <code>docker logs &lt;container&gt;</code> Fetches the logs of a Docker container."},{"location":"classes/containerization/#docker-compose","title":"Docker Compose","text":"<p>Docker Compose is a tool for defining and running multi-container Docker applications - in a declarative language. With Compose, you can use a YAML file to configure your application's services, networks, and volumes, making it easier to manage complex applications. All the services defined in the <code>compose.yaml</code> file can be started with a single command, allowing you to run multiple containers as a single application.</p> compose.yaml<pre><code>name: myapp\n\nservices:\n\n  web:\n    build:\n      dockerfile_inline: |\n        FROM nginx:latest\n        RUN apt update\n        RUN apt install -y net-tools iputils-ping\n    ports:\n      - 80:80\n\n  app:\n    image: eclipse-temurin:25-jdk\n    depends_on:\n      - db\n\n  db:\n    image: postgres:latest\n    environment:\n      POSTGRES_USER: user\n      POSTGRES_PASSWORD: password\n      POSTGRES_DB: mydb\n    volumes:\n      - ${VOLUME}/db:/var/lib/postgresql/data\n    ports:\n      - 5432:5432\n</code></pre> <p>To run the application defined in the <code>compose.yaml</code> file, you can use the following command:</p> <pre><code>docker compose up -d --build # (1)!\n</code></pre> <ol> <li><code>-d</code> runs the containers in detached mode, allowing them to run in the background. <code>--build</code> forces a rebuild of the images before starting the containers.</li> </ol> <p>This command will start all the services defined in the <code>compose.yaml</code> file, creating a subnetwork for them to communicate with each other. You can then access the web service on port 80 of your host machine. The illustration below shows how the services are connected:</p> <pre><code>flowchart LR\n    user[User] --&gt;|HTTP| web[Web]\n    subgraph myapp [172.18.0.0/16]\n        web[Web]\n        app[App]\n        db[(Database)]\n    end\n    web --&gt;|API| app\n    app --&gt;|Connection| db</code></pre> The above diagram illustrates how the user interacts with the web service, which in turn communicates with the application and database services within the defined Docker network. <p>Environment Variables</p> <p>Docker Compose allows you to define environment variables in the <code>compose.yaml</code> file or in a separate <code>.env</code> file. This is useful for passing configuration values, such as database credentials or API keys, to your containers without hardcoding them in the Dockerfile or application code.</p> <p>Therefore, to facilitate the correction, you can pass the environment variables directly in the <code>compose.yaml</code>, which Docker Compose will automatically read and use when starting the containers. Example:</p> compose.yaml<pre><code>name: myapp\n\n  db:\n    image: postgres:latest\n    environment:\n      POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n      POSTGRES_USER: ${POSTGRES_USER:-projeto}\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n    volumes:\n      - ${VOLUME}/db:/var/lib/postgresql/data # (2)!\n    ports:\n      - 5432:5432 #(3)!\n</code></pre> <ol> <li> <p>If the <code>POSTGRES_DB</code> environment variable does not exist or is null - if it is not defined in the <code>.env</code> file - the default value will be <code>project</code>. See documentation.</p> </li> <li> <p>The <code>volumes</code> section maps a directory on the host machine to a directory in the container. This allows data to persist even if the container is removed or recreated. In this example, the <code>db</code> service's data is stored in the <code>${VOLUME}/db</code> directory on the host machine, which is mapped to the <code>/var/lib/postgresql/data</code> directory in the container. This means that any data stored in the database will persist even if the container is stopped or removed.</p> </li> <li> <p>Here, a tunnel is created from the database container's port 5432 to the host's port 5432 (in this case, localhost). In a production environment, this port should not be exposed, as no one outside the compose should access the database directly.</p> </li> </ol> .env<pre><code>POSTGRES_DB=superproject\nPOSTGRES_USER=myproject\nPOSTGRES_PASSWORD=S3cr3t\nVOLUME=/path/to/volume\n</code></pre> <p>When you run <code>docker compose up</code>, Docker Compose will automatically read the <code>.env</code> file in the same directory as the <code>compose.yaml</code> file and use the defined environment variables. If a variable is not defined in the <code>.env</code> file, it will use the default value specified in the <code>compose.yaml</code> file.</p> <p>Security</p> <p>NEVER store sensitive information, such as passwords or API keys, directly in the <code>compose.yaml</code> file or in the code. Instead, use environment variables to pass sensitive information securely.</p> <p>Different environments (development, testing, production) can have different <code>.env</code> files, allowing you to manage configurations without changing the code or the <code>compose.yaml</code> file.</p> <p>NEVER store credentials in the repository, even if it is a private repository. That is, NEVER place a <code>.env</code> file in the repository (GitHub).</p> <p>NEVER leave ports exposed in production unless absolutely necessary.</p> <p>To delivery a project, this could be deployed on-premises, in a private cloud, or in a public cloud. In all these cases, containerization can be used to package and deploy the application consistently across different environments.</p>"},{"location":"classes/containerization/#clouding","title":"Clouding","text":"<p>Containerization is a key technology for cloud computing, as it allows applications to be packaged and deployed in a consistent and portable manner across different cloud environments. Many cloud providers, such as AWS, Google Cloud, and Microsoft Azure, offer managed container services that allow developers to easily deploy and manage containerized applications in the cloud. These services typically provide features such as automatic scaling, load balancing, and integration with other cloud services, making it easier for developers to build and deploy applications in the cloud using containerization.</p> <p>Cloud Course</p> <p>A good course to learn about cloud computing is Computa\u00e7\u00e3o em Nuvem, offered by Insper. This course covers the fundamentals of cloud computing, including cloud architecture, deployment models, and cloud services. It also includes hands-on exercises and projects to help students gain practical experience with cloud technologies.</p> <p>In a cloud environment, it is possible to create virtual machines (VMs) and run Docker containers on them. This allows for greater flexibility and scalability, as you can easily deploy and manage containerized applications in the cloud. Also, these containers run inside of virtual private networks (VPNs), which provide an additional layer of security and isolation for the applications running in the cloud.</p> <p>Containerization offers several benefits that make it an attractive choice for companies:</p> <ol> <li> <p>Portability: Containers encapsulate an application and its dependencies, making it easy to move and run the application across different environments without compatibility issues.</p> </li> <li> <p>Scalability: Containers can be easily scaled up or down to handle varying workloads, allowing companies to efficiently manage resources and meet demand.</p> </li> <li> <p>Efficiency: Containers share the host operating system's kernel, which makes them more lightweight and efficient compared to traditional virtual machines. This allows companies to run more applications on the same hardware.</p> </li> <li> <p>Consistency: Containers provide a consistent environment for applications, ensuring that they run the same way in development, testing, and production environments. This reduces the \"it works on my machine\" problem and improves collaboration between teams.</p> </li> </ol>"},{"location":"classes/containerization/#cost-effectiveness","title":"Cost-effectiveness","text":"<p>Containerization can help companies save costs by reducing the need for expensive hardware and allowing for more efficient use of resources. Containers can run on a shared infrastructure, which can lead to cost savings compared to running applications on dedicated servers or virtual machines. Additionally, container orchestration tools like Kubernetes can help optimize resource allocation and reduce operational costs by automating the deployment and management of containerized applications.</p>"},{"location":"classes/containerization/#data-centers","title":"Data centers","text":"Google AWS Tesla <p> Inside a Google data center</p> <p></p> <p> Inside Amazon's Massive Data Center</p> <p></p> <p> Inside Elon Musk's Colossus Supercomputer!</p> <p></p>"},{"location":"classes/containerization/#exercises","title":"Exercises","text":"<ol> <li> <p>What are the main differences between Docker containers and virtual machines? Provide examples of use cases where each technology would be more suitable.</p> </li> <li> <p>How does Docker Compose facilitate the management of multi-container applications? Provide an example of a <code>compose.yaml</code> file for a simple web application with a database.</p> </li> <li> <p>Try to run a simple <code>compose.yaml</code> file:</p> compose.yaml<pre><code>name: myapp\n\nservices:\n\n  web:\n    build:\n      dockerfile_inline: |\n        FROM nginx:latest\n        RUN apt update\n        RUN apt install -y net-tools iputils-ping\n    ports:\n      - 80:80\n\n  app:\n    image: eclipse-temurin:25-jdk\n    depends_on:\n      - db\n\n  db:\n    image: postgres:latest\n    environment:\n      POSTGRES_USER: user\n      POSTGRES_PASSWORD: password\n      POSTGRES_DB: mydb\n    volumes:\n      - ${VOLUME}/db:/var/lib/postgresql/data\n    ports:\n      - 5432:5432\n</code></pre> <p>Then, access the web service on port 80 of your host machine and verify that it is working correctly. If you encounter any issues, check the logs of the containers using <code>docker logs &lt;container&gt;</code> and troubleshoot accordingly.</p> </li> </ol> <ol> <li> <p>Docker vs. Virtual Machines: Differences You Should Know \u21a9</p> </li> <li> <p>Docker Networking \u21a9</p> </li> </ol>"},{"location":"classes/devops/","title":"Index","text":"<p>DevOps is a set of practices that combines software development (Dev) and IT operations (Ops). It aims to shorten the system development life cycle and provide continuous delivery with high software quality. DevOps is complementary with Agile software development; several DevOps aspects came from Agile methodology.</p> <p>Key concepts of DevOps include:</p> <ul> <li>Continuous Integration (CI): Developers regularly merge their code changes into a central repository, after which automated builds and tests are run.</li> <li>Continuous Delivery (CD): The combined practices of continuous integration and automated testing allow for the continuous delivery of code changes to a staging or production system.</li> <li>Infrastructure as Code (IaC): Infrastructure is defined and managed using code and software development techniques, such as version control and continuous integration.</li> <li>Monitoring and Logging: Keeping track of how applications and systems are performing in real-time to understand ongoing IT infrastructure status.</li> <li>Communication and Collaboration: Increased communication and collaboration in an organization is one of the key cultural aspects of DevOps. The use of DevOps tooling and automation of the software delivery process tends to increase collaboration between the teams.</li> </ul> <p></p> <p> </p> Source: Wikipedia - Devops"},{"location":"classes/devops/#cicd","title":"CI/CD","text":""},{"location":"classes/devops/#pipeline","title":"Pipeline","text":""},{"location":"classes/devops/#service-level-agreement-sla","title":"Service-level agreement - SLA","text":"<p>Service-level agreement, well-known as SLA, is </p>"},{"location":"classes/devops/#other-approaches","title":"Other Approaches","text":""},{"location":"classes/devops/#noops","title":"NoOps","text":"<p>NoOps, short for \"No Operations\", is a concept in software development where the software is designed in such a way that it requires minimal or even no IT operations support. This is often achieved through the use of fully automated processes and systems, which eliminate the need for manual intervention in tasks such as deployment, scaling, and systems management.</p> <p>The goal of NoOps is to allow the software developers to focus on writing new features for the application, rather than spending time on operational concerns. This is often achieved through the use of Platform as a Service (PaaS) providers, which handle many of the operational tasks automatically.</p> <p>https://www.jenkins.io/doc/tutorials/build-a-java-app-with-maven/</p> <p>Jenkins</p> <p>Install plugins: - Blue Ocean - Docker - Docker Pipeline - Kubernetes Cli</p> <p>https://www.jenkins.io/doc/tutorials/build-a-java-app-with-maven/</p> <p>https://www.jenkins.io/blog/2017/02/07/declarative-maven-project/</p> <ol> <li> <p>Wiki Service-level Agreement \u21a9</p> </li> </ol>"},{"location":"classes/devops/docker/","title":"Docker","text":"<p>How to avoid the classical..</p> <p></p> <p>?</p> <p>The answer is: CONTAINERIZATION.</p> <p>Docker is a platform and tool that enables developers to automate the deployment of applications inside lightweight, portable containers. Containers are a form of virtualization that packages an application and its dependencies together, ensuring consistency across different environments, from development to testing and production.</p> <p>Here are some key concepts and components of Docker:</p> <ul> <li>Containerization: Containers are lightweight, standalone, and executable packages that include everything needed to run a piece of software, including the code, runtime, libraries, and system tools. Containers isolate applications from their environment, making them portable and consistent across various systems.</li> <li>Docker Engine: This is the core component of Docker. It is a lightweight and portable runtime that can run containers on various operating systems, including Linux and Windows. The Docker Engine consists of a server, a REST API, and a command-line interface.</li> <li>Docker Image: An image is a lightweight, standalone, and executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and config files. Images are used to create containers.</li> <li>Dockerfile: A Dockerfile is a text file that contains instructions for building a Docker image. It specifies the base image, sets up the environment, installs dependencies, and configures the application.</li> <li>Registry: Docker images can be stored in registries, which are repositories for sharing and distributing container images. Docker Hub is a popular public registry, and organizations often use private registries to store and manage their proprietary images.</li> <li>Container Orchestration: Docker can be used in conjunction with container orchestration tools like Kubernetes or Docker Swarm to manage the deployment, scaling, and orchestration of containerized applications in production environments.</li> <li>Portability: One of Docker's key advantages is its portability. Since containers encapsulate everything an application needs to run, they can run consistently across different environments, reducing the \"it works on my machine\" problem often encountered in software development.</li> </ul> <p>Docker has become a widely adopted technology in the software development and deployment space due to its ease of use, portability, and the efficiency it brings to the development and deployment lifecycle. It has revolutionized the way applications are packaged, shipped, and deployed, making it easier for developers to build, test, and deploy applications in a more reliable and consistent manner.</p>"},{"location":"classes/devops/docker/#differences-between-docker-and-virtual-machines","title":"Differences between Docker and Virtual Machines","text":"<p>Docker containers and virtual machines (VMs) are both technologies used for virtualization, but they operate at different levels and have distinct characteristics. Here are the key differences between Docker containers and virtual machines:</p> Aspect Docker Containers Virtual Machines Architecture Containers share the host operating system's kernel and isolate the application processes from each other. Each container runs in its own user space but uses the host's kernel. VMs, on the other hand, run a complete operating system, including its own kernel, on top of a hypervisor. Each VM is essentially a full-fledged virtualized computer with its own resources. Resource Efficiency Containers are more lightweight and share the host OS kernel, which makes them more resource-efficient compared to VMs. Containers can start up quickly and consume fewer system resources. VMs have more overhead because each VM requires a full operating system and has its own kernel. This makes VMs less resource-efficient than containers. Isolation Containers provide process-level isolation, meaning that each container runs in its own process space, but they share the same OS kernel. This isolation is generally sufficient for most applications. VMs provide stronger isolation since each VM runs its own operating system and has its own kernel. This makes VMs a better choice in situations where strong isolation is a critical requirement. Portability Containers are highly portable because they encapsulate the application and its dependencies, ensuring consistency across different environments. VMs are less portable due to the larger size and complexity associated with bundling a full operating system with the application. Startup Time Containers can start up very quickly, typically in seconds, making them well-suited for microservices architectures and dynamic scaling. VMs generally have longer startup times, often measured in minutes, due to the time required to boot a full operating system. Resource Utilization Containers share the host OS resources, which can lead to higher density and more efficient resource utilization. VMs have a higher resource overhead because each VM requires its own set of resources, including memory, disk space, and CPU. Use Cases Containers are well-suited for microservices architectures, continuous integration/continuous deployment (CI/CD) pipelines, and scenarios where rapid deployment and scalability are crucial. VMs are suitable for scenarios that require strong isolation, compatibility with various operating systems, and where applications rely on specific OS configurations. <p> </p> Source: Docker vs. Virtual Machines: Differences You Should Know <p>In summary, Docker containers and virtual machines have different levels of abstraction and are suitable for different use cases. Containers are lightweight, portable, and efficient, making them popular for modern application development and deployment practices. Virtual machines provide stronger isolation and are more suitable for scenarios where running multiple instances of different operating systems is necessary. The choice between Docker containers and virtual machines depends on the specific requirements of the application and the environment in which it will be deployed. To install Docker Engine, see Install Docker Engine.</p>"},{"location":"classes/devops/docker/#creating-a-simple-docker","title":"Creating a Simple Docker","text":"Command Description <code>docker run &lt;image&gt;</code> Runs a Docker container from an image. <code>docker ps</code> Lists running Docker containers. <code>docker ps -a</code> Lists all Docker containers, both running and stopped. <code>docker stop &lt;container&gt;</code> Stops a running Docker container. <code>docker rm &lt;container&gt;</code> Removes a Docker container. <code>docker images</code> Lists Docker images. <code>docker rmi &lt;image&gt;</code> Removes a Docker image. <code>docker pull &lt;image&gt;</code> Pulls a Docker image from a Docker registry. <code>docker build -t &lt;tag&gt; .</code> Builds a Docker image from a Dockerfile in the current directory. <code>docker exec -it &lt;container&gt; &lt;command&gt;</code> Executes a command in a running Docker container. <code>docker logs &lt;container&gt;</code> Fetches the logs of a Docker container. <p>Hello Markdown!</p> pip install termynalInstalled <pre><code>FROM openjdk:17-alpine\nVOLUME /tmp\nARG JAR_FILE=target/gateway-0.0.1-SNAPSHOT.jar\nCOPY ${JAR_FILE} app.jar\nENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]\n</code></pre> <p>https://docs.docker.com/engine/install/</p> <p>https://www.docker.com/blog/how-to-use-your-own-registry-2/</p> <ol> <li> <p>Docker vs. Virtual Machines: Differences You Should Know \u21a9</p> </li> </ol>"},{"location":"classes/devops/packaging/","title":"Packaging","text":""},{"location":"classes/devops/packaging/#maven","title":"Maven","text":"<p>Maven uses an XML file to describe the software project being built, its dependencies on other external modules and components, the build order, directories, and required plugins. It comes with pre-defined targets for performing certain well-defined tasks such as compilation of code and its packaging.</p> <p>Key Features: - Simple project setup that follows best practices. - Dependency management including automatic updating, dependency closures (also known as transitive dependencies) - Able to easily work with multiple projects at the same time. - Large and mature community with a large ecosystem of plugins and integrations.</p> <pre><code>mvn clean package\n</code></pre> <pre><code>mvn clean install\n</code></pre> <pre><code>mvn clean package spring-boot:run\n</code></pre> <pre><code>mvn versions:display-dependency-updates\n</code></pre> <pre><code>mvn dependency:analyze\n</code></pre> <p>more about Maven dependency plugin</p>"},{"location":"classes/devops/packaging/#gradle","title":"Gradle","text":"<p>Gradle is another build automation tool that builds upon the concepts of Apache Ant and Apache Maven and introduces a Groovy-based domain-specific language (DSL) instead of the XML form used by Apache Maven for declaring the project configuration. Gradle provides a platform to support the entire development lifecycle of a software project.</p> <p>Key Features: - Declarative builds and build-by-convention. - Language for dependency-based programming. - Structure your build. - Deep API. - Multi-project builds. - Many ways to manage dependencies. - Integration with existing structures. - Ease of migration.</p>"},{"location":"classes/distributed_systems/","title":"1. Distributed Systems","text":"<p>Distributed systems represent a paradigm in computing where multiple independent computers or nodes collaborate to achieve a common goal, appearing as a single coherent system to the end-user. Unlike centralized systems, where all processing occurs on a single machine, distributed systems span across networks, leveraging interconnected nodes to handle tasks such as data storage, computation, and communication. This architecture has become foundational in modern computing, powering everything from cloud services like Amazon Web Services (AWS) and Google Cloud to large-scale applications such as social networks, e-commerce platforms, and scientific simulations.</p> <p>Understanding distributed systems requires grasping both theoretical foundations and practical implementations. Key concepts include node autonomy, where each component operates independently yet coordinates with others; message passing as the primary communication mechanism; and the inherent challenges of asynchrony, where there are no global clocks or guaranteed message delivery times. Pioneering work in this field dates back to the 1970s and 1980s, with contributions from researchers like Leslie Lamport (who introduced concepts like logical clocks<sup>1</sup>) and the development of systems like ARPANET, which evolved into the internet.</p> <p>Distributed systems can be classified based on various criteria:</p> <ul> <li>homogeneous vs. heterogeneous (uniform hardware/software vs. diverse);</li> <li>tightly coupled vs. loosely coupled (high interdependence vs. loose integration);</li> <li>and client-server vs. peer-to-peer (hierarchical vs. egalitarian structures). For instance, a client-server model is evident in web applications, where browsers (clients) request data from servers, while peer-to-peer systems like BitTorrent distribute file sharing across equal nodes.</li> </ul>"},{"location":"classes/distributed_systems/#advantages-of-distributed-systems","title":"Advantages of Distributed Systems","text":"<p>Distributed systems offer several compelling benefits, making them indispensable for handling the scale and demands of contemporary applications.</p> <ol> <li> <p>Scalability: One of the primary advantages is the ability to scale horizontally by adding more nodes, rather than vertically upgrading a single machine. This is crucial for handling growing workloads. For example, in a distributed database like Apache Cassandra, new nodes can be added seamlessly to increase storage and throughput, allowing systems to manage petabytes of data and millions of queries per second.</p> </li> <li> <p>Fault Tolerance and Reliability: By distributing tasks across multiple nodes, the system can continue functioning even if some nodes fail. Techniques like replication (storing data copies on multiple nodes) and redundancy ensure high availability. In practice, systems like Google's Spanner use synchronous replication across data centers to achieve fault tolerance, minimizing downtime to near-zero levels.</p> </li> <li> <p>Resource Sharing and Efficiency: Distributed systems enable efficient utilization of resources across geographies. Users can access shared resources like printers, files, or computational power remotely. In grid computing, for instance, idle resources from thousands of machines are pooled for tasks like protein folding simulations in projects such as Folding@home.</p> </li> <li> <p>Performance through Parallelism: Tasks can be parallelized across nodes, reducing execution time. MapReduce, popularized by Hadoop, exemplifies this by dividing large datasets into smaller chunks processed in parallel, then aggregating results\u2014ideal for big data analytics.</p> </li> <li> <p>Geographical Distribution and Latency Reduction: Nodes can be placed closer to users, reducing latency. Content Delivery Networks (CDNs) like Akamai distribute web content globally, ensuring faster load times by serving data from the nearest edge server.</p> </li> </ol> <p>These advantages stem from the principle of modularity, where the system can evolve incrementally without overhauling the entire infrastructure.</p>"},{"location":"classes/distributed_systems/#disadvantages-of-distributed-systems","title":"Disadvantages of Distributed Systems","text":"<p>Despite their strengths, distributed systems introduce significant challenges that complicate design, implementation, and maintenance.</p> <ol> <li> <p>Increased Complexity: Managing coordination among nodes is inherently complex. Developers must handle issues like synchronization, concurrency, and distributed state management. For example, ensuring atomic operations across nodes requires sophisticated protocols, leading to higher development costs and bug-prone code. The \"fallacies of distributed computing\" outlined by Peter Deutsch highlight misconceptions, such as assuming the network is reliable or latency is zero, which often lead to system failures.</p> </li> <li> <p>Network Dependencies and Overhead: Communication over networks introduces latency, bandwidth limitations, and potential failures. Messages can be delayed, lost, or duplicated, necessitating retry mechanisms and error handling. In high-latency environments, like intercontinental data centers, this can degrade performance significantly compared to local systems.</p> </li> <li> <p>Consistency and Synchronization Challenges: Maintaining data consistency across nodes is non-trivial. Without a single point of truth, conflicts arise during concurrent updates. This ties into theoretical limits, as we'll discuss with the CAP theorem below.</p> </li> <li> <p>Security Vulnerabilities: Distributed systems expand the attack surface. Securing communication channels (e.g., via TLS encryption), authenticating nodes, and preventing unauthorized access become critical. Issues like Byzantine faults\u2014where nodes behave maliciously\u2014require robust protocols like Practical Byzantine Fault Tolerance (PBFT), used in blockchain systems.</p> </li> <li> <p>Higher Operational Costs: Monitoring, debugging, and maintaining distributed systems demand specialized tools and expertise. Tools like Prometheus for monitoring or Kubernetes for orchestration add layers of complexity. Failures can cascade (e.g., the \"thundering herd\" problem where many nodes retry simultaneously), leading to outages that are harder to diagnose than in monolithic systems.</p> </li> </ol> <p>In summary, while distributed systems excel in scale, their cons often manifest as trade-offs in reliability and manageability, requiring careful architectural choices.</p>"},{"location":"classes/distributed_systems/#key-concepts-in-distributed-systems-highlighting-the-cap-theorem","title":"Key Concepts in Distributed Systems: Highlighting the CAP Theorem","text":"<p>Several foundational theorems and algorithms underpin distributed systems. Here, it will highlight the CAP Theorem, a cornerstone concept, while touching on related subjects for context.</p>"},{"location":"classes/distributed_systems/#the-cap-theorem","title":"The CAP Theorem","text":"<p>The CAP Theorem<sup>4</sup>, proposed by Eric Brewer in 2000 and formally proven by Seth Gilbert and Nancy Lynch in 2002, states that in a distributed system with replicated data, it is impossible to simultaneously guarantee all three of the following properties:</p> <p></p> <ul> <li> <p>Consistency (C): Every read operation receives the most recent write or an error. In other words, all nodes see the same data at the same time, akin to linearizability in concurrent programming. For example, in a banking system, consistency ensures that account balances are up-to-date across all replicas.</p> </li> <li> <p>Availability (A): Every request receives a non-error response, without guarantee that it contains the most recent write. The system remains operational as long as at least one node is functioning, even during failures.</p> </li> <li> <p>Partition Tolerance (P): The system continues to operate despite arbitrary network partitions (message drops or delays between nodes). Partitions are inevitable in real-world networks due to hardware failures, congestion, or geographic distances.</p> </li> </ul> <p>According to the theorem, a distributed system can provide at most two of these guarantees during a network partition. This forces designers to make explicit trade-offs:</p> <ul> <li> <p>CP Systems (Consistent and Partition-Tolerant): Prioritize consistency over availability. During partitions, the system may become unavailable to ensure data accuracy. Examples include traditional relational databases like PostgreSQL in distributed modes or MongoDB in CP configurations. In a CP system, writes might be rejected if they can't be propagated to all replicas.</p> </li> <li> <p>AP Systems (Available and Partition-Tolerant): Favor availability, allowing \"eventual consistency\" where nodes may temporarily diverge but converge over time. Amazon's DynamoDB and Apache Cassandra are AP systems, using techniques like anti-entropy (background reconciliation) and hinted handoffs to resolve inconsistencies post-partition.</p> </li> <li> <p>CA Systems (Consistent and Available): These assume no partitions, which is unrealistic in distributed networks. They are more akin to single-node systems or clusters on reliable LANs, like some in-memory caches.</p> </li> </ul> <p>The CAP Theorem has profound implications for system design. It underscores that \"perfect\" distributed systems don't exist; instead, engineers must choose based on application needs. For instance, in e-commerce, availability might trump strict consistency (e.g., showing slightly outdated stock levels), while in financial transactions, consistency is paramount.</p> <p>Critiques and extensions of CAP include the PACELC theorem by Daniel Abadi (2010), which expands on CAP by considering latency (L) and consistency (C) in non-partitioned scenarios: systems must trade off between consistency and low latency even without partitions.</p>"},{"location":"classes/distributed_systems/#related-subjects","title":"Related Subjects","text":"<p>To contextualize CAP, consider these interconnected topics:</p> <ul> <li> <p>Consensus Algorithms: Achieving agreement among nodes despite failures is key to consistency. Paxos<sup>2</sup> (Lamport, 1998) provides a protocol for consensus in asynchronous systems, tolerating up to half the nodes failing non-Byzantine. Raft (Ongaro and Ousterhout, 2014) simplifies Paxos for practical use, as seen in etcd and Consul. These algorithms help in leader election and state replication, directly addressing CAP trade-offs.</p> </li> <li> <p>Eventual Consistency Models: In AP systems, models like Causal Consistency (ensuring operations respect causality) or Conflict-Free Replicated Data Types (CRDTs) allow merges without coordination. For example, Riak uses vector clocks to track versions and resolve conflicts.</p> </li> <li> <p>Distributed Databases and File Systems: Systems like Google Bigtable (CP-oriented) or HDFS (Hadoop Distributed File System) illustrate CAP in action. Bigtable prioritizes consistency for structured data, while HDFS focuses on availability for massive storage.</p> </li> <li> <p>Quorum Systems: To balance C and A, quorums require a majority of nodes to agree on operations. In a system with N replicas, writes might need W acknowledgments and reads R, where W + R &gt; N ensures consistency.</p> </li> <li> <p>Failure Models: Distributed systems model failures as crash-stop (nodes halt), crash-recovery (nodes restart), or Byzantine (arbitrary behavior). The FLP Impossibility Theorem (Fischer, Lynch, Paterson, 1985) proves that consensus is impossible in asynchronous systems with even one faulty node, leading to practical approximations like timeouts.</p> </li> </ul>"},{"location":"classes/distributed_systems/#practical-considerations","title":"Practical Considerations","text":"<p>In practice, designing distributed systems involves tools like ZooKeeper for coordination, Kafka for messaging, and microservices architectures for modularity. Testing is challenging; tools like Jepsen simulate partitions to verify CAP compliance.</p> <p>Looking ahead, emerging trends include edge computing (distributing to devices), serverless architectures (e.g., AWS Lambda), and blockchain for decentralized trust. Quantum networking may introduce new paradigms, but CAP's fundamental limits will persist.</p> <p>In conclusion, distributed systems embody a delicate balance of power and peril. Their pros enable unprecedented scale, but cons demand rigorous engineering. The CAP Theorem exemplifies this, reminding us that trade-offs are inevitable\u2014choose wisely based on your domain.</p> <ol> <li> <p>Lamport's Logical Clocks: A method for ordering events in a distributed system without relying on synchronized physical clocks, using a logical timestamp to capture causality between events.\u00a0\u21a9</p> </li> <li> <p>Paxos Algorithm: A consensus algorithm that allows a collection of nodes to agree on a single value even in the presence of failures, ensuring consistency in distributed systems.\u00a0\u21a9</p> </li> <li> <p>Raft Consensus Algorithm: A consensus algorithm designed to be more understandable than Paxos, providing a practical solution for achieving consensus in distributed systems, often used in systems like etcd and Consul for leader election and state replication.\u00a0\u21a9</p> </li> <li> <p>CAP Theorem: A fundamental principle in distributed systems that states it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees: Consistency, Availability, and Partition Tolerance.\u00a0\u21a9</p> </li> <li> <p>PACELC Theorem: An extension of the CAP theorem that considers latency (L) and consistency (C) in non-partitioned scenarios, highlighting trade-offs even when the system is not experiencing partitions.\u00a0\u21a9</p> </li> </ol>"},{"location":"classes/microservices/","title":"3. Microservices","text":"<p>Microservices, also known as the microservices architecture, is an architectural style that structures an application as a collection of small autonomous services, modeled around a business domain.</p> <p>Key concepts of microservices include:</p> <ul> <li>Single Responsibility: Each microservice should have a single responsibility and should implement a single business capability.</li> <li>Independence: Microservices should be able to run and evolve independently of each other. They should be independently deployable and scalable.</li> <li>Decentralization: Microservices architecture favors decentralized governance. Teams have the freedom to choose the best technology stack that suits their service.</li> <li>Isolation of Failures: If a microservice fails, it should not impact the availability of other services.</li> <li>Data Isolation: Each microservice should have its own database to ensure that the services are loosely coupled and can evolve independently.</li> <li>Communication: Microservices communicate with each other through well-defined APIs and protocols, typically HTTP/REST with JSON<sup>4</sup><sup>5</sup> or gRPC with Protobuf.</li> <li>Infrastructure Automation: Due to the distributed nature of the microservices architecture, automation of infrastructure is a must. This includes automated provisioning, scaling, and deployment.</li> <li>Observability: With many different services, it's important to have excellent monitoring and logging to detect and diagnose problems.</li> </ul>"},{"location":"classes/microservices/#domain-driven-design","title":"Domain Driven Design","text":"<p>Domain-Driven Design (DDD) is a software development approach that emphasizes collaboration between technical experts and domain experts. The goal is to create software that is a deep reflection of the underlying domain, which is the specific area of business or activity that the software is intended to support.</p> <p>Key concepts of DDD include:</p> <ul> <li>Ubiquitous Language: A common language established between developers and domain experts, used to describe all aspects of the domain.</li> <li>Bounded Context: A boundary within which a particular model is defined and applicable.</li> <li>Entities: Objects that have a distinct identity that persists over time and across different representations.</li> <li>Value Objects: Objects that are defined by their attributes, not their identity.</li> <li>Aggregates: Clusters of entities and value objects that are treated as a single unit.</li> <li>Repositories: They provide a way to obtain references to aggregates.</li> <li>Domain Events: Events that domain experts care about.</li> <li>Services: Operations that don't naturally belong to any entity or value object.</li> </ul> <p>By focusing on the domain and domain logic, DDD provides techniques to develop complex systems targeting real-world scenarios. It helps to reduce the complexity by dividing the system into manageable and interconnected parts.</p>"},{"location":"classes/microservices/#best-practices","title":"Best Practices","text":"Source: System Design 101 - Microservice Architecture"},{"location":"classes/microservices/#typical-microservices-architecture","title":"Typical Microservices Architecture","text":"Source: System Design 101 - Microservice Architecture <p>Components of a typical microservices architecture include:</p> <ul> <li> <p>Load Balancer: Distributes incoming network traffic across multiple servers to ensure no single server becomes overwhelmed.</p> </li> <li> <p>CDN (Content Delivery Network): A geographically distributed network of servers that delivers content to users based on their location, improving performance and availability.</p> </li> <li> <p>API Gateway: Acts as a single entry point for all clients, routing requests to the appropriate microservices and handling cross-cutting concerns such as authentication, logging, and rate limiting.</p> </li> <li> <p>Identity Provider: Manages user authentication and authorization, often using protocols like OAuth2 or OpenID Connect.</p> </li> <li> <p>Service Discovery &amp; Registry: Allows microservices to find and communicate with each other without hardcoding their network locations.</p> </li> <li> <p>Configuration Service: Centralizes the management of configuration settings for all microservices, allowing for dynamic updates without redeploying services.</p> </li> <li> <p>Microservices: Independent services that implement specific business capabilities, communicating with each other through APIs.</p> </li> </ul>"},{"location":"classes/microservices/#our-microservices-architecture","title":"Our Microservices Architecture","text":"<p>The proposed architecture for our microservices will be based on the principles of Domain-Driven Design (DDD) and will follow the Clean Architecture pattern. Each microservice will be designed to have a single responsibility, and we will ensure that they are loosely coupled and independently deployable. We will also implement a robust API Gateway to handle client requests and route them to the appropriate microservices. Additionally, we will use a service discovery mechanism to allow microservices to find and communicate with each other without hardcoding their network locations. Finally, we will implement monitoring and logging to ensure that we can detect and diagnose problems effectively in our distributed system. A diagram of the proposed architecture is shown below.</p> <pre><code>flowchart LR\n  subgraph client[\"Internet\"]\n    direction LR\n    Web\n    Mobile\n    Desktop\n  end\n  subgraph Trusted Layer\n    direction LR\n    lb([\"Load Balance\"])\n    gateway[\"Gateway\"]\n    auth[\"Auth\"]\n    subgraph bm [\"Business Microservice\"]\n      direction LR\n      ms1[\"Service 1\"]\n      ms2[\"Service 2\"]\n      ms3[\"Service 3\"]\n      db1[(\"Database 1\")]\n      db2[(\"Database 2\")]\n    end\n  end\n  subgraph third-party[\"Third-Party API\"]\n    direction LR\n    tp1[\"Third-Party Service\"]\n  end\n  client --&gt; lb --&gt; gateway\n  gateway --&gt; ms1\n  gateway --&gt; ms2\n  gateway --&gt; ms3\n  ms1 --&gt; db1\n  ms2 --&gt; db2\n  ms2 --&gt; ms3\n  ms3 --&gt; tp1\n  gateway --&gt; auth</code></pre> <ol> <li> <p>XU, A., System Design 101: A comprehensive guide to system design, covering various architectural patterns, including microservices. It provides insights into best practices, trade-offs, and real-world examples to help developers design scalable and maintainable systems.\u00a0\u21a9</p> </li> <li> <p>Wikipedia - Domain Driven Design: A software development approach that emphasizes collaboration between technical experts and domain experts to create software that is a deep reflection of the underlying domain. It provides techniques to develop complex systems targeting real-world scenarios by focusing on the domain and domain logic.\u00a0\u21a9</p> </li> <li> <p>Domain-Driven Design Reference: A comprehensive reference for Domain-Driven Design, covering all the key concepts and patterns in detail. It serves as a valuable resource for developers and architects looking to implement DDD in their projects.\u00a0\u21a9</p> </li> <li> <p>RFC 7159: The application/json Media Type for JavaScript Object Notation (JSON).\u00a0\u21a9</p> </li> <li> <p>JSON: JSON (JavaScript Object Notation) is a lightweight data-interchange format that is easy for humans to read and write, and easy for machines to parse and generate. It is based on a subset of the JavaScript Programming Language, Standard ECMA-262 3rd Edition - December 1999. JSON is a text format that is completely language independent but uses conventions that are familiar to programmers of the C-family of languages, including C, C++, C#, Java, JavaScript, Perl, Python, and many others. These properties make JSON an ideal data-interchange language.\u00a0\u21a9</p> </li> </ol>"},{"location":"classes/microservices/microservice-diagram/","title":"Microservice diagram","text":"<pre><code>flowchart LR\n  subgraph client[\"Internet\"]\n    direction LR\n    Web\n    Mobile\n    Desktop\n  end\n  subgraph Trusted Layer\n    direction LR\n    lb([\"Load Balance\"])\n    gateway[\"Gateway\"]\n    auth[\"Auth\"]\n    subgraph bm [\"Business Microservice\"]\n      direction LR\n      ms1[\"Service 1\"]\n      ms2[\"Service 2\"]\n      ms3[\"Service 3\"]\n      db1[(\"Database 1\")]\n      db2[(\"Database 2\")]\n    end\n  end\n  subgraph third-party[\"Third-Party API\"]\n    direction LR\n    tp1[\"Third-Party Service\"]\n  end\n  client --&gt; lb --&gt; gateway\n  gateway --&gt; ms1\n  gateway --&gt; ms2\n  gateway --&gt; ms3\n  ms1 --&gt; db1\n  ms2 --&gt; db2\n  ms2 --&gt; ms3\n  ms3 --&gt; tp1\n  gateway --&gt; auth</code></pre>"},{"location":"classes/orchestration/","title":"Index","text":""},{"location":"classes/paas/","title":"Index","text":""},{"location":"classes/reliability/","title":"Index","text":"<p>Reliability is a critical aspect of modern software systems, ensuring that services remain available, performant, and trustworthy for users. Central to managing reliability are three key concepts: Service Level Indicators (SLIs), Service Level Objectives (SLOs), and Service Level Agreements (SLAs). This document provides a comprehensive overview of these concepts, their definitions, interrelationships, and practical applications.</p>"},{"location":"classes/reliability/#1-core-definitions","title":"1. Core Definitions","text":"Term Full Name Definition SLI Service Level Indicator A measurable metric that reflects the actual performance or quality of a service. SLO Service Level Objective A target value or range for an SLI that the team commits to achieve. SLA Service Level Agreement A formal contract between a service provider and a customer that defines the expected level of service, usually expressed via SLOs and consequences for missing them."},{"location":"classes/reliability/#2-in-depth-breakdown","title":"2. In-Depth Breakdown","text":""},{"location":"classes/reliability/#sli-the-raw-measurement","title":"SLI \u2013 The Raw Measurement","text":"<ul> <li>What it is: A quantitative metric pulled from logs, monitoring systems, or instrumentation.</li> <li>Examples:<ul> <li>Availability: <code>% of successful HTTP requests</code> (e.g., 200 OK responses)</li> <li>Latency: <code>95th percentile request latency &lt; 200 ms</code></li> <li>Error rate: <code>Errors per second / Total requests per second</code></li> <li>Throughput: <code>Requests per second (RPS)</code></li> <li>Durability: <code>% of data writes acknowledged by 3+ replicas</code></li> </ul> </li> <li>Key properties:<ul> <li>Objective (not subjective)</li> <li>Directly measurable</li> <li>Relevant to user experience</li> </ul> </li> <li>How it's collected:<ul> <li>Prometheus exporters, OpenTelemetry, Cloud monitoring, application logs, synthetic probes.</li> </ul> </li> </ul>"},{"location":"classes/reliability/#slo-the-target-you-commit-to","title":"SLO \u2013 The Target You Commit To","text":"<ul> <li>What it is: A specific, time-bound target for an SLI.</li> <li>Format: <code>SLI \u2265 threshold</code> over a rolling window (e.g., 28 days).</li> <li>Examples:<ul> <li>Availability SLO: <code>99.9%</code> of requests return 200 OK in a 28-day window.</li> <li>Latency SLO: <code>95th percentile latency \u2264 150 ms</code> over 28 days.</li> <li>Error Budget: Allowed error = <code>100% \u2013 99.9% = 0.1%</code> \u2192 ~43 minutes downtime/month.</li> </ul> </li> <li>Error Budget = <code>1 \u2013 SLO target</code><ul> <li>Drives reliability decisions: If budget is consumed \u2192 stop features, focus on stability.</li> </ul> </li> </ul>"},{"location":"classes/reliability/#sla-the-contractual-commitment","title":"SLA \u2013 The Contractual Commitment","text":"<ul> <li>What it is: A legal/business agreement with penalties (credits, refunds) if SLOs are breached.</li> <li>Structure:<ul> <li>List of SLOs</li> <li>Measurement period</li> <li>Exclusions (maintenance, force majeure)</li> <li>Remedies (service credits)</li> </ul> </li> <li>Example:     &gt; \"Provider guarantees 99.95% monthly uptime. If below, customer receives 10% credit for that month.\"</li> <li>SLA \u2260 SLO: SLA is external, SLO is internal target (often stricter than SLA to provide buffer).</li> </ul>"},{"location":"classes/reliability/#3-how-sli-slo-sla-connect-the-reliability-stack","title":"3. How SLI \u2192 SLO \u2192 SLA Connect (The Reliability Stack)","text":"<pre><code>flowchart TD\n    A(\"SLI: Measurable Metric&lt;br&gt;&lt;small&gt;e.g., % successful requests&lt;/small&gt;\") --&gt; B(\"SLO: Target Value&lt;br&gt;&lt;small&gt;Internal target&lt;br&gt;(e.g., 99.99% uptime)&lt;/small&gt;\")\n    B --&gt; C(\"SLA: Formal Agreement&lt;br&gt;&lt;small&gt;External contract&lt;br&gt;(e.g., 99.95% uptime)&lt;/small&gt;\")\n    C --&gt; D[Customer Expectations]\n    B --&gt; E[Error Budget Management]\n    A --&gt; F[Monitoring &amp; Alerting]</code></pre>"},{"location":"classes/reliability/#flow","title":"Flow:","text":"<ol> <li>Choose SLIs \u2192 What matters to users?</li> <li>Set SLOs \u2192 What can we realistically achieve?</li> <li>Define SLA \u2192 What do we promise customers? (usually looser than SLO)</li> </ol> <p>Best Practice: <code>SLO &gt; SLA</code> \u2192 gives error budget buffer to avoid penalties.</p>"},{"location":"classes/reliability/#4-roles-responsibilities","title":"4. Roles &amp; Responsibilities","text":"Role Works with SLI? Works with SLO? Works with SLA? Primary Tasks SRE (Site Reliability Engineer) \u2705 Yes \u2705 Yes \u26a0\ufe0f Indirectly - Define &amp; monitor SLIs- Propose &amp; defend SLOs- Manage error budgets- Alerting &amp; incident response Product Manager \u26a0\ufe0f Reviews \u2705 Yes \u26a0\ufe0f Reviews - Align SLOs with user needs- Balance features vs reliability- Approve risk during error budget spend Engineering / Dev Team \u2705 Yes \u2705 Yes No - Instrument code for SLIs- Fix issues consuming error budget- Ship features within budget DevOps / Platform Team \u2705 Yes \u26a0\ufe0f Indirectly No - Build monitoring pipelines- Export SLIs to dashboards- Automate SLO compliance checks Customer Success / Account Manager No No \u2705 Yes - Explain SLA to customers- Handle credit requests- Report SLA compliance Legal / Contracts Team No No \u2705 Yes - Draft &amp; negotiate SLA terms- Define exclusions, remedies Leadership (CTO, VP Eng) \u26a0\ufe0f Reviews \u2705 Yes \u2705 Yes - Approve SLO targets- Sign off on SLA commitments- Strategic reliability goals"},{"location":"classes/reliability/#5-real-world-example-web-service","title":"5. Real-World Example (Web Service)","text":"Component Value SLI <code>% of HTTP requests returning 2xx/3xx in &lt; 500ms</code> SLO <code>99.9%</code> over 28-day rolling window Error Budget <code>0.1%</code> \u2192 ~43 min/month allowed failure SLA <code>99.5%</code> monthly \u2192 if missed, 15% credit <p>\u2192 Team monitors SLI daily, uses error budget to decide:  </p> <p>\"We have 10 min left this month \u2192 no new deploys until stabilized.\"</p>"},{"location":"classes/reliability/#6-key-best-practices","title":"6. Key Best Practices","text":"Practice Why SLIs must reflect user experience Avoid vanity metrics (e.g., CPU \u2260 happiness) SLOs should be ambitious but achievable Too tight \u2192 constant alerts; too loose \u2192 no pressure Error budgets drive product decisions Google SRE: \"If no budget left, reliability &gt; features\" SLA &lt; SLO Buffer against penalties Automate SLI/SLO dashboards Real-time visibility"},{"location":"classes/reliability/#7-summary-table","title":"7. Summary Table","text":"SLI SLO SLA Nature Metric Target Contract Audience Engineers Team Customer Example 99.95% success 99.9% 99.5% + credit Owner SRE / Dev SRE + PM Legal + CS Consequence Alert Pause features Refund"},{"location":"classes/reliability/#final-takeaway","title":"Final Takeaway","text":"<p>SLI is what you measure SLO is what you promise internally SLA is what you promise externally (with money on the line)</p> <p>They form a hierarchy of reliability: </p><pre><code>SLI (data) \u2192 SLO (target) \u2192 SLA (contract)\n</code></pre><p></p> <p>Used together, they enable data-driven reliability engineering \u2014 the foundation of modern SRE practices<sup>1</sup>.</p> <ol> <li> <p>Google SRE Book, 2016 \u21a9</p> </li> </ol>"},{"location":"exercises/exchange/","title":"Exchange","text":"<p>Now, the user wants to create an API that allows the user to convert between currencies. The API should use a third-party API to get the exchange rates. Note, this microservice HAVE TO be code in Python.</p> <pre><code>flowchart LR\n    subgraph api [Trusted Layer]\n        direction TB\n        gateway --&gt; account\n        gateway --&gt; auth\n        account --&gt; db@{ shape: cyl, label: \"Database\" }\n        auth --&gt; account\n        gateway e1@==&gt; exchange:::red\n        gateway --&gt; product\n        gateway --&gt; order\n        product --&gt; db\n        order --&gt; db\n        order --&gt; product\n    end\n    exchange e3@==&gt; 3partyapi:::green@{label: \"3rd-party API\"}\n    internet e2@==&gt;|request| gateway\n    e1@{ animate: true }\n    e2@{ animate: true }\n    e3@{ animate: true }\n    classDef red fill:#fcc\n    classDef green fill:#cfc\n    click product \"#product-api\" \"Product API\"</code></pre> <p>Attention</p> <p>To consume the API, the user must be authenticated.</p> <p>Using FastAPI<sup>1</sup> (or other framework) on Python , create a REST API that allows the user to convert between currencies. The API should have the following endpoints:</p> <p>GET /exchange/{from}/{to}</p> <p>Get the current of a coin from one currency to another. E.g. <code>GET /coin/USD/EUR</code>.</p> Response <p></p><pre><code>{\n    \"sell\": 0.82,\n    \"buy\": 0.80,\n    \"date\": \"2021-09-01 14:23:42\",\n    \"id-account\": \"0195ae95-5be7-7dd3-b35d-7a7d87c404fb\"\n}\n</code></pre> <pre><code>Response code: 200 (ok)\n</code></pre><p></p> <p>The API should use a third-party API to get the exchange rates. You can use the free tier of the API, e.g.:</p> <ul> <li>AwesomeAPI;</li> <li>ExchangeRate-API;</li> <li>Open Exchange Rates;</li> <li>CurrencyLayer;</li> <li>any other API.</li> </ul> <p>Or, you can scrape the data from a website.</p> <p>Hint</p> <p>You can use the <code>requests</code> library to make HTTP requests to the third-party API.</p> <p>Entrega</p> <p>Individualmente, cada aluno deve criar um reposit\u00f3rio no GitHub, com a documenta\u00e7\u00e3o em MkDocs dos exerc\u00edcios realizados e tamb\u00e9m com o projeto e entrega o link via BlabkBoard. Na documenta\u00e7\u00e3o publicada deve constar:</p> <ul> <li>Nome do aluno e grupo;</li> <li>Documenta\u00e7\u00e3o das atividades realizadas;</li> <li>C\u00f3digo fonte das atividades realizadas;</li> <li>Documenta\u00e7\u00e3o do projeto;</li> <li>C\u00f3digo fonte do projeto;</li> <li>Link para todos os reposit\u00f3rios utilizados;</li> <li>Destaques para os bottlenecks implementados (ao menos 2 por indiv\u00edduo);</li> <li>Apresenta\u00e7\u00e3o do projeto;</li> <li>V\u00eddeo de apresenta\u00e7\u00e3o do projeto (2-3 minutos);</li> </ul> <p>Um template de documenta\u00e7\u00e3o pode ser encontrado em Template de Documenta\u00e7\u00e3o.</p> <ol> <li> <p>FastAPI - First Steps.\u00a0\u21a9</p> </li> </ol>"},{"location":"exercises/jenkins/","title":"Jenkins","text":"<p>Now, it is time to create a pipeline to deploy the application to a cloud provider. You can use any cloud provider you prefer, such as AWS, Azure, or Google Cloud Platform. The pipeline should include the following steps:</p> <ol> <li>SCM</li> <li>Dependencies</li> <li>Build</li> <li>Push to Docker Hub</li> <li>Deploy to K8s</li> </ol> <p>TO DO</p> <p>All microservices should be deployed in the same cluster, to do this, it is mandatory to user Jenkinsfile in each microservice. The pipeline should be created in the root of the project, and it should include all microservices:</p> <ul> <li><code>account-service</code>;</li> <li><code>auth-service</code>;</li> <li><code>gateway-service</code>;</li> <li><code>product-service</code>, and;</li> <li><code>order-service</code>.</li> </ul> <p>A basic directory structure for the project is as follows:</p> <pre><code>.\n\u251c\u2500\u2500 account-service\n\u2502   \u251c\u2500\u2500 Jenkinsfile\n\u2502   \u2514\u2500\u2500 ...\n</code></pre> <p>Example of a Jenkinsfile for the <code>account-service</code>:</p> Jenkinsfile <pre><code>pipeline {\n    agent any\n    environment {\n        SERVICE = 'account'\n        NAME = \"humbertosandmann/${env.SERVICE}\"\n    }\n    stages {\n        stage('Dependecies') {\n            steps {\n                build job: 'account', wait: true\n            }\n        }\n        stage('Build') { \n            steps {\n                sh 'mvn -B -DskipTests clean package'\n            }\n        }      \n        stage('Build &amp; Push Image') {\n            steps {\n                withCredentials([usernamePassword(\n                    credentialsId: 'dockerhub-credential',\n                    usernameVariable: 'USERNAME',\n                    passwordVariable: 'TOKEN')])\n                {\n                    sh \"docker login -u $USERNAME -p $TOKEN\"\n                    sh \"docker buildx create --use --platform=linux/arm64,linux/amd64 --node multi-platform-builder-${env.SERVICE} --name multi-platform-builder-${env.SERVICE}\"\n                    sh \"docker buildx build --platform=linux/arm64,linux/amd64 --push --tag ${env.NAME}:latest --tag ${env.NAME}:${env.BUILD_ID} -f Dockerfile .\"\n                    sh \"docker buildx rm --force multi-platform-builder-${env.SERVICE}\"\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>Entrega</p> <p>Individualmente, cada aluno deve criar um reposit\u00f3rio no GitHub, com a documenta\u00e7\u00e3o em MkDocs dos exerc\u00edcios realizados e tamb\u00e9m com o projeto e entrega o link via BlabkBoard. Na documenta\u00e7\u00e3o publicada deve constar:</p> <ul> <li>Nome do aluno e grupo;</li> <li>Documenta\u00e7\u00e3o das atividades realizadas;</li> <li>C\u00f3digo fonte das atividades realizadas;</li> <li>Documenta\u00e7\u00e3o do projeto;</li> <li>C\u00f3digo fonte do projeto;</li> <li>Link para todos os reposit\u00f3rios utilizados;</li> <li>Destaques para os bottlenecks implementados (ao menos 2 por indiv\u00edduo);</li> <li>Apresenta\u00e7\u00e3o do projeto;</li> <li>V\u00eddeo de apresenta\u00e7\u00e3o do projeto (2-3 minutos);</li> </ul> <p>Um template de documenta\u00e7\u00e3o pode ser encontrado em Template de Documenta\u00e7\u00e3o.</p>"},{"location":"exercises/minikube/","title":"Minikube","text":"<p>Kubernetes should be installed and running on your local machine. You can use Minikube or Kind for this purpose. If you are using Docker Desktop, make sure Kubernetes is enabled in the settings.</p> <p>TO DO</p> <p>All microservices should be published in the same kubernetes cluster. Create the setup files for each microservice in the root of the project, eg.:</p> <pre><code>\ud83d\udcc1 api/\n\u2514\u2500\u2500 \ud83d\udcc1 account-service/\n    \u2514\u2500\u2500 \ud83d\udcc1 k8s/\n        \u2514\u2500\u2500  k8s.yaml\n</code></pre> <p>Where <code>k8s.yaml</code> is the setup file for the microservice. The setup file should include the following resources:</p> <ul> <li><code>Secrets</code>;</li> <li><code>ConfigMap</code>;</li> <li><code>Deployment</code>, and;</li> <li><code>Service</code>.</li> </ul> <p>The setup file should be created in the root of the project, and it should include all microservices:</p> <ul> <li><code>account-service</code>;</li> <li><code>auth-service</code>;</li> <li><code>gateway-service</code>;</li> <li><code>product-service</code>, and;</li> <li><code>order-service</code>.</li> </ul> <p>Execute the all services in the same cluster, and make sure they are running. You can use the following command to check if the services are running. You can user local kubernetes or a cloud provider, such as AWS, Azure, or Google Cloud Platform. Evidence the services are running in the same cluster using a video.</p> <p>Entrega</p> <p>Individualmente, cada aluno deve criar um reposit\u00f3rio no GitHub, com a documenta\u00e7\u00e3o em MkDocs dos exerc\u00edcios realizados e tamb\u00e9m com o projeto e entrega o link via BlabkBoard. Na documenta\u00e7\u00e3o publicada deve constar:</p> <ul> <li>Nome do aluno e grupo;</li> <li>Documenta\u00e7\u00e3o das atividades realizadas;</li> <li>C\u00f3digo fonte das atividades realizadas;</li> <li>Documenta\u00e7\u00e3o do projeto;</li> <li>C\u00f3digo fonte do projeto;</li> <li>Link para todos os reposit\u00f3rios utilizados;</li> <li>Destaques para os bottlenecks implementados (ao menos 2 por indiv\u00edduo);</li> <li>Apresenta\u00e7\u00e3o do projeto;</li> <li>V\u00eddeo de apresenta\u00e7\u00e3o do projeto (2-3 minutos);</li> </ul> <p>Um template de documenta\u00e7\u00e3o pode ser encontrado em Template de Documenta\u00e7\u00e3o.</p>"},{"location":"exercises/order/","title":"Order","text":"<pre><code>flowchart LR\n    subgraph api [Trusted Layer]\n        direction TB\n        gateway --&gt; account\n        gateway --&gt; auth\n        account --&gt; db@{ shape: cyl, label: \"Database\" }\n        auth --&gt; account\n        gateway e5@==&gt; product\n        gateway e6@==&gt; order:::red\n        product e2@==&gt; db\n        order e3@==&gt; db\n        order e4@==&gt; product\n    end\n    internet e1@==&gt;|request| gateway\n    e1@{ animate: true }\n    e2@{ animate: true }\n    e3@{ animate: true }\n    e4@{ animate: true }\n    e5@{ animate: true }\n    e6@{ animate: true }\n    classDef red fill:#fcc\n    click order \"#order-api\" \"Order API\"</code></pre> <p>Attention</p> <p>To consume the API, the user must be authenticated.</p>"},{"location":"exercises/order/#order-api","title":"Order API","text":"<p>POST /order</p> <p>Create a new order for the current user.</p> RequestResponse <pre><code>{\n    \"items\": [\n        {\n            \"idProduct\": \"0195abfb-7074-73a9-9d26-b4b9fbaab0a8\",\n            \"quantity\": 2\n        },\n        {\n            \"idProduct\": \"0195abfe-e416-7052-be3b-27cdaf12a984\",\n            \"quantity\": 1\n        }\n    ]\n}\n</code></pre> <p></p><pre><code>{\n    \"id\": \"0195ac33-73e5-7cb3-90ca-7b5e7e549569\",\n    \"date\": \"2025-09-01T12:30:00\",\n    \"items\": [\n        {\n            \"id\": \"01961b9a-bca2-78c4-9be1-7092b261f217\",\n            \"product\": {\n                \"id\": \"0195abfb-7074-73a9-9d26-b4b9fbaab0a8\"\n            },\n            \"quantity\": 2,\n            \"total\": 20.24\n        },\n        {\n            \"id\": \"01961b9b-08fd-76a5-8508-cdb6cd5c27ab\",\n            \"product\": {\n                \"id\": \"0195abfe-e416-7052-be3b-27cdaf12a984\"\n            },\n            \"quantity\": 10,\n            \"total\": 6.2\n        }\n    ],\n    \"total\": 26.44\n}\n</code></pre> <pre><code>Response code: 201 (created)\nResponse code: 400 (bad request), if the product does not exist.\n</code></pre><p></p> <p>GET /order</p> <p>Get all orders for the current user.</p> Response <p></p><pre><code>[\n    {\n        \"id\": \"0195ac33-73e5-7cb3-90ca-7b5e7e549569\",\n        \"date\": \"2025-09-01T12:30:00\",\n        \"total\": 26.44\n    },\n    {\n        \"id\": \"0195ac33-cbbd-7a6e-a15b-b85402cf143f\",\n        \"date\": \"2025-10-09T03:21:57\",\n        \"total\": 18.6\n    }\n\n]\n</code></pre> <pre><code>Response code: 200 (ok)\n</code></pre><p></p> <p>GET /order/{id}</p> <p>Get the order details by its ID. The order must belong to the current user., otherwise, return a <code>404</code>.</p> Response <p></p><pre><code>{\n    \"id\": \"0195ac33-73e5-7cb3-90ca-7b5e7e549569\",\n    \"date\": \"2025-09-01T12:30:00\",\n    \"items\": [\n        {\n            \"id\": \"01961b9a-bca2-78c4-9be1-7092b261f217\",\n            \"product\": {\n                \"id\": \"0195abfb-7074-73a9-9d26-b4b9fbaab0a8\",\n            },\n            \"quantity\": 2,\n            \"total\": 20.24\n        },\n        {\n            \"id\": \"01961b9b-08fd-76a5-8508-cdb6cd5c27ab\",\n            \"product\": {\n                \"id\": \"0195abfe-e416-7052-be3b-27cdaf12a984\",\n            },\n            \"quantity\": 10,\n            \"total\": 6.2\n        }\n    ],\n    \"total\": 26.44\n}\n</code></pre> <pre><code>Response code: 200 (ok)\nResponse code: 404 (not found), if the order does not belong to the current user.\n</code></pre><p></p>"},{"location":"exercises/order/#additionals","title":"Additionals","text":"<p>Additional features are welcome, such as:</p> <ul> <li>Search products by \"like\" name;</li> <li>Authorization by role (admin, user):<ul> <li>Admin can create, update, and delete products;</li> <li>User can only create orders;</li> </ul> </li> <li>Input validations;</li> <li>Error handling.</li> </ul>"},{"location":"exercises/order/#nice-to-have","title":"Nice to have","text":"<ul> <li>Observability (metrics, logs), see Prometheus and Grafana;</li> <li>Database In-Memory (suggestion: Product microservice), see Redis;</li> <li>Swagger documentation, see SpringDoc.</li> </ul> <p>Entrega</p> <p>Individualmente, cada aluno deve criar um reposit\u00f3rio no GitHub, com a documenta\u00e7\u00e3o em MkDocs dos exerc\u00edcios realizados e tamb\u00e9m com o projeto e entrega o link via BlabkBoard. Na documenta\u00e7\u00e3o publicada deve constar:</p> <ul> <li>Nome do aluno e grupo;</li> <li>Documenta\u00e7\u00e3o das atividades realizadas;</li> <li>C\u00f3digo fonte das atividades realizadas;</li> <li>Documenta\u00e7\u00e3o do projeto;</li> <li>C\u00f3digo fonte do projeto;</li> <li>Link para todos os reposit\u00f3rios utilizados;</li> <li>Destaques para os bottlenecks implementados (ao menos 2 por indiv\u00edduo);</li> <li>Apresenta\u00e7\u00e3o do projeto;</li> <li>V\u00eddeo de apresenta\u00e7\u00e3o do projeto (2-3 minutos);</li> </ul> <p>Um template de documenta\u00e7\u00e3o pode ser encontrado em Template de Documenta\u00e7\u00e3o.</p>"},{"location":"exercises/product/","title":"Product","text":"<p>Create a RESTful API for a store. The API should have two main resources: <code>product</code> and <code>order</code>.</p> <pre><code>flowchart LR\n    subgraph api [Trusted Layer]\n        direction TB\n        gateway --&gt; account\n        gateway --&gt; auth\n        account --&gt; db@{ shape: cyl, label: \"Database\" }\n        auth --&gt; account\n        gateway e5@==&gt; product:::red\n        gateway e6@==&gt; order\n        product e2@==&gt; db\n        order e3@==&gt; db\n        order e4@==&gt; product\n    end\n    internet e1@==&gt;|request| gateway\n    e1@{ animate: true }\n    e2@{ animate: true }\n    e3@{ animate: true }\n    e4@{ animate: true }\n    e5@{ animate: true }\n    e6@{ animate: true }\n    classDef red fill:#fcc\n    click product \"#product-api\" \"Product API\"</code></pre> <p>Attention</p> <p>To consume the API, the user must be authenticated.</p>"},{"location":"exercises/product/#product-api","title":"Product API","text":"<p>The API should have the following endpoints:</p> <p>POST /product</p> <p>Create a new product.</p> RequestResponse <pre><code>{\n    \"name\": \"Tomato\",\n    \"price\": 10.12,\n    \"unit\": \"kg\"\n}\n</code></pre> <p></p><pre><code>{\n    \"id\": \"0195abfb-7074-73a9-9d26-b4b9fbaab0a8\",\n    \"name\": \"Tomato\",\n    \"price\": 10.12,\n    \"unit\": \"kg\"\n}\n</code></pre> <pre><code>Response code: 201 (created)\n</code></pre><p></p> <p>GET /product</p> <p>Get all products.</p> Response <p></p><pre><code>[\n    {\n        \"id\": \"0195abfb-7074-73a9-9d26-b4b9fbaab0a8\",\n        \"name\": \"Tomato\",\n        \"price\": 10.12,\n        \"unit\": \"kg\"\n    },\n    {\n        \"id\": \"0195abfe-e416-7052-be3b-27cdaf12a984\",\n        \"name\": \"Cheese\",\n        \"price\": 0.62,\n        \"unit\": \"slice\"\n    }\n]\n</code></pre> <pre><code>Response code: 200 (ok)\n</code></pre><p></p> <p>GET /product/{id}</p> <p>Get a product by its ID.</p> Response <p></p><pre><code>{\n    \"id\": \"0195abfb-7074-73a9-9d26-b4b9fbaab0a8\",\n    \"name\": \"Tomato\",\n    \"price\": 10.12,\n    \"unit\": \"kg\"\n}\n</code></pre> <pre><code>Response code: 200 (ok)\n</code></pre><p></p> <p>DELETE /product/{id}</p> <p>Delete a product by its ID.</p> <pre><code>Response code: 204 (no content)\n</code></pre>"},{"location":"exercises/product/#additionals","title":"Additionals","text":"<p>Additional features are welcome, such as:</p> <ul> <li>Search products by \"like\" name;</li> <li>Authorization by role (admin, user):<ul> <li>Admin can create, update, and delete products;</li> <li>User can only create orders;</li> </ul> </li> <li>Input validations;</li> <li>Error handling.</li> </ul>"},{"location":"exercises/product/#nice-to-have","title":"Nice to have","text":"<ul> <li>Observability (metrics, logs), see Prometheus and Grafana;</li> <li>Database In-Memory (suggestion: Product microservice), see Redis;</li> <li>Swagger documentation, see SpringDoc.</li> </ul> <p>Entrega</p> <p>Individualmente, cada aluno deve criar um reposit\u00f3rio no GitHub, com a documenta\u00e7\u00e3o em MkDocs dos exerc\u00edcios realizados e tamb\u00e9m com o projeto e entrega o link via BlabkBoard. Na documenta\u00e7\u00e3o publicada deve constar:</p> <ul> <li>Nome do aluno e grupo;</li> <li>Documenta\u00e7\u00e3o das atividades realizadas;</li> <li>C\u00f3digo fonte das atividades realizadas;</li> <li>Documenta\u00e7\u00e3o do projeto;</li> <li>C\u00f3digo fonte do projeto;</li> <li>Link para todos os reposit\u00f3rios utilizados;</li> <li>Destaques para os bottlenecks implementados (ao menos 2 por indiv\u00edduo);</li> <li>Apresenta\u00e7\u00e3o do projeto;</li> <li>V\u00eddeo de apresenta\u00e7\u00e3o do projeto (2-3 minutos);</li> </ul> <p>Um template de documenta\u00e7\u00e3o pode ser encontrado em Template de Documenta\u00e7\u00e3o.</p>"},{"location":"exercises/bottlenecks/bottlenecks/","title":"Bottlenecks","text":"<p>To deliver a high-performance application, you need to identify and address potential bottlenecks in your system. This document outlines some common bottlenecks and how to mitigate them.</p>"},{"location":"exercises/bottlenecks/bottlenecks/#caching","title":"Caching","text":"<p>In-memory databases are a great way to improve the performance of your application. They can be used to store frequently accessed data, reducing the need to query the database for every request. Exemples of in-memory databases include Redis and Memcached.</p>"},{"location":"exercises/bottlenecks/bottlenecks/#observability","title":"Observability","text":"<p>Observability is the ability to measure and understand the internal state of a system based on its external outputs. It is essential for identifying and diagnosing performance issues in your application. Tools like Prometheus and Grafana can help you monitor your application's performance and identify bottlenecks.</p> <ul> <li> <p>Set Up Prometheus and Grafana for Spring Boot Monitoring</p> </li> <li> <p>Monitor a Spring Boot App Using Prometheus</p> </li> <li> <p></p> </li> </ul> <p>Spring + Prometheus + Grafana</p> <p>This tip provides a basic configuration for integrating Spring Boot with Prometheus and Grafana for monitoring purposes.</p> <p>Suggested file structure:</p> <pre><code>\ud83d\udcc1 microservice\n\u251c\u2500\u2500 \ud83d\udcc1 src\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 main\n\u2502       \u2514\u2500\u2500 \ud83d\udcc1 resources\n\u2502           \u2514\u2500\u2500  application.yaml\n\u2514\u2500\u2500  pom.xml\n\ud83d\udcc1 volume\n\u251c\u2500\u2500 \ud83d\udcc1 prometheus\n\u2502   \u2514\u2500\u2500  prometheus.yml\n\u2514\u2500\u2500 \ud83d\udcc1 grafana\n    \u2514\u2500\u2500 \ud83d\udcc1 provisioning\n        \u2514\u2500\u2500 \ud83d\udcc1 datasources\n            \u2514\u2500\u2500  datasources.yml\n .env # (1)!\n compose.yaml\n</code></pre> <ol> <li>VOLUME=./volume</li> </ol> 1. pom.xml2. application.yaml3. compose.yaml4. prometheus.yml5. Grafana to Prometheus6. Access Grafana <p>Add the following dependencies to your <code>pom.xml</code> file:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.micrometer&lt;/groupId&gt;\n    &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;\n    &lt;scope&gt;runtime&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre> <p>Configure the <code>application.yaml</code> file to enable the actuator and Prometheus endpoint:</p> <pre><code>server:\n  port: 8080\n\nspring:\n  application:\n    name: gateway\n\nmanagement:\n  endpoint:\n    gateway:\n      enabled: true\n  endpoints:\n    web:\n      base-path: /gateway/actuator\n      exposure:\n        include: [ 'prometheus', 'gateway' ]\n</code></pre> <p>Include into the <code>compose.yaml</code> file to set up Prometheus and Grafana:</p> <pre><code>name: store\n\nservices:\n\n  prometheus:\n    image: prom/prometheus:latest\n    hostname: prometheus\n    ports:\n      - 9090:9090\n    volumes:\n      - $VOLUME/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n\n  grafana:\n    image: grafana/grafana-enterprise\n    hostname: grafana\n    ports:\n      - 3000:3000\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n    volumes:\n      - $VOLUME/grafana:/var/lib/grafana\n      - $VOLUME/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources      \n    restart: always\n    depends_on:\n      - prometheus\n</code></pre> <p>Connect Prometheus to your Spring Boot application by creating a <code>prometheus.yaml</code> file:</p> <pre><code>scrape_configs:\n\n  - job_name: 'GatewayMetrics'\n    metrics_path: '/gateway/actuator/prometheus'\n    scrape_interval: 1s\n    static_configs:\n      - targets:\n        - gateway:8080\n        labels:\n          application: 'Gateway Application'\n\n  - job_name: 'AuthMetrics'\n    metrics_path: '/auth/actuator/prometheus'\n    scrape_interval: 1s\n    static_configs:\n      - targets:\n        - auth:8080\n        labels:\n          application: 'Auth Application'\n\n  # - job_name: 'AccountMetrics'\n  #   metrics_path: '/account/actuator/prometheus'\n  #   scrape_interval: 1s\n  #   static_configs:\n  #     - targets:\n  #       - account:8080\n  #       labels:\n  #         application: 'Account Application'\n\n  # - job_name: 'ProductMetrics'\n  #   metrics_path: '/product/actuator/prometheus'\n  #   scrape_interval: 1s\n  #   static_configs:\n  #     - targets:\n  #       - product:8080\n  #       labels:\n  #         application: 'Product Application'\n\n  # - job_name: 'OrderMetrics'\n  #   metrics_path: '/order/actuator/prometheus'\n  #   scrape_interval: 1s\n  #   static_configs:\n  #     - targets:\n  #       - order:8080\n  #       labels:\n  #         application: 'Order Application'  \n</code></pre> <p>To connect Grafana to Prometheus, create a <code>datasources.yml</code> file in the <code>provisioning/datasources</code> directory:</p> <pre><code>apiVersion: 1\n\ndatasources:\n  - name: Prometheus\n    type: prometheus\n    access: proxy\n    url: http://prometheus:9090\n    isDefault: true\n</code></pre> <p>After starting the containers and binding the ports to your local machine, you can access Grafana at <code>http://localhost:3000</code> with the default username <code>admin</code> and password <code>admin</code>. You can then create or import dashboards to visualize the metrics collected from your Spring Boot application.</p> <p>For more information on how to create dashboards in Grafana, refer to the Grafana documentation.</p> <p>A nice dashboard for Spring Boot</p> <p>You can find a nice dashboard for Spring Boot applications in the Grafana dashboard repository: SpringBoot APM Dashboard.</p> <p></p>"},{"location":"exercises/bottlenecks/bottlenecks/#messaging","title":"Messaging","text":"<p>Message queues are a great way to decouple your application and improve its performance. They can be used to handle asynchronous tasks, such as sending emails or processing background jobs. Examples of message queues include RabbitMQ and Apache Kafka.</p>"},{"location":"exercises/bottlenecks/bottlenecks/#load-balancing","title":"Load Balancing","text":"<p>Load balancing is the process of distributing incoming network traffic across multiple servers. This helps to ensure that no single server is overwhelmed with requests, improving the overall performance and reliability of your application. Tools like Nginx and HAProxy can help you implement load balancing in your application.</p> <ul> <li>How To Configure Nginx as a Reverse Proxy on Ubuntu</li> <li></li> </ul>"},{"location":"exercises/bottlenecks/bottlenecks/#vulnerability-scanning","title":"Vulnerability Scanning","text":"<p>Vulnerability scanning is the process of identifying and addressing security vulnerabilities in your application. Tools like OWASP ZAP and Snyk can help you identify potential security issues in your code and dependencies.</p> <p>Entrega</p> <p>Individualmente, cada aluno deve criar um reposit\u00f3rio no GitHub, com a documenta\u00e7\u00e3o em MkDocs dos exerc\u00edcios realizados e tamb\u00e9m com o projeto e entrega o link via BlabkBoard. Na documenta\u00e7\u00e3o publicada deve constar:</p> <ul> <li>Nome do aluno e grupo;</li> <li>Documenta\u00e7\u00e3o das atividades realizadas;</li> <li>C\u00f3digo fonte das atividades realizadas;</li> <li>Documenta\u00e7\u00e3o do projeto;</li> <li>C\u00f3digo fonte do projeto;</li> <li>Link para todos os reposit\u00f3rios utilizados;</li> <li>Destaques para os bottlenecks implementados (ao menos 2 por indiv\u00edduo);</li> <li>Apresenta\u00e7\u00e3o do projeto;</li> <li>V\u00eddeo de apresenta\u00e7\u00e3o do projeto (2-3 minutos);</li> </ul> <p>Um template de documenta\u00e7\u00e3o pode ser encontrado em Template de Documenta\u00e7\u00e3o.</p>"},{"location":"exercises/project/project/","title":"Project","text":"Tarefas Descri\u00e7\u00e3o Peso AWS Configurar AWS 5% EKS Disponibilizar a aplica\u00e7\u00e3o 15% Testes Testes de carga 20% CI/CD Jenkins 10% Custos An\u00e1lise de custos 15% PaaS Plano de uso da plataforma 15% Apresenta\u00e7\u00e3o Storytelling e documenta\u00e7\u00e3o 20% <p>Entrega</p> <ul> <li>Trabalho em grupo deve ser documentado no GitHub. Um template est\u00e1 dispon\u00edvel para auxiliar na documenta\u00e7\u00e3o: template de entrega.</li> </ul>"},{"location":"exercises/project/project/#configuracao-do-aws","title":"Configura\u00e7\u00e3o do AWS","text":"<p>A AWS \u00e9 uma plataforma de computa\u00e7\u00e3o em nuvem que oferece uma ampla gama de servi\u00e7os, incluindo computa\u00e7\u00e3o, armazenamento, banco de dados, an\u00e1lise, rede, mobilidade, ferramentas de desenvolvedor, gerenciamento e seguran\u00e7a. Para configurar a AWS, voc\u00ea precisar\u00e1 criar uma conta e configurar os servi\u00e7os necess\u00e1rios para o seu projeto.</p> Roadmap <p>This roudmap is not complete and may not cover all the steps you need to take to configure your AWS environment. It is a good start to help you understand the steps you need to take to configure your AWS environment. You can find more information about each step in the AWS documentation.</p> <p>Create an AWS account and configure the AWS CLI. You can use the AWS CLI to manage your AWS services from the command line.</p> 1. Create User2. Loggin at AWS Dashboard3. Create Access Key4. Configure AWS CLI <p> </p> <p>Loggin at the AWS Dashboard with the created user.</p> <p> </p> <p>AWS CLI</p>"},{"location":"exercises/project/project/#configuracao-do-eks","title":"Configura\u00e7\u00e3o do EKS","text":"<p>O Amazon Elastic Kubernetes Service (EKS) \u00e9 um servi\u00e7o gerenciado que facilita a execu\u00e7\u00e3o do Kubernetes na AWS sem a necessidade de instalar e operar seu pr\u00f3prio plano de controle ou n\u00f3s de trabalho do Kubernetes. O EKS cuida da alta disponibilidade e escalabilidade do plano de controle do Kubernetes, permitindo que voc\u00ea se concentre em implantar e gerenciar seus aplicativos.</p> <p>EKS</p> <p>Custo de Uso</p> <p>O custo de uso do EKS pode variar dependendo da regi\u00e3o e dos servi\u00e7os utilizados. \u00c9 importante monitorar os custos e otimizar o uso dos recursos para evitar surpresas na fatura. Voc\u00ea pode usar a calculadora de pre\u00e7os da AWS para estimar os custos do seu projeto.</p> <p>CUIDADO: o tipo de inst\u00e2ncia EC2 \u00e9 um dos principais fatores que afetam o custo do EKS. Inst\u00e2ncias maiores e mais poderosas custam mais, enquanto inst\u00e2ncias menores e menos poderosas custam menos. Al\u00e9m disso, o uso de recursos adicionais, como armazenamento em bloco e balanceadores de carga, tamb\u00e9m pode aumentar os custos<sup>1</sup>.</p> <p>TO DO</p> <p>Fa\u00e7a um cluster EKS e fa\u00e7a o deploy da aplica\u00e7\u00e3o Spring Boot no cluster. Voc\u00ea pode usar o AWS CLI ou o console da AWS para criar e gerenciar seu cluster EKS.</p> <p>Para implementar a base de dados, voc\u00ea pode usar o Amazon RDS (Relational Database Service) ou o Amazon DynamoDB, dependendo das necessidades do seu projeto. </p> Roadmap <p>This roudmap is not complete and may not cover all the steps you need to take to configure your AWS environment. It is a good start to help you understand the steps you need to take to configure your AWS environment. You can find more information about each step in the AWS documentation.</p> <p>Create an AWS account and configure the AWS CLI. You can use the AWS CLI to manage your AWS services from the command line.</p> 1. Create EKS Role2. Create a VPC3. Create EKS Cluster4. Create a Role for the Node Group5. Define the Node Group6. Access the EKS Cluster <p> </p> <p>Overview of the VPC:</p> <pre><code>flowchart TB\nsubgraph Region\n    direction LR\n    subgraph Zone A\n    direction LR\n    subgraph subpri1[\"Subnet Private\"]\n        direction TB\n        poda1[\"pod 1\"]\n        poda2[\"pod 2\"]\n        poda3[\"pod 3\"]\n    end\n    subgraph subpub1[\"Subnet Public\"]\n        loadbalancea[\"Load Balance\"]\n    end\n    end\n    subgraph Zone B\n    direction LR\n    subgraph subpri2[\"Subnet Private\"]\n        direction TB\n        podb1[\"pod 1\"]\n        podb2[\"pod 2\"]\n        podb3[\"pod 3\"]\n    end\n    subgraph subpub2[\"Subnet Public\"]\n        loadbalanceb[\"Load Balance\"]\n    end\n    end\n    User --&gt; loadbalancea\n    loadbalancea --&gt; poda1\n    loadbalancea --&gt; poda2\n    loadbalancea --&gt; poda3\n    User --&gt; loadbalanceb\n    loadbalanceb --&gt; podb1\n    loadbalanceb --&gt; podb2\n    loadbalanceb --&gt; podb3\nend</code></pre> <p>Create a VPC with the following configuration, including 2 public and 2 private subnets. The public subnets will be used for the load balancers, and the private subnets will be used for the pods. The VPC should be created in the same region as the EKS cluster.</p> <p>To create the VPC, use the AWS CloudFormation with the template file: amazon-eks-vpc-private-subnets.yaml (download it and upload it as a CloudFormation template).</p> <p> </p> <p> </p> <p>Pay Attention</p> <p>The EKS cluster will take a few minutes to be created. You can check the status of the cluster in the AWS console. Once the cluster is created, you can access it using the AWS CLI or kubectl.</p> <p>Notice that there no nodes on cluster also, because only the Control Pane had been created, there is no exist a node for the worker nodes.</p> <p></p> <p>Add Permissions to the role:</p> <ul> <li>AmazonEKS_CNI_Policy</li> <li>AmazonEKSWorkerNodePolicy</li> <li>AmazonEC2ContainerRegistryReadOnly</li> </ul> <p> </p> <p> </p> <p>Define the Configuration of machine type</p> <p></p> <p>Only private subnets:</p> <p></p> <p>AWS CLI</p> <p>On terminal, after that it had been set up the aws cli.</p> <pre><code>aws configure\n</code></pre> <p>See the configuration that was set up:</p> <pre><code>aws configure list\n</code></pre> <p></p>aws configure list    Name                    Value             Type    Location    ----                    -----             ----    --------profile                &lt;not set&gt;             None    Noneaccess_key     **TTNI shared-credentials-file    secret_key     **zAJ1 shared-credentials-file        region                us-east-2      config-file    ~/.aws/config<p></p> <p>Set up the kube-config to point to the remote aws eks cluster.</p> <pre><code>aws eks update-kubeconfig --name eks-store\n</code></pre> <p></p>aws eks update-kubeconfig --name eks-storeAdded new context arn:aws:eks:us-east-2:058264361068:cluster/eks-store to /Users/sandmann/.kube/config&gt;&gt;kubectl get podsNo resources found in default namespace.&gt;&gt;kubectl get nodesNo resources found&gt;<p></p> <p>Nice commands</p> <pre><code>kubectl config get-contexts\n</code></pre> <pre><code>kubectl config set-context [NAME]\n</code></pre>"},{"location":"exercises/project/project/#testes-de-carga","title":"Testes de Carga","text":"<p>Os testes de carga s\u00e3o uma parte importante do desenvolvimento de software, pois ajudam a garantir que sua aplica\u00e7\u00e3o possa lidar com o tr\u00e1fego esperado. Existem v\u00e1rias ferramentas dispon\u00edveis para realizar testes de carga, incluindo Apache JMeter, Gatling e Locust.</p> <p>Kubernetes - HPA - Increase the load</p> <p>TO DO</p> <p>Fa\u00e7a um teste de carga na sua aplica\u00e7\u00e3o Spring Boot. Grave um video do teste de carga, mostrando: - O teste de carga em execu\u00e7\u00e3o; - HPA (Horizontal Pod Autoscaler) em execu\u00e7\u00e3o.</p> <p>Dicas</p> <ul> <li>No do link do HPA, voc\u00ea encontrar\u00e1 um exemplo de teste de carga. Ele aponta para um apache httpd, mas voc\u00ea pode adapt\u00e1-lo para o seu projeto Spring Boot;</li> <li>Um endere\u00e7o de exemplo para o teste de carga \u00e9: <code>http://&lt;dns-name&gt;/info</code>. Pois o <code>gateway</code> possui um endpoint <code>/info</code> que retorna informa\u00e7\u00f5es sobre a aplica\u00e7\u00e3o. Voc\u00ea pode usar esse endpoint para testar a carga da sua aplica\u00e7\u00e3o.</li> </ul> <p>Example of HPA</p> <p>Open three terminal windows, one for each tab below.</p> 1. Create the HPA2. Monitor the Pods3. Run the Load Test <p>Create the HPA (Horizontal Pod Autoscaler) for the <code>gateway</code> deployment. The HPA will automatically scale the number of pods in the deployment based on CPU usage.</p> <pre><code>kubectl autoscale deployment gateway --cpu-percent=50 --min=1 --max=10\n</code></pre> <p>Check the status of the HPA:</p> <pre><code>kubectl get hpa                                                       \nNAME      REFERENCE            TARGETS       MINPODS   MAXPODS   REPLICAS   AGE\ngateway   Deployment/gateway   cpu: 1%/50%   1         10        1          66s\n</code></pre> <p>Watch the HPA status:</p> <pre><code>watch -n 1 'kubectl get hpa'\n</code></pre> <p>At the end of the test, delete the HPA:</p> <pre><code>kubectl delete hpa gateway\n</code></pre> <p>Open another terminal window and monitor the pods in the <code>gateway</code> deployment:</p> <pre><code>watch -n 1 'kubectl get pods -l app=gateway'\n</code></pre> <p>Open another terminal window and run the load test against the <code>gateway</code> deployment. This will simulate a high load on the application, causing the HPA to scale the number of pods in the deployment.</p> <pre><code>kubectl run -i --tty load-generator --rm --image=busybox:1.28 --restart=Never -- /bin/sh -c \"while sleep 0.01; do wget -q -O- http://gateway/health-check; done\"\n</code></pre> <p>In the command above, the <code>wget</code> command is used to send requests to the <code>/info</code> endpoint of the <code>gateway</code> deployment. The <code>while</code> loop will continue to send requests until you stop it (e.g., by pressing <code>Ctrl+C</code>). The interval between requests is set to 0.01 seconds, which simulates a high load on the application. Try to increase and decrease the interval to see how the HPA reacts to different loads.</p>"},{"location":"exercises/project/project/#cicd","title":"CI/CD","text":"<p>A integra\u00e7\u00e3o cont\u00ednua (CI) e a entrega cont\u00ednua (CD) s\u00e3o pr\u00e1ticas de desenvolvimento de software que ajudam a garantir que seu c\u00f3digo esteja sempre em um estado implant\u00e1vel. O Jenkins \u00e9 uma ferramenta popular para implementar CI/CD em seus projetos.</p> <p>TO DO</p> <p>Complemente seu pipeline de CI/CD de forma que ap\u00f3s o push da imagem no Docker Hub, o Jenkins fa\u00e7a o deploy da imagem no EKS.</p>"},{"location":"exercises/project/project/#custos","title":"Custos","text":"<p>A an\u00e1lise de custos \u00e9 uma parte importante do desenvolvimento de software, pois ajuda a garantir que seu projeto esteja dentro do or\u00e7amento. Existem v\u00e1rias ferramentas dispon\u00edveis para ajudar na an\u00e1lise de custos, incluindo o AWS Cost Explorer<sup>2</sup> e o AWS Budgets<sup>3</sup>.</p> <p>TO DO</p> <p>Monte um plano de custos para o seu projeto, incluindo os custos de uso do EKS, RDS e outros servi\u00e7os da AWS que voc\u00ea est\u00e1 utilizando. Use a calculadora de pre\u00e7os da AWS para estimar os custos do seu projeto.</p>"},{"location":"exercises/project/project/#paas","title":"PaaS","text":"<p>A plataforma como servi\u00e7o (PaaS) \u00e9 um modelo de computa\u00e7\u00e3o em nuvem que fornece uma plataforma para desenvolver, executar e gerenciar aplicativos sem a complexidade de construir e manter a infraestrutura normalmente associada ao desenvolvimento e lan\u00e7amento de aplicativos.</p> <p></p> <p>TO DO</p> <p>Descreva onde seu grupo utilizou PaaS e como utilizou.</p>"},{"location":"exercises/project/project/#apresentacao","title":"Apresenta\u00e7\u00e3o","text":"<p>A apresenta\u00e7\u00e3o do seu projeto \u00e9 uma parte importante do processo de desenvolvimento de software. \u00c9 a oportunidade de mostrar seu trabalho e explicar como sua aplica\u00e7\u00e3o funciona. Use ferramentas como o PowerPoint ou o Google Slides para criar uma apresenta\u00e7\u00e3o visualmente atraente. Se poss\u00edvel, fa\u00e7a uma demonstra\u00e7\u00e3o ao vivo da sua aplica\u00e7\u00e3o para mostrar como ela funciona na pr\u00e1tica, assim bem como um v\u00eddeo de apresenta\u00e7\u00e3o do projeto.</p> <p>TO DO</p> <p>Crie uma apresenta\u00e7\u00e3o do seu projeto, incluindo os seguintes t\u00f3picos:</p> <ul> <li>Introdu\u00e7\u00e3o ao projeto;</li> <li>Arquitetura do projeto;</li> <li>Demonstra\u00e7\u00e3o da aplica\u00e7\u00e3o;</li> <li>Desafios enfrentados - bottlenecks;</li> <li>Conclus\u00e3o e pr\u00f3ximos passos.</li> </ul> <p>O v\u00eddeo de apresenta\u00e7\u00e3o deve ter entre 2 e 3 minutos e deve ser enviado junto com a documenta\u00e7\u00e3o do projeto.</p> <p>Video de Apresenta\u00e7\u00e3o</p> <p>Excepcionalmente, nesta edi\u00e7\u00e3o do curso, a apresenta\u00e7\u00e3o do projeto ser\u00e1 feita atrav\u00e9s de um v\u00eddeo de 3 a 5 minutos, onde cada grupo deve apresentar o projeto e os bottlenecks implementados. O v\u00eddeo deve ser enviado junto com a documenta\u00e7\u00e3o do projeto.</p> <p>Entrega</p> <p>Individualmente, cada aluno deve criar um reposit\u00f3rio no GitHub, com a documenta\u00e7\u00e3o em MkDocs dos exerc\u00edcios realizados e tamb\u00e9m com o projeto e entrega o link via BlabkBoard. Na documenta\u00e7\u00e3o publicada deve constar:</p> <ul> <li>Nome do aluno e grupo;</li> <li>Documenta\u00e7\u00e3o das atividades realizadas;</li> <li>C\u00f3digo fonte das atividades realizadas;</li> <li>Documenta\u00e7\u00e3o do projeto;</li> <li>C\u00f3digo fonte do projeto;</li> <li>Link para todos os reposit\u00f3rios utilizados;</li> <li>Destaques para os bottlenecks implementados (ao menos 2 por indiv\u00edduo);</li> <li>Apresenta\u00e7\u00e3o do projeto;</li> <li>V\u00eddeo de apresenta\u00e7\u00e3o do projeto (2-3 minutos);</li> </ul> <p>Um template de documenta\u00e7\u00e3o pode ser encontrado em Template de Documenta\u00e7\u00e3o.</p> <ol> <li> <p>AWS Pricing Calculator \u21a9</p> </li> <li> <p>AWS Cost Explorer \u21a9</p> </li> <li> <p>AWS Budgets \u21a9</p> </li> </ol>"},{"location":"handout/architecture/","title":"Architecture","text":""},{"location":"handout/architecture/#clean-architecture","title":"Clean Architecture","text":"<p>Total desacoplamento das regras de neg\u00f3cios das camadas de interface:</p> <p> </p> Source: The Clean Code Blog <p>Em nossa arquitetura:</p> <pre><code>flowchart LR\n  subgraph Controller\n    direction TB\n    Interface:::adapter\n    RecordIn:::adapter\n    RecordOut:::adapter\n  end\n  subgraph Case\n    direction TB\n    Service:::case\n    DTO:::case\n  end\n  subgraph Entity\n    direction TB\n    Repository:::entity\n    Table:::entity\n  end\n\n  Interface --&gt; RecordIn\n  Interface --&gt; RecordOut\n\n  Controller &lt;--&gt; parser[\"Parser\"] &lt;--&gt; Case\n\n  Service --&gt; DTO\n\n  Case &lt;--&gt; mapper[\"Mapper\"] &lt;--&gt; Entity\n\n  Repository --&gt; Table\n\n  classDef adapter fill:#6f6\n  classDef case fill:#f99\n  classDef entity fill:#ff9\n</code></pre>"},{"location":"handout/architecture/#referencias","title":"Refer\u00eancias:","text":"<ol> <li> <p> Criando um projeto Spring Boot com Arquitetura Limpa by Giuliana Silva Bezerra</p> <p> \u21a9</p> </li> <li> <p> Clean Architecture: A Craftsman's Guide to Software Structure and Design \u21a9</p> </li> <li> <p> Como se faz DevOps: Organizando pessoas, dos silos aos times de plataforma \u21a9</p> </li> </ol>"},{"location":"handout/business/","title":"Business","text":""},{"location":"handout/business/#compromissos-e-contratos","title":"Compromissos e Contratos","text":"<p>SLI significa Service Level Indicator, ou Indicador de N\u00edvel de Servi\u00e7o. S\u00e3o m\u00e9tricas quantitativas que medem a qualidade de um servi\u00e7o. Por exemplo, se o SLA especificar que os sistemas v\u00e3o estar dispon\u00edveis 99,95% do tempo, o SLI \u00e9 a medi\u00e7\u00e3o real da disponibilidade.</p> <p>SLO significa Service Level Objective, ou Objetivo de N\u00edvel de Servi\u00e7o. S\u00e3o metas espec\u00edficas de desempenho que uma equipe de SRE define para cumprir os requisitos do SLA.</p> <p>SLA significa Service Level Agreement, ou Acordo de N\u00edvel de Servi\u00e7o. \u00c9 um acordo entre a empresa e o cliente acerca do servi\u00e7o contratado. Por exemplo, se assinamos com o cliente que vamos manter ativo o seu ecommerce durante pelo menos 99,99% do tempo do m\u00eas, isso quer dizer que o m\u00e1ximo de tempo que a p\u00e1gina pode estar inacess\u00edvel durante o m\u00eas ser\u00e1 4 minutos e 19 segundos.</p> <p></p> <pre><code>\nflowchart LR\nsubgraph \"SLI\"\n  a(\"M\u00e9tricas\")\nend\nsubgraph \"SLO\"\n  b(\"Objetivos\")\nend\nsubgraph \"SLA\"\n  c(\"Promessas\")\nend\n\n\nSLI --&gt; SLO --&gt; SLA --&gt; SLI</code></pre>"},{"location":"handout/business/#cicd-continuous-integration-and-continuous-delivery","title":"CI/CD - Continuous Integration and Continuous Delivery","text":"<p>CI/CD \u00e9 uma abordagem pr\u00e1tica e \u00e1gil para o desenvolvimento de software que combina duas pr\u00e1ticas: Integra\u00e7\u00e3o Cont\u00ednua (CI) e Entrega Cont\u00ednua/Implanta\u00e7\u00e3o Cont\u00ednua (CD). Esses processos automatizam a constru\u00e7\u00e3o, teste e implanta\u00e7\u00e3o de aplica\u00e7\u00f5es, facilitando um ciclo de desenvolvimento mais r\u00e1pido e confi\u00e1vel.</p>"},{"location":"handout/business/#conceito-de-cicd","title":"Conceito de CI/CD","text":"<ol> <li>Integra\u00e7\u00e3o Cont\u00ednua (CI):</li> <li>Objetivo: Automatizar a integra\u00e7\u00e3o de c\u00f3digo de m\u00faltiplos desenvolvedores em um reposit\u00f3rio central v\u00e1rias vezes ao dia.</li> <li>Processo: Sempre que um desenvolvedor faz commit de c\u00f3digo em um reposit\u00f3rio, um servidor de CI automaticamente verifica e testa o novo c\u00f3digo para detectar problemas rapidamente.</li> <li> <p>Ferramentas Comuns: Jenkins, Travis CI, CircleCI, GitLab CI/CD.</p> </li> <li> <p>Entrega Cont\u00ednua (CD - Continuous Delivery):</p> </li> <li>Objetivo: Automatizar a entrega de c\u00f3digo para um ambiente de produ\u00e7\u00e3o de maneira segura e r\u00e1pida.</li> <li>Processo: Ap\u00f3s a fase de integra\u00e7\u00e3o cont\u00ednua, o c\u00f3digo \u00e9 preparado para a produ\u00e7\u00e3o atrav\u00e9s de uma s\u00e9rie de testes automatizados. O c\u00f3digo est\u00e1 sempre pronto para ser implantado com um simples clique ou comando.</li> <li> <p>Ferramentas Comuns: Jenkins, GitLab CI/CD, Bamboo.</p> </li> <li> <p>Implanta\u00e7\u00e3o Cont\u00ednua (CD - Continuous Deployment):</p> </li> <li>Objetivo: Automatizar a implanta\u00e7\u00e3o de c\u00f3digo diretamente em produ\u00e7\u00e3o sem interven\u00e7\u00e3o manual.</li> <li>Processo: Ap\u00f3s passar por todos os testes, o c\u00f3digo \u00e9 automaticamente implantado em produ\u00e7\u00e3o. Isso requer um alto n\u00edvel de confian\u00e7a nos testes automatizados.</li> <li>Ferramentas Comuns: Jenkins, GitLab CI/CD, Spinnaker.</li> </ol>"},{"location":"handout/business/#vantagens-do-cicd","title":"Vantagens do CI/CD","text":"<ol> <li>Detec\u00e7\u00e3o Precoce de Problemas: Integra\u00e7\u00e3o cont\u00ednua ajuda a detectar e corrigir problemas rapidamente.</li> <li>Entrega R\u00e1pida: Automatiza\u00e7\u00e3o da entrega permite que novas funcionalidades e corre\u00e7\u00f5es cheguem aos usu\u00e1rios mais rapidamente.</li> <li>Qualidade e Confiabilidade: Testes automatizados garantem que o c\u00f3digo est\u00e1 funcionando conforme esperado antes de ser implantado.</li> <li>Feedback R\u00e1pido: Desenvolvedores recebem feedback r\u00e1pido sobre o estado do c\u00f3digo, facilitando um desenvolvimento mais \u00e1gil e iterativo.</li> <li>Automa\u00e7\u00e3o: Reduz o trabalho manual, minimizando erros humanos e aumentando a efici\u00eancia.</li> </ol>"},{"location":"handout/business/#conclusao","title":"Conclus\u00e3o","text":"<p>CI/CD \u00e9 uma pr\u00e1tica essencial no desenvolvimento moderno de software, promovendo automa\u00e7\u00e3o, rapidez e confiabilidade nos processos de integra\u00e7\u00e3o, teste e implanta\u00e7\u00e3o de aplica\u00e7\u00f5es. Utilizando ferramentas como Jenkins, GitLab CI/CD e outras, equipes de desenvolvimento podem entregar software de alta qualidade de forma cont\u00ednua e eficiente.</p> <p> </p> Source: Wikipedia - Devops"},{"location":"handout/business/#iac-infrastructure-as-code","title":"IaC - Infrastructure as Code","text":"<p>IaC, ou \"Infrastructure as Code\" (Infraestrutura como C\u00f3digo), \u00e9 uma abordagem para gerenciar e provisionar a infraestrutura de TI atrav\u00e9s de arquivos de configura\u00e7\u00e3o leg\u00edveis por humanos, em vez de processos manuais. Esta pr\u00e1tica permite automatizar a configura\u00e7\u00e3o de infraestrutura, tornando-a mais eficiente, replic\u00e1vel e gerenci\u00e1vel.</p>"},{"location":"handout/business/#conceito-de-iac","title":"Conceito de IaC","text":"<p>Em vez de configurar manualmente servidores, redes, e outros componentes de infraestrutura, voc\u00ea escreve c\u00f3digo para definir e gerenciar essas configura\u00e7\u00f5es. Esse c\u00f3digo pode ser armazenado em sistemas de controle de vers\u00e3o, revisado, testado e aplicado de maneira consistente.</p>"},{"location":"handout/business/#ferramentas-comuns-de-iac","title":"Ferramentas Comuns de IaC","text":"<ol> <li>Terraform: Uma ferramenta de c\u00f3digo aberto que permite definir a infraestrutura em um arquivo de configura\u00e7\u00e3o usando o HashiCorp Configuration Language (HCL) ou JSON.</li> <li>AWS CloudFormation: Um servi\u00e7o da Amazon Web Services que permite modelar e configurar recursos da AWS.</li> <li>Ansible: Uma ferramenta que pode automatizar o provisionamento de infraestrutura, al\u00e9m de gerenciamento de configura\u00e7\u00e3o e implanta\u00e7\u00e3o de aplica\u00e7\u00f5es.</li> </ol>"},{"location":"handout/business/#vantagens-do-iac","title":"Vantagens do IaC","text":"<ol> <li>Consist\u00eancia: A infraestrutura \u00e9 provisionada de forma consistente cada vez que o c\u00f3digo \u00e9 executado.</li> <li>Reprodutibilidade: F\u00e1cil de replicar ambientes, como desenvolvimento, teste e produ\u00e7\u00e3o.</li> <li>Controle de Vers\u00e3o: As configura\u00e7\u00f5es de infraestrutura podem ser versionadas e auditadas, assim como o c\u00f3digo de aplica\u00e7\u00e3o.</li> <li>Automa\u00e7\u00e3o: Reduz o erro humano e aumenta a velocidade ao automatizar tarefas repetitivas.</li> <li>Documenta\u00e7\u00e3o: O pr\u00f3prio c\u00f3digo serve como documenta\u00e7\u00e3o da infraestrutura.</li> </ol>"},{"location":"handout/business/#conclusao_1","title":"Conclus\u00e3o","text":"<p>IaC transforma a gest\u00e3o de infraestrutura, permitindo uma abordagem mais \u00e1gil, escal\u00e1vel e segura. Usando ferramentas como Terraform, CloudFormation ou Ansible, equipes podem definir, gerenciar e versionar a infraestrutura de maneira eficiente e confi\u00e1vel.</p>"},{"location":"handout/business/#iaas-infrastructure-as-a-service","title":"IaaS - Infrastructure as a Service","text":"<p>IaaS, ou \"Infrastructure as a Service\" (Infraestrutura como Servi\u00e7o), \u00e9 um modelo de servi\u00e7o de computa\u00e7\u00e3o em nuvem que oferece recursos computacionais fundamentais como servidores virtuais, armazenamento, e redes, sob demanda, na internet. Esses recursos s\u00e3o escal\u00e1veis e gerenciados por um provedor de servi\u00e7os, permitindo que as empresas evitem o custo e a complexidade de comprar e gerenciar a pr\u00f3pria infraestrutura f\u00edsica.</p>"},{"location":"handout/business/#conceito-de-iaas","title":"Conceito de IaaS","text":"<p>Com IaaS, os usu\u00e1rios podem alugar recursos de computa\u00e7\u00e3o, como m\u00e1quinas virtuais, armazenamento, e redes, e pagar somente pelo que utilizam. Esse modelo oferece flexibilidade, escalabilidade e efici\u00eancia, permitindo que as empresas foquem em suas aplica\u00e7\u00f5es e servi\u00e7os em vez de gerenciar a infraestrutura subjacente.</p>"},{"location":"handout/business/#provedores-comuns-de-iaas","title":"Provedores Comuns de IaaS","text":"<ol> <li>Amazon Web Services (AWS): Oferece servi\u00e7os como EC2 (Elastic Compute Cloud), S3 (Simple Storage Service), e VPC (Virtual Private Cloud).</li> <li>Microsoft Azure: Oferece servi\u00e7os como Azure Virtual Machines, Azure Blob Storage, e Virtual Networks.</li> <li>Google Cloud Platform (GCP): Oferece servi\u00e7os como Compute Engine, Cloud Storage, e Virtual Private Cloud.</li> </ol>"},{"location":"handout/business/#vantagens-do-iaas","title":"Vantagens do IaaS","text":"<ol> <li>Escalabilidade: Capacidade de aumentar ou diminuir recursos rapidamente conforme a demanda.</li> <li>Custo-Efetivo: Pague apenas pelos recursos que utiliza, sem necessidade de grandes investimentos iniciais em hardware.</li> <li>Flexibilidade: Escolha e configure recursos conforme suas necessidades espec\u00edficas.</li> <li>Redu\u00e7\u00e3o de Tempo: Rapidamente provisiona e deprovisiona recursos, acelerando a implementa\u00e7\u00e3o de novos projetos.</li> <li>Gerenciamento: O provedor de IaaS gerencia a infraestrutura f\u00edsica, enquanto voc\u00ea gerencia apenas os recursos alocados.</li> </ol>"},{"location":"handout/business/#conclusao_2","title":"Conclus\u00e3o","text":"<p>IaaS oferece uma solu\u00e7\u00e3o poderosa e flex\u00edvel para organiza\u00e7\u00f5es que precisam de infraestrutura computacional robusta sem o \u00f4nus de gerenciar hardware f\u00edsico. Provedores como AWS, Azure, e GCP facilitam o provisionamento e gerenciamento de servidores, armazenamento e redes, permitindo que as empresas se concentrem no desenvolvimento e opera\u00e7\u00e3o de suas aplica\u00e7\u00f5es e servi\u00e7os.</p>"},{"location":"handout/business/#paas-platform-as-a-service","title":"PaaS - Platform as a Service","text":"<p>PaaS, ou \"Platform as a Service\" (Plataforma como Servi\u00e7o), \u00e9 um modelo de servi\u00e7o de computa\u00e7\u00e3o em nuvem que fornece uma plataforma permitindo que os clientes desenvolvam, executem e gerenciem aplica\u00e7\u00f5es sem a complexidade de construir e manter a infraestrutura normalmente associada ao desenvolvimento e ao lan\u00e7amento de uma aplica\u00e7\u00e3o.</p>"},{"location":"handout/business/#exemplo-de-paas","title":"Exemplo de PaaS","text":"<p>Imagine que voc\u00ea \u00e9 um desenvolvedor de software e deseja criar um aplicativo web.</p> <p>Sem PaaS</p> <ul> <li>Configura\u00e7\u00e3o do Servidor: Voc\u00ea precisaria comprar servidores f\u00edsicos ou m\u00e1quinas virtuais para hospedar sua aplica\u00e7\u00e3o.</li> <li>Instala\u00e7\u00e3o do Sistema Operacional: Configurar o sistema operacional nos servidores.</li> <li>Configura\u00e7\u00e3o de Redes e Seguran\u00e7a: Configurar redes, firewalls, e garantir a seguran\u00e7a da aplica\u00e7\u00e3o.</li> <li>Banco de Dados: Instalar e gerenciar o banco de dados.</li> <li>Manuten\u00e7\u00e3o: Monitorar e manter o sistema, aplicando patches de seguran\u00e7a e atualiza\u00e7\u00f5es.</li> </ul> <p>Com PaaS</p> <ul> <li>Escolha da Plataforma: Voc\u00ea escolhe uma plataforma PaaS, como Google App Engine, Microsoft Azure, ou Heroku.</li> <li>Desenvolvimento da Aplica\u00e7\u00e3o: Foca apenas no desenvolvimento do c\u00f3digo da aplica\u00e7\u00e3o.</li> <li>Desdobramento: Sobe (deploy) o c\u00f3digo para a plataforma PaaS.</li> <li>Gest\u00e3o e Escalabilidade: A plataforma cuida automaticamente da hospedagem, seguran\u00e7a, balanceamento de carga, escalabilidade, e manuten\u00e7\u00e3o.</li> </ul>"},{"location":"handout/business/#vantagens-do-paas","title":"Vantagens do PaaS","text":"<ul> <li>Redu\u00e7\u00e3o de Complexidade: Voc\u00ea n\u00e3o precisa se preocupar com a infraestrutura subjacente.</li> <li>Escalabilidade: F\u00e1cil de escalar sua aplica\u00e7\u00e3o conforme a demanda.</li> <li>Foco no Desenvolvimento: Permite focar mais no desenvolvimento da aplica\u00e7\u00e3o e menos na gest\u00e3o de servidores.</li> <li>Custo-Efetivo: Geralmente paga-se apenas pelos recursos usados, evitando grandes investimentos iniciais em hardware.</li> </ul>"},{"location":"handout/business/#conclusao_3","title":"Conclus\u00e3o","text":"<p>Em resumo, PaaS permite que desenvolvedores se concentrem em criar e melhorar suas aplica\u00e7\u00f5es sem se preocupar com a infraestrutura necess\u00e1ria para suport\u00e1-las.</p>"},{"location":"handout/business/#paap-platform-as-a-product","title":"PaaP - Platform as a Product","text":"<p>\"PaaP\" significa \"Plataforma como Produto\", um conceito que v\u00ea uma plataforma n\u00e3o apenas como um conjunto de ferramentas ou servi\u00e7os, mas como um produto completo e coeso que fornece uma solu\u00e7\u00e3o abrangente para seus usu\u00e1rios. \u00c9 diferente de Plataforma como Servi\u00e7o (PaaS), que geralmente foca em fornecer a infraestrutura e o ambiente para desenvolver, executar e gerenciar aplica\u00e7\u00f5es. PaaP enfatiza a experi\u00eancia do usu\u00e1rio, a integra\u00e7\u00e3o e o valor entregue ao usu\u00e1rio como um produto unificado.</p>"},{"location":"handout/business/#conceitos-chave-do-paap","title":"Conceitos-Chave do PaaP","text":"<ol> <li> <p>Solu\u00e7\u00e3o de Ponta a Ponta: PaaP fornece uma solu\u00e7\u00e3o completa que cobre todos os aspectos das necessidades do usu\u00e1rio, desde o desenvolvimento e implanta\u00e7\u00e3o at\u00e9 o gerenciamento e escalabilidade. Ele integra v\u00e1rias ferramentas e servi\u00e7os em uma experi\u00eancia cont\u00ednua.</p> </li> <li> <p>Design Centrado no Usu\u00e1rio: A plataforma \u00e9 projetada com foco na experi\u00eancia do usu\u00e1rio. Prioriza a facilidade de uso, interfaces intuitivas e fluxos de trabalho simplificados para garantir que os usu\u00e1rios possam atingir seus objetivos de forma eficiente.</p> </li> <li> <p>Integra\u00e7\u00e3o e Interoperabilidade: Plataformas PaaP frequentemente integram m\u00faltiplos servi\u00e7os e ferramentas, garantindo que eles funcionem juntos de forma harmoniosa. Essa integra\u00e7\u00e3o reduz a complexidade para os usu\u00e1rios, que n\u00e3o precisam gerenciar sistemas diferentes.</p> </li> <li> <p>Entrega de Valor: A plataforma \u00e9 empacotada e comercializada como um produto que entrega proposi\u00e7\u00f5es de valor espec\u00edficas aos seus usu\u00e1rios. \u00c9 projetada para resolver problemas espec\u00edficos ou atender necessidades espec\u00edficas de maneira abrangente.</p> </li> <li> <p>Melhoria Cont\u00ednua: Produtos PaaP s\u00e3o continuamente melhorados com base no feedback dos usu\u00e1rios e nas demandas do mercado. Atualiza\u00e7\u00f5es e aprimoramentos regulares garantem que a plataforma permane\u00e7a relevante e eficaz.</p> </li> </ol>"},{"location":"handout/business/#exemplo-salesforce","title":"Exemplo: Salesforce","text":"<p>O Salesforce \u00e9 um exemplo not\u00e1vel de Plataforma como Produto. Ele oferece uma su\u00edte abrangente de ferramentas para gerenciamento de relacionamento com clientes (CRM), mas vai al\u00e9m de apenas fornecer infraestrutura.</p> <ol> <li> <p>Solu\u00e7\u00e3o de CRM de Ponta a Ponta: O Salesforce fornece ferramentas para vendas, atendimento ao cliente, automa\u00e7\u00e3o de marketing, an\u00e1lises e mais, tudo integrado em uma \u00fanica plataforma.</p> </li> <li> <p>Design Centrado no Usu\u00e1rio: O Salesforce \u00e9 projetado para ser f\u00e1cil de usar, com pain\u00e9is personaliz\u00e1veis, interfaces intuitivas e amplos recursos de suporte.</p> </li> <li> <p>Integra\u00e7\u00e3o e Interoperabilidade: Ele integra com uma ampla gama de aplica\u00e7\u00f5es e servi\u00e7os de terceiros, permitindo que os usu\u00e1rios conectem seu CRM com outras ferramentas que utilizam em seus neg\u00f3cios.</p> </li> <li> <p>Entrega de Valor: O Salesforce \u00e9 comercializado como um produto que ajuda as empresas a gerenciar seus relacionamentos com clientes de forma mais eficaz, melhorar as vendas e aprimorar o atendimento ao cliente.</p> </li> <li> <p>Melhoria Cont\u00ednua: O Salesforce lan\u00e7a regularmente atualiza\u00e7\u00f5es e novos recursos com base no feedback dos usu\u00e1rios e nos avan\u00e7os tecnol\u00f3gicos, garantindo que a plataforma evolua com as necessidades dos usu\u00e1rios.</p> </li> </ol>"},{"location":"handout/business/#beneficios-do-paap","title":"Benef\u00edcios do PaaP","text":"<ol> <li> <p>Experi\u00eancia do Usu\u00e1rio Simplificada: os usu\u00e1rios interagem com uma \u00fanica plataforma unificada, simplificando seu fluxo de trabalho e reduzindo a necessidade de gerenciar m\u00faltiplas ferramentas.</p> </li> <li> <p>Aumento da Produtividade: ferramentas e servi\u00e7os integrados simplificam os processos, levando a uma maior efici\u00eancia e produtividade.</p> </li> <li> <p>Escalabilidade: solu\u00e7\u00f5es PaaP s\u00e3o projetadas para escalar com as necessidades do usu\u00e1rio, facilitando o crescimento sem a necessidade de trocar de plataformas ou ferramentas.</p> </li> <li> <p>Maior Valor: ao fornecer uma solu\u00e7\u00e3o abrangente, PaaP entrega maior valor aos usu\u00e1rios, atendendo suas necessidades de forma mais eficaz do que ferramentas dispersas.</p> </li> <li> <p>Adapta\u00e7\u00e3o Cont\u00ednua: atualiza\u00e7\u00f5es e melhorias regulares garantem que a plataforma permane\u00e7a relevante e \u00fatil \u00e0 medida que as necessidades dos usu\u00e1rios evoluem.</p> </li> </ol>"},{"location":"handout/business/#conclusao_4","title":"Conclus\u00e3o","text":"<p>Plataforma como Produto (PaaP) representa uma abordagem hol\u00edstica para a entrega de solu\u00e7\u00f5es tecnol\u00f3gicas, focando em fornecer produtos completos, integrados e centrados no usu\u00e1rio. Ao combinar as for\u00e7as de v\u00e1rias ferramentas e servi\u00e7os em uma plataforma coesa, PaaP oferece maior valor, simplicidade e efici\u00eancia aos seus usu\u00e1rios. Salesforce \u00e9 um exemplo not\u00e1vel, mas os princ\u00edpios de PaaP podem ser aplicados em diversas ind\u00fastrias e solu\u00e7\u00f5es tecnol\u00f3gicas para criar plataformas mais eficazes e amig\u00e1veis.</p> <ol> <li> <p> Platform Revolution: How Networked Markets Are Transforming the Economy and How to Make Them Work for You \u21a9</p> </li> </ol>"},{"location":"handout/cloud/aws/cli/","title":"Cli","text":""},{"location":"handout/cloud/aws/cli/#setting-up-the-aws-cli","title":"Setting up the AWS Cli","text":"<pre><code>aws configure\n</code></pre> aws configureAWS Access Key ID: ****************5DMGAWS Secret Access Key]: *********************************fhwQtDefault region name [None]: Default output format [None]:  <pre><code>aws sts get-session-token\n</code></pre> aws sts get-session-token{    \"Credentials\": {        \"AccessKeyId\": \"ASIA4MTWJ5HP4RFKVFX2\",        \"SecretAccessKey\": \"RWfqFn9NZRZYEy1a5sFpdUPSd5i03YRer/9+PZ6V\",        \"SessionToken\": \"FwoGZXIvYXdzEJX//////////wEaDIRJrTOKnJTZ/        ZpZGiKCAYnnc+16sxQl/eGYvj998q9u2eFb3VziCgpvNzKAuI/YcthL2XLp2VUXZswaOb5C3BikDENEKVbeH4va32ltJ/1Bm+F/        qkHNE9dTRMOxshV9iwkCe3/4+Sl9O6dZJguglcCq2Yfh+9HDzJxo6WtAd7UiCL6C/        hlcWgRS24IhvbdUDsgoy47qsQYyKNwLwW9ki4w5bmYRM9MVMinufs4LEkVRJGpEmc8        RG3gNaGvnRB0d840=\",        \"Expiration\": \"2024-05-08T07:55:55+00:00\"    }} <pre><code>aws sts get-caller-identity\n</code></pre> aws sts get-caller-identity{    \"UserId\": \"AIDA4MTWJ5HPRUU7R22VG\",    \"Account\": \"851725380063\",    \"Arn\": \"arn:aws:iam::851725380063:user/root\"}"},{"location":"handout/cloud/aws/cli/#reference","title":"Reference","text":"<ul> <li> <p>AWS Command Line Interface Documentation - https://docs.aws.amazon.com/cli/</p> <ul> <li> <p>User Guide - Install AWS Cli</p> <p></p> </li> </ul> </li> </ul>"},{"location":"handout/cloud/aws/eks/","title":"Eks","text":""},{"location":"handout/cloud/aws/eks/#elastic-kubernetes-service","title":"Elastic Kubernetes Service","text":"<p>Never spend your money before you have it, Jefferson T.</p> <p>EKS n\u00e3o tem cota gr\u00e1tis, sempre \u00e9 muito bem cobrado.</p>"},{"location":"handout/cloud/aws/eks/#rise-up-an-eks","title":"Rise up an EKS","text":""},{"location":"handout/cloud/aws/eks/#1-creating-a-role","title":"1. Creating a role","text":"<p>IAM - Identity and Access Management: gerencia usu\u00e1rios e acessos.</p> <p>Role \u00e9 um grupo de policiies que est\u00e3o vinculadas a servi\u00e7os AWS, assim, o EKS precisa de permissionamento para acessar os recursos da AWS.</p> <p></p> <p></p> <p></p>"},{"location":"handout/cloud/aws/eks/#2-creating-a-vpc","title":"2. Creating a VPC","text":"<p>Virtual Private Cloud</p> <p>Organiza\u00e7\u00e3o do Kubernetes</p> Kubernetes Components <sup>2</sup> <p>\u00c9 necess\u00e1rio criar uma estrutura de rede para suportar o Kubernetes, para isso, \u00e9 aconselh\u00e1vel utilizar um template do Cloud Formation. Abaixe o arquivo amazon-eks-vpc-private-subnets.yaml e d\u00ea um upload na cria\u00e7\u00e3o da VPC.</p> <p></p> <pre><code>https://s3.us-west-2.amazonaws.com/amazon-eks/cloudformation/2020-10-29/amazon-eks-vpc-private-subnets.yaml\n</code></pre> <p></p> <p></p> <pre><code>flowchart TB\n  subgraph Region\n    direction LR\n    subgraph Zone A\n      direction LR\n      subgraph subpri1[\"Subnet Private\"]\n        direction TB\n        poda1[\"pod 1\"]\n        poda2[\"pod 2\"]\n        poda3[\"pod 3\"]\n      end\n      subgraph subpub1[\"Subnet Public\"]\n        loadbalancea[\"Load Balance\"]\n      end\n    end\n    subgraph Zone B\n      direction LR\n      subgraph subpri2[\"Subnet Private\"]\n        direction TB\n        podb1[\"pod 1\"]\n        podb2[\"pod 2\"]\n        podb3[\"pod 3\"]\n      end\n      subgraph subpub2[\"Subnet Public\"]\n        loadbalanceb[\"Load Balance\"]\n      end\n    end\n    User --&gt; loadbalancea\n    loadbalancea --&gt; poda1\n    loadbalancea --&gt; poda2\n    loadbalancea --&gt; poda3\n    User --&gt; loadbalanceb\n    loadbalanceb --&gt; podb1\n    loadbalanceb --&gt; podb2\n    loadbalanceb --&gt; podb3\n  end</code></pre> <p>gateway --&gt; auth gateway --&gt; discovery</p>"},{"location":"handout/cloud/aws/eks/#3-building-an-eks","title":"3. Building an EKS","text":""},{"location":"handout/cloud/aws/eks/#4-accessing-the-eks","title":"4. Accessing the EKS","text":"<p>On terminal, after that it had been set up the aws cli.</p> <pre><code>aws configure\n</code></pre> <p>See the configuration that was done.</p> <pre><code>aws configure list\n</code></pre> aws configure list      Name                    Value             Type    Location      ----                    -----             ----    --------   profile                &lt;not set&gt;             None    Noneaccess_key     ****************TTNI shared-credentials-file    secret_key     ****************zAJ1 shared-credentials-file        region                us-east-2      config-file    ~/.aws/config <p>Set up the kube-config to point to the remote aws eks cluster.</p> <pre><code>aws eks update-kubeconfig --name eks-store\n</code></pre> aws eks update-kubeconfig --name eks-storeAdded new context arn:aws:eks:us-east-2:058264361068:cluster/eks-store to /Users/sandmann/.kube/config&gt;&gt;kubectl get podsNo resources found in default namespace.&gt;&gt;kubectl get nodesNo resources found&gt; <p>Come back to AWS EKS &gt; compute:</p> <p></p> <p>Notice that there no nodes on cluster also, because only the Control Pane had been created, there is no exist a node for the worker nodes.</p> <p>Attach roles to node group, it is exclusive for the worker nodes.</p> <p>IAM &gt; Roles</p> <p></p> <p>Add Permissions</p> <ul> <li>AmazonEKS_CNI_Policy (Configuration Network Interface)</li> <li>AmazonEKSWorkerNodePolicy</li> <li>AmazonEC2ContainerRegistryReadOnly</li> </ul> <p>Review</p> <p></p> <p>Group Node Group</p> <p></p> <p></p> <p>Only private subnets:</p> <p></p> <pre><code>kubectl get nodes\n</code></pre> kubectl get nodesNAME                                            STATUS   ROLES    AGE   VERSIONip-192-168-179-174.us-east-2.compute.internal   Ready    &lt;none&gt;   54s   v1.29.3-eks-ae9a62aip-192-168-204-234.us-east-2.compute.internal   Ready    &lt;none&gt;   54s   v1.29.3-eks-ae9a62a <p>Now, deploy the microservice.</p> kubectl apply -f ./k8s/deployment.yamldeployment.apps/gateway createdkubectl apply -f ./k8s/service.yamlservice/gateway created&gt;&gt;&gt;kubectl get allNAME                           READY   STATUS    RESTARTS   AGEpod/gateway-7894679df8-lbngj   1/1     Running   0          81sNAME                 TYPE           CLUSTER-IP     EXTERNAL-IP                                                               PORT(S)          AGEservice/gateway      LoadBalancer   10.100.245.4   a3a5cc62ba81e466e9746f64f83fc349-1127848642.us-east-2.elb.amazonaws.com   8080:32681/TCP   25mservice/kubernetes   ClusterIP      10.100.0.1     &lt;none&gt;                                                                    443/TCP          87mNAME                      READY   UP-TO-DATE   AVAILABLE   AGEdeployment.apps/gateway   1/1     1            1           82sNAME                                 DESIRED   CURRENT   READY   AGEreplicaset.apps/gateway-7894679df8   1         1         1       82s&gt; <p>Jenkins update</p> <p>Jenkins precisa instalar o awscli (adicionar ao <code>docker-compose.yaml</code>) </p><pre><code>RUN apt-get install -y awscli\n</code></pre><p></p> <p>Dentro da inst\u00e2ncia, configurar:</p> <pre><code>&gt; aws configure\n&gt; aws eks update-kubeconfig --name eks-store\n</code></pre> <p>Scale</p> <pre><code>&gt; kubectl scale --replicas=3 deployment/gateway\n</code></pre> <p></p>kubectl scale --replicas=3 deployment/gatewaydeployment.apps/gateway scaledkubectl get podsNAME                       READY   STATUS    RESTARTS   AGEgateway-7894679df8-62m7z   1/1     Running   0          12sgateway-7894679df8-r2kp2   1/1     Running   0          12sgateway-7894679df8-v6xhs   1/1     Running   0          5m58s<p></p>"},{"location":"handout/cloud/aws/eks/#references","title":"References:","text":"<ol> <li> <p>Setting up to use Amazon EKS \u21a9</p> </li> <li> <p>Kubernetes Components \u21a9</p> </li> <li> <p> Como criar um cluster Kubernetes na AWS com EKS by Fabricio Veronez</p> <p> \u21a9</p> </li> <li> <p>Creating a VPC for your Amazon EKS cluster \u21a9</p> </li> <li> <p>AWS Princing Calculator - EKS \u21a9</p> </li> <li> <p>Getting started with Amazon EKS \u2013 AWS Management Console and AWS CLI \u21a9</p> </li> <li> <p>kubectl scale \u21a9</p> </li> </ol>"},{"location":"handout/devops/jenkins/","title":"Jenkins","text":"Docker ComposeEnvironment Variables docker-compose.yaml<pre><code># docker compose up -d --build --force-recreate\nversion: '3.8'\nname: ops\n\nservices:\n\njenkins:\n    container_name: jenkins\n    build:\n    dockerfile_inline: |\n        FROM jenkins/jenkins:jdk21\n        USER root\n        RUN apt-get update &amp;&amp; apt-get install -y lsb-release\n        RUN curl -fsSLo /usr/share/keyrings/docker-archive-keyring.asc \\\n        https://download.docker.com/linux/debian/gpg\n        RUN echo \"deb [arch=$(dpkg --print-architecture) \\\n        signed-by=/usr/share/keyrings/docker-archive-keyring.asc] \\\n        https://download.docker.com/linux/debian \\\n        $(lsb_release -cs) stable\" &gt; /etc/apt/sources.list.d/docker.list\n\n        RUN apt-get update &amp;&amp; apt-get install -y docker-ce maven\n\n        RUN apt-get install -y apt-transport-https ca-certificates curl\n        RUN curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n        RUN chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n        RUN echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list\n        RUN chmod 644 /etc/apt/sources.list.d/kubernetes.list\n        RUN apt-get update\n        RUN apt-get install -y kubectl\n\n        RUN apt-get install -y awscli\n\n        RUN usermod -aG docker jenkins\n    ports:\n        - 9080:8080\n        - 50000:50000 \n    volumes:\n        - $CONFIG/jenkins:/var/jenkins_home\n        - /var/run/docker.sock:/var/run/docker.sock\n    restart: always\n    networks:\n        - infra\n\nnetworks:\n    infra:\n        driver: bridge\n</code></pre> .env<pre><code>CONFIG=./config\n</code></pre> <p>To run this container:</p> <pre><code>docker compose up -d --build\n</code></pre> <p>The will be avaliable at: </p><pre><code>http://localhost:9000\n</code></pre><p></p>"},{"location":"handout/devops/jenkins/#pipeline","title":"Pipeline","text":""},{"location":"handout/devops/jenkins/#checkout-scm","title":"Checkout SCM","text":"Jenkinsfile<pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                sh 'mvn -B -DskipTests clean install'\n            }\n        }\n    }\n}\n</code></pre> <p>Definindo o n\u00famero m\u00e1ximo de executores. </p> <p>Instalando o plugin para executar o Docker dentro do Jenkins container.</p> <p></p> <p></p> <p>BASED ARTICLE:</p> <p>Getting \u201cPermission Denied\u201d error when pulling a docker image in Jenkins docker container on Mac</p>"},{"location":"handout/devops/kubernetes/","title":"Kubernetes","text":""},{"location":"handout/devops/kubernetes/#minikube","title":"Minikube","text":"<p>Vers\u00e3o light do kubernetes, para rodar em m\u00e1quinas locais. Instala\u00e7\u00e3o do Kubernetes.</p> <p>Para Inicializar o Minikube ap\u00f3s a instala\u00e7\u00e3o, utilize:</p> <pre><code>minikube start --driver=docker --profile=store\n</code></pre> <pre><code>minikube profile list\n</code></pre> <pre><code>minikube delete --all\n</code></pre> <pre><code>minikube delete --all --purge\n</code></pre> <p>Dashboard </p><pre><code>minikube dashboard\n</code></pre><p></p>"},{"location":"handout/devops/kubernetes/#kubectl","title":"Kubectl","text":"<p>Comando cliente de gerenciamento do Kubernetes.</p> <pre><code>kubectl apply -f &lt;filename&gt;\n</code></pre> <pre><code>kubectl get deployments\n</code></pre> <pre><code>kubectl get svc\n</code></pre> <pre><code>kubectl get pods\n</code></pre> <pre><code>kubectl port-forward &lt;pod&gt; 8080:8080\n</code></pre> <pre><code>kubectl exec -it &lt;pod&gt; -- bash\n</code></pre> <pre><code>kubectl delete --all\n</code></pre> <pre><code>kubectl api-resources\n</code></pre> <pre><code>kubectl logs &lt;pod&gt;\n</code></pre> <pre><code>kubectl describe pod &lt;pod&gt;\n</code></pre> reset the core dns<pre><code>kubectl -n kube-system rollout restart deployment coredns\n</code></pre>"},{"location":"handout/devops/kubernetes/#services","title":"Services","text":"<ul> <li> <p>ClusterIp: apenas dentro do cluster.</p> </li> <li> <p>NodePort: permite exposi\u00e7\u00e3o de porta para fora do cluster.</p> </li> <li> <p>LoadBalance: uma porta para diversas inst\u00e2ncias no cluster.</p> </li> </ul>"},{"location":"handout/devops/kubernetes/#deploying-a-postgres","title":"Deploying a Postgres","text":"<p>Crie um novo reposit\u00f3rio para armazenar as configura\u00e7\u00f5es do banco de dados: platform.241.store.db.</p> estrutura de diret\u00f3rio sugerida<pre><code> store.account\n\ud83d\udcc1 store.db\n\u2514\u2500\u2500 \ud83d\udcc1 k8s\n    \u251c\u2500\u2500  configmap.yaml\n    \u251c\u2500\u2500  credentials.yaml\n    \u251c\u2500\u2500  pv.yaml\n    \u251c\u2500\u2500  pvc.yaml\n    \u251c\u2500\u2500  deployment.yaml\n    \u2514\u2500\u2500  service.yaml\n</code></pre> configmap.yamlcredentials.yamlpv.yamlpvc.yamldeployment.yamlservice.yaml <p>Configura\u00e7\u00e3o de conex\u00e3o do banco</p> configmap.yaml<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n    name: postgres-configmap\n    labels:\n        app: postgres\ndata:\n    POSTGRES_HOST: postgres\n    POSTGRES_DB: store\n</code></pre> <pre><code>kubectl apply -f ./k8s/configmap.yaml\nkubectl get configmap\n</code></pre> <p>Configura\u00e7\u00e3o de acesso ao banco</p> credentials.yaml<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n    name: postgres-credentials\ndata:\n    POSTGRES_USER: c3RvcmU=\n    POSTGRES_PASSWORD: c3RvcmU=\n</code></pre> <pre><code>kubectl apply -f ./k8s/credentials.yaml\nkubectl get secrets\n</code></pre> <p>Use encode base64 para ofuscar a senha. Vide: Base64Encode.</p> <p>Persistence Volume: espa\u00e7o alocado no cluster</p> pv.yaml<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n    name: postgres-volume\n    labels:\n        type: local\n        app: postgres\nspec:\n    storageClassName: manual\n    capacity:\n        storage: 10Gi\n    accessModes:\n        - ReadWriteMany\n    hostPath:\n        path: /data/postgresql\n</code></pre> <pre><code>kubectl apply -f ./k8s/pv.yaml\nkubectl get pv\n</code></pre> <p>Persistence Volume Claim: espa\u00e7o alocado do cluster para o pods.</p> pvc.yaml<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: postgres-volume-claim\n    labels:\n        app: postgres\nspec:\n    storageClassName: manual\n    accessModes:\n        - ReadWriteMany\n    resources:\n        requests:\n            storage: 10Gi\n</code></pre> <pre><code>kubectl apply -f ./k8s/pvc.yaml\nkubectl get pvc\n</code></pre> deployment.yaml<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n          - name: postgres\n            image: 'postgres:latest'\n            imagePullPolicy: IfNotPresent\n            ports:\n              - containerPort: 5432\n            env:\n\n              - name: POSTGRES_DB\n                valueFrom:\n                  configMapKeyRef:\n                    name: postgres-configmap\n                    key: POSTGRES_DB\n\n              - name: POSTGRES_USER\n                valueFrom:\n                  secretKeyRef:\n                    name: postgres-credentials\n                    key: POSTGRES_USER\n\n              - name: POSTGRES_PASSWORD\n                valueFrom:\n                  secretKeyRef:\n                    name: postgres-credentials\n                    key: POSTGRES_PASSWORD\n\n            volumeMounts:\n              - mountPath: /var/lib/postgresql/data\n                name: postgresdata\n      volumes:\n          - name: postgresdata\n            persistentVolumeClaim:\n              claimName: postgres-volume-claim\n</code></pre> <pre><code>kubectl apply -f ./k8s/deployment.yaml\nkubectl get deployments\nkubectl get pods\n</code></pre> service.yaml<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n    name: postgres\n    labels:\n        app: postgres\nspec:\n    type: ClusterIP\n    ports:\n        - port: 5432\n    selector:\n        app: postgres\n</code></pre> <pre><code>kubectl apply -f ./k8s/service.yaml\nkubectl get services\n</code></pre> <p>Acessando o pod do Postgres:</p> <pre><code>kubectl exec -it postgres-&lt;pod-id&gt; -- psql -h localhost -U store --password -p 5432 store\n</code></pre> <p>Redirecionando porta: </p><pre><code>kubectl port-forward &lt;pod&gt; 5432:5432\n</code></pre><p></p>"},{"location":"handout/devops/kubernetes/#deploying-the-discovery-microservice","title":"Deploying the Discovery Microservice","text":"discovery<pre><code>\ud83d\udcc1 store.discovery-resource\n\u251c\u2500\u2500 \ud83d\udcc1 src\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 main\n\u2502       \u2514\u2500\u2500 \ud83d\udcc1 resources\n\u2502           \u2514\u2500\u2500  application.yaml\n\u251c\u2500\u2500 \ud83d\udcc1 k8s\n\u2502   \u251c\u2500\u2500  configmap.yaml\n\u2502   \u251c\u2500\u2500  deployment.yaml\n\u2502   \u2514\u2500\u2500  service.yaml\n\u251c\u2500\u2500  Dockerfile\n\u251c\u2500\u2500  Jenkins\n\u2514\u2500\u2500  pom.xml\n</code></pre> configmap.yamldeployment.yamlservice.yaml configmap.yaml<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: discovery-configmap\n  labels:\n    app: discovery\ndata:\n  DISCOVERY_HOST: discovery    \n</code></pre> configmap.yaml<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: discovery\n  labels:\n    app: discovery\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: discovery\n  template:\n    metadata:\n      labels:\n        app: discovery\n    spec:\n      containers:\n        - name: discovery\n          image: humbertosandmann/discovery:latest\n          ports:\n            - containerPort: 8761\n</code></pre> service.yaml<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: discovery\n  labels:\n    app: discovery\nspec:\n  type: ClusterIP\n  ports:\n    - port: 8761\n      targetPort: 8761\n      protocol: TCP\n  selector:\n    app: discovery\n</code></pre>"},{"location":"handout/devops/kubernetes/#deploying-a-microservice","title":"Deploying a Microservice","text":"account<pre><code>\ud83d\udcc1 store.account-resource\n\u251c\u2500\u2500 \ud83d\udcc1 src\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 main\n\u2502       \u2514\u2500\u2500 \ud83d\udcc1 resources\n\u2502           \u2514\u2500\u2500  application.yaml\n\u251c\u2500\u2500 \ud83d\udcc1 k8s\n\u2502   \u251c\u2500\u2500  deployment.yaml\n\u2502   \u2514\u2500\u2500  service.yaml\n\u251c\u2500\u2500  Dockerfile\n\u251c\u2500\u2500  Jenkins\n\u2514\u2500\u2500  pom.xml\n</code></pre> application.yamldeployment.yamlservice.yaml application.yaml<pre><code>server:\n  port: 8080\n\nspring:\n  application:\n    name: account\n  datasource:\n    url: jdbc:postgresql://${POSTGRES_HOST}:5432/${POSTGRES_DB}\n    username: ${POSTGRES_USER:postgres}\n    password: ${POSTGRES_PASSWORD:Post123321}\n    driver-class-name: org.postgresql.Driver\n  flyway:\n    baseline-on-migrate: true\n    schemas: account\n  jpa:\n    properties:\n      hibernate:\n        default_schema: account\n\nmanagement:\n  endpoints:\n    web:\n      base-path: /account/actuator\n        exposure:\n          include: [ 'prometheus' ]\n\neureka:\n  client:\n    register-with-eureka: true\n    fetch-registry: true\n    service-url:\n    defaultZone: http://${DISCOVERY_HOST}:8761/eureka/\n</code></pre> <p>Subir no Git e rodar o Jenkins.</p> deployment.yaml<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: account\nspec:\n  selector:\n    matchLabels:\n      app: account\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: account\n    spec:\n      containers:\n        - name: account\n          image: humbertosandmann/account:latest\n          ports:\n            - containerPort: 8080\n          env:\n\n            - name: DISCOVERY_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: discovery-configmap\n                  key: DISCOVERY_HOST\n\n            - name: POSTGRES_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: postgres-configmap\n                  key: POSTGRES_HOST\n\n            - name: POSTGRES_DB\n              valueFrom:\n                configMapKeyRef:\n                  name: postgres-configmap\n                  key: POSTGRES_DB\n\n            - name: POSTGRES_USER\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_USER\n\n            - name: POSTGRES_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_PASSWORD\n</code></pre> service.yaml<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: account\n  labels:\n    name: account\nspec:\n  type: NodePort\n  ports:\n    - port: 8080\n      targetPort: 8080\n      protocol: TCP\n  selector:\n    app: account\n</code></pre> <pre><code>kubectl apply -f ./k8s/service.yaml\nkubectl get services\n</code></pre> <pre><code>kubectl apply -f k8s/deployment.yaml\nkubectl apply -f k8s/service.yaml  \n</code></pre>"},{"location":"handout/devops/kubernetes/#deploying-using-jenkins","title":"Deploying using Jenkins","text":""},{"location":"handout/devops/kubernetes/#creating-crendentials-for-jenkins-to-k8s","title":"Creating crendentials for Jenkins to K8s","text":"<p>Criar credentials no Kubernetes para que o Jenkins possa conectar.</p> jenkins.yaml<pre><code>---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: jenkins\n  namespace: default\n---\n\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: jenkins\n  namespace: default\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\",\"services\"]\n  verbs: [\"create\",\"delete\",\"get\",\"list\",\"patch\",\"update\",\"watch\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\"]\n  verbs: [\"create\",\"delete\",\"get\",\"list\",\"patch\",\"update\",\"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods/exec\"]\n  verbs: [\"create\",\"delete\",\"get\",\"list\",\"patch\",\"update\",\"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods/log\"]\n  verbs: [\"get\",\"list\",\"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  verbs: [\"get\",\"create\"]\n- apiGroups: [\"\"]\n  resources: [\"configmaps\"]\n  verbs: [\"create\",\"get\",\"update\"]\n- apiGroups: [\"\"]\n  resources: [\"persistentvolumeclaims\"]\n  verbs: [\"create\",\"delete\",\"get\",\"list\",\"patch\",\"update\",\"watch\"]\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: jenkins-token\n  annotations:\n    kubernetes.io/service-account.name: jenkins\ntype: kubernetes.io/service-account-token\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: jenkins\n  namespace: default\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: jenkins\nsubjects:\n- kind: ServiceAccount\n  name: jenkins\n---\n# Allows jenkins to create persistent volumes\n# This cluster role binding allows anyone in the \"manager\" group to read secrets in any namespace.\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: jenkins-crb\nsubjects:\n- kind: ServiceAccount\n  namespace: default\n  name: jenkins\nroleRef:\n  kind: ClusterRole\n  name: jenkinsclusterrole\n  apiGroup: rbac.authorization.k8s.io\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  # \"namespace\" omitted since ClusterRoles are not namespaced\n  name: jenkinsclusterrole\nrules:\n- apiGroups: [\"\"]\n  resources: [\"persistentvolumes\"]\n  verbs: [\"create\",\"delete\",\"get\",\"list\",\"patch\",\"update\",\"watch\"]\n</code></pre> <p>Executar a declara\u00e7\u00e3o: </p><pre><code>kubectl apply -f jenkins.yaml\n</code></pre><p></p>"},{"location":"handout/devops/kubernetes/#recovering-the-jenkins-token","title":"Recovering the Jenkins' Token","text":"<pre><code>kubectl get secrets\n</code></pre> kubectl get secretsNAME            TYPE                                  DATA   AGEjenkins-token   kubernetes.io/service-account-token   3      21s <p>Abrindo o objeto com o token.</p> <pre><code>kubectl describe secrets/jenkins-token\n</code></pre> kubectl describe secrets/jenkins-tokenName:         jenkins-tokenNamespace:    defaultLabels:       &lt;none&gt;Annotations:  kubernetes.io/service-account.name: jenkins              kubernetes.io/service-account.uid: 0d06d343-fd34-4aff-8396-5dfec5a9e5b6Type:  kubernetes.io/service-account-tokenData====ca.crt:     1111 bytesnamespace:  7 bytestoken:      eyJhbGciOiJSUzI1NiIsImtpZCI6IklqTkZXdEVKcW1iclBrNHBnQzJSX1F6QjFIWDFMX0FvNGVkNGd2aWFKd00ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImplbmtpbnMtdG9rZW4iLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiamVua2lucyIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBkMDZkMzQzLWZkMzQtNGFmZi04Mzk2LTVkZmVjNWE5ZTViNiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OmplbmtpbnMifQ.XkwD5vwC7CJNDv44PxCAIpLEfVlQbLE6VDNmTOEpFkaoe_x4ehU8QS8fnTgUz0a_vjUKuXum-PD2vF8Fx_WBsWVAG8BNhXJv79MMbEe7axYT7W91fjsnT0rMqSqzajNjTTDFvPDQu0KkLzC-UUnlG3RdNHhzxGVnUIA9lIeJuVKnlCXAexPQr6HeX5ggbe-CZO_uMjFZjwBnjLC-IJsIKKaz8I4CbFxz10vAl5SpJ7PadA1iZZEvr_VYhhG42qMqRFLzkrXtWUG0NX8aSitJT0Wk9c54ME13WDZb6MfRXwUWbARu-TLN56KrPaqtL2dBtRG2EFOn5nVXARI7jPzhjg Try it!!! <p>Abra o token no site jwt.io e verifique seu conte\u00fado.</p>"},{"location":"handout/devops/kubernetes/#set-up-the-credential-to-jenkins","title":"Set up the credential to Jenkins","text":"<p>Before to go ahead</p> <p>Instale os plugins: Kubernetes Cli e Kubernetes pipeline.</p> <p>Manage Jenkins &gt; Credentials</p> <p></p>"},{"location":"handout/devops/kubernetes/#updating-the-jenkinsfile","title":"Updating the Jenkinsfile","text":"<p>Adding the <code>Deploy on k8s</code> stage:</p> Jenkinsfile<pre><code>...\n    stage('Deploy on local k8s') {\n        steps {\n            withCredentials([ string(credentialsId: 'minikube-credentials', variable: 'api_token') ]) {\n                sh 'kubectl --token $api_token --server https://host.docker.internal:55529  --insecure-skip-tls-verify=true apply -f ./k8s/deployment.yaml '\n                sh 'kubectl --token $api_token --server https://host.docker.internal:55529  --insecure-skip-tls-verify=true apply -f ./k8s/service.yaml '\n            }\n        }\n    }\n...\n</code></pre>"},{"location":"handout/devops/kubernetes/#kubectl-config","title":"kubectl config","text":"<p>kubectl config get-contexts</p>"},{"location":"handout/devops/kubernetes/#references","title":"References:","text":"<p>[1^]: Using a Service to Expose Your App</p> <p>[2^]: Install Kubernetes's Tools</p> <p>[3^]: How to Deploy Postgres to Kubernetes Cluster</p> <p>[4^]: Spring boot, PostgreSQL and Kubernetes</p> <p>[5^]: Deploy nodejs App in a Minikube Kubernetes using Jenkins CI/CD pipeline</p> <p>[6^]: Horizontal Pod Autoscaling</p>"},{"location":"handout/devops/observability/","title":"Observability","text":"<ul> <li>Logging</li> <li>Monitoring</li> <li>Tracing</li> </ul>"},{"location":"handout/devops/observability/#microservice","title":"Microservice","text":"pom.xml<pre><code>&lt;!-- metricas de uso --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n&lt;!-- exporta no formato prometheus --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.micrometer&lt;/groupId&gt;\n    &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;\n    &lt;scope&gt;runtime&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre> application.yaml<pre><code>management:\n  endpoints:\n    web:\n      base-path: /gateway/actuator\n      exposure:\n        include: [ 'prometheus' ]\n</code></pre>"},{"location":"handout/devops/observability/#docker","title":"Docker","text":"docker-compose.yaml<pre><code>  prometheus:\n    image: prom/prometheus:latest\n    container_name: store-prometheus\n    ports:\n      - 9090:9090\n    volumes:\n      - $VOLUME/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n    networks:\n      - private-network\n\n  grafana:\n    container_name: store-grafana\n    image: grafana/grafana-enterprise\n    ports:\n      - 3000:3000\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n    volumes:\n      - $VOLUME/grafana:/var/lib/grafana\n      - $VOLUME/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources      \n    restart: always\n    networks:\n      - private-network\n</code></pre>"},{"location":"handout/devops/observability/#prometheus","title":"Prometheus","text":"$VOLUME/prometheus/prometheus.yml<pre><code>scrape_configs:\n\n  - job_name: 'GatewayMetrics'\n    metrics_path: '/gateway/actuator/prometheus'\n    scrape_interval: 1s\n    static_configs:\n      - targets:\n        - gateway:8080\n        labels:\n          application: 'Gateway Application'\n\n  - job_name: 'AuthMetrics'\n    metrics_path: '/auth/actuator/prometheus'\n    scrape_interval: 1s\n    static_configs:\n      - targets:\n        - auth:8080\n        labels:\n          application: 'Auth Application'\n\n  - job_name: 'AccountMetrics'\n    metrics_path: '/accounts/actuator/prometheus'\n    scrape_interval: 1s\n    static_configs:\n      - targets:\n        - account:8080\n        labels:\n          application: 'Account Application'\n</code></pre> <p>http://localhost:9090/</p>"},{"location":"handout/devops/observability/#grafana","title":"Grafana","text":"$VOLUME/grafana/provisioning/datasources/datasources.yml<pre><code>apiVersion: 1\ndatasources:\n  - name: Prometheus\n    type: prometheus\n    access: proxy\n    url: http://prometheus:9090\n    isDefault: true\n</code></pre> <p>http://localhost:3000/</p> <ul> <li>Dashboard MarketPlace</li> </ul>"},{"location":"handout/microservices/account/","title":"Account","text":"<p>Esse microservi\u00e7o \u00e9 respons\u00e1vel por gerenciar as contas dos usu\u00e1rios do sistema que est\u00e1 sendo desenvolvido. Ele tamb\u00e9m pode ser utilizado como template para o desenvolvimento de outros microservi\u00e7os que se utilizem de recuros semelhantes em seu funcionamento.</p> <ol> <li>Endpoints</li> <li>Modulariza\u00e7\u00e3o<ul> <li>Interface</li> <li>Resource</li> </ul> </li> <li>Persist\u00eancia</li> <li>Documenta\u00e7\u00e3o</li> <li>Integra\u00e7\u00e3o</li> <li>Docker</li> </ol>"},{"location":"handout/microservices/account/#endpoints","title":"Endpoints","text":"Create Account <pre><code>POST /accounts\n</code></pre> <p>Request </p><pre><code>{\n    \"name\": \"Antonio do Estudo\",\n    \"email\": \"acme@insper.edu.br\",\n    \"password\": \"123@\"\n}\n</code></pre> Responses:<p></p> <p></p> codebody 201 <pre><code>{\n  \"id\": \"45d16201-12a4-48bf-8c84-df768fdc4878\",\n  \"name\": \"Antonio do Estudo\",\n  \"email\": \"acme@insper.edu.br\"\n}\n</code></pre> 401 Login :: find by email and password Get Account <pre><code>GET /accounts/{uuid}\n</code></pre> <p>Responses:</p> <p></p> codebody 200 <pre><code>{\n  \"id\": \"45d16201-12a4-48bf-8c84-df768fdc4878\",\n  \"name\": \"Antonio do Estudo\",\n  \"email\": \"acme@insper.edu.br\"\n}\n</code></pre> 401"},{"location":"handout/microservices/account/#modularizacao","title":"Modulariza\u00e7\u00e3o","text":"<p>Class Diagram</p> <p>Exemplo para o microsservi\u00e7o Account.</p> <pre><code>classDiagram\n  namespace Interface {\n    class AccountController {\n      &lt;&lt;interface&gt;&gt;\n      create(AccountIn)\n      read(String id): AccountOut\n      update(String id, AccountIn)\n      delete(String id)\n      findByEmailAndPassword(AccountIn)\n    }\n    class AccountIn {\n      &lt;&lt;record&gt;&gt;\n      String name\n      String email\n      String password\n    }\n    class AccountOut {\n      &lt;&lt;record&gt;&gt;\n      String id\n      String name\n      String email\n    }\n  }\n  namespace Resource {\n    class AccountResource {\n      &lt;&lt;REST API&gt;&gt;\n      -accountService\n    }\n    class AccountService {\n      &lt;&lt;service&gt;&gt;\n      -accountRepository\n      create(Account)\n    }\n    class AccountRepository {\n      &lt;&lt;nterface&gt;&gt;\n      findByEmailAndHash(String, String)\n    }\n    class AccountModel {\n      &lt;&lt;entity&gt;&gt;\n      String id\n      String name\n      String email\n      String hash\n    }\n    class Account {\n      &lt;&lt;dto&gt;&gt;\n      String id\n      String name\n      String email\n      String password\n    }\n  }\n  AccountController &lt;|-- AccountResource\n  AccountResource o-- AccountService\n  AccountService o-- AccountRepository</code></pre>"},{"location":"handout/microservices/account/#pom-dependecy","title":"POM dependecy","text":"<p>Note que esse microsservi\u00e7o possui depend\u00eancia da interface, o Account. Logo, se torna necess\u00e1rio explicitar essa depend\u00eancia no <code>pom.xml</code> do microsservi\u00e7o Account.</p> <pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;insper.store&lt;/groupId&gt;\n  &lt;artifactId&gt;account&lt;/artifactId&gt;\n  &lt;version&gt;${project.version}&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <p>Outras depend\u00eancias relevantes para adicionar no <code>pom.xml</code> s\u00e3o o suporte ao registro no discovery.</p> <pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n  &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>Quando adicionado o acesso ao Discovery, \u00e9 necess\u00e1rio definir no <code>application.yalm</code> o nome com o qual o servi\u00e7o ser\u00e1 invocado, assim bem como, o endere\u00e7o de acesso do discovery ao qual o servi\u00e7o ir\u00e1 conectar:</p> <pre><code>spring:\n  application:\n    name: store-account\n\neureka:\n  client:\n    register-with-eureka: true\n    fetch-registry: true\n    service-url:\n      defaultZone: ${EUREKA_URI:http://localhost:8761/eureka/}\n</code></pre> <p>J\u00e1 para disponibilizar o uso ao <code>OpenFeign</code>.</p> <pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n  &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"handout/microservices/auth/","title":"Auth","text":"<p>A fim do sistema possuir um controle de acesso, \u00e9 conveniente a cria\u00e7\u00e3o de um microsservi\u00e7o Auth, que ser\u00e1 respons\u00e1vel pelo cadastro de usu\u00e1rios do sistema.</p> <ol> <li>Endpoints</li> <li>Modulariza\u00e7\u00e3o<ul> <li>Interface</li> <li>Resource</li> </ul> </li> <li>Documenta\u00e7\u00e3o</li> <li>Integra\u00e7\u00e3o</li> <li>Token</li> <li>Docker</li> </ol>"},{"location":"handout/microservices/auth/#endpoints","title":"Endpoints","text":"Register <pre><code>POST /auth/register\n</code></pre> Autentica\u00e7\u00e3o :: Login <pre><code>POST /auth/login\n</code></pre>"},{"location":"handout/microservices/auth/#request","title":"Request","text":"<pre><code>{\n    \"name\": \"Antonio do Estudo\",\n    \"email\": \"acme@insper.edu.br\",\n    \"password\": \"123@321\"\n}\n</code></pre>"},{"location":"handout/microservices/auth/#response","title":"Response","text":"code body 201"},{"location":"handout/microservices/auth/#sequence-diagram","title":"Sequence Diagram","text":"<pre><code>sequenceDiagram\nautonumber\nactor User\nUser-&gt;&gt;+Auth: register(RegisterIn)\nAuth-&gt;&gt;+Account: create(AccountIn)\nAccount-&gt;&gt;-Auth: returns the new account (AccountOut)\nAuth-&gt;&gt;-User: returns 201</code></pre>"},{"location":"handout/microservices/auth/#request_1","title":"Request","text":"<pre><code>{\n    \"email\": \"acme@insper.edu.br\",\n    \"password\": \"123@321\"\n}\n</code></pre>"},{"location":"handout/microservices/auth/#response_1","title":"Response","text":"code body 201 <code>{ \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiI0NWQxNjIwMS0xMmE0LTQ4YmYtOGM4NC1kZjc2OGZkYzQ4NzgiLCJuYW1lIjoiQW50b25pbyBkbyBFc3R1ZG8iLCJpYXQiOjE1MTYyMzkwMjIsInJvbGUiOiJyZWd1bGFyIn0.8eiTZjXGUFrseBP5J91UdDctw-Flp7HP-PAp1eO8f1M\" }</code> 403"},{"location":"handout/microservices/auth/#sequence-diagram_1","title":"Sequence Diagram","text":"<pre><code>sequenceDiagram\nautonumber\nactor User\nUser-&gt;&gt;+Auth: authenticate(CredentiaIn)\nAuth-&gt;&gt;+Account: login(LoginIn)\ncritical validated\n    Account-&gt;&gt;-Auth: returns the account\noption denied\n    Auth--&gt;&gt;User: unauthorized message\nend  \nAuth-&gt;&gt;Auth: generates a token\nAuth-&gt;&gt;-User: returns LoginOut\nUser-&gt;&gt;User: stores the token to use for the next requests</code></pre>"},{"location":"handout/microservices/auth/#modularizacao","title":"Modulariza\u00e7\u00e3o","text":"<p>Exemplo para o microsservi\u00e7o Auth.</p> <pre><code>classDiagram\n  namespace Interface {\n    class AuthController {\n      &lt;&lt;interface&gt;&gt;\n      register(RegisterIn)\n      authenticate(CredentialIn): LoginOut\n      solve(SolveIn): SolveOut\n    }\n    class RegisterIn {\n      &lt;&lt;record&gt;&gt;\n      String name\n      String email\n      String password\n    }\n    class CredentialIn {\n      &lt;&lt;record&gt;&gt;\n      String email\n      String password\n    }\n    class LoginOut {\n      &lt;&lt;Record&gt;&gt;\n      String token\n    }\n    class SolveIn {\n      &lt;&lt;Record&gt;&gt;\n      String token\n    }\n    class SolveOut {\n      &lt;&lt;Record&gt;&gt;\n      String id\n      String name\n      String role\n    }\n  }\n  namespace Resource {\n    class AuthResource {\n      &lt;&lt;REST API&gt;&gt;\n      -authService\n    }\n    class AuthService {\n      &lt;&lt;service&gt;&gt;\n      JwtService jwtService\n      register(RegisterIn)\n      authenticate(CredentialIn)\n    }\n    class JwtService {\n      &lt;&lt;service&gt;&gt;\n      String secretKey\n      String issuer\n      long duration\n      SecretKey key\n      JwtParser parser\n      init()\n      create(String id, String name, String role): String\n      getToken(String token): Token\n      getRole(String token): String\n    }\n    class Token {\n      &lt;&lt;record&gt;&gt;\n      String id\n      String name\n      String role\n    }\n  }\n  AuthController &lt;|-- AuthResource\n  AuthResource o-- AuthService\n  AuthService o-- JwtService</code></pre> <p>Exemplo de uma implementa\u00e7\u00e3o da interface AuthController.</p> AuthController.java<pre><code>package store.auth;\n\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestBody;\n\n@FeignClient(\"store-auth\")\npublic interface AuthController {\n\n    @PostMapping(\"/auth/register\")\n    ResponseEntity&lt;?&gt; create (\n        @RequestBody(required = true) RegisterIn in\n    );\n\n    @PostMapping(\"/auth/login\")\n    ResponseEntity&lt;LoginOut&gt; authenticate (\n        @RequestBody(required = true) Credential in\n    );\n}\n</code></pre> <p>Repare que h\u00e1 a publica\u00e7\u00e3o da interface como sendo um servi\u00e7o a ser registrado no Discovery.</p>"},{"location":"handout/microservices/auth/#documentacao","title":"Documenta\u00e7\u00e3o","text":"<p>Para fazer a documenta\u00e7\u00e3o dos APIs, de forma automatizada, \u00e9 aconselh\u00e1vel a utiliza\u00e7\u00e3o da biblioteca <code>SpringDoc OpenAPI</code>.</p> pom.xml<pre><code>&lt;!-- https://mvnrepository.com/artifact/org.springdoc/springdoc-openapi-ui --&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;org.springdoc&lt;/groupId&gt;\n  &lt;artifactId&gt;springdoc-openapi-starter-webmvc-ui&lt;/artifactId&gt;\n  &lt;version&gt;[2.3.0,)&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"handout/microservices/auth/#integracao","title":"Integra\u00e7\u00e3o","text":"<p>A integra\u00e7\u00e3o entre os microsservi\u00e7os \u00e9 feita via OpenFeign. Esse framework precisa saber, quando a aplica\u00e7\u00e3o sobe, em quais pacotes ir\u00e1 procurar os servi\u00e7os. Para isso, se torna necess\u00e1rio anotar a classe <code>AuthApplication</code> com a lista de pacotes, assim bem como, anotar que esse microsservi\u00e7o ir\u00e1 trabalhar com a sistema de descoberta de microsservi\u00e7os habitado.</p> AuthApplication.java<pre><code>package store.auth;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\nimport org.springframework.cloud.openfeign.EnableFeignClients;\n\n@EnableFeignClients(basePackages = {\n    \"insper.store.account\"\n})\n@EnableDiscoveryClient\n@SpringBootApplication\npublic class AuthApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(AuthApplication.class, args);\n    }\n\n}\n</code></pre> <p>Necess\u00e1rio tamb\u00e9m atualizar o <code>pom.xml</code> para que o microsservi\u00e7o possa enxergar o outro microsservi\u00e7o.</p> <p>Note que esse microsservi\u00e7o possui depend\u00eancia de outro, o Account, al\u00e9m da depend\u00eancia da interface do pr\u00f3prio microsservi\u00e7o. Logo, se torna necess\u00e1rio explicitar essa depend\u00eancia no <code>pom.xml</code> do microsservi\u00e7o Auth.</p> pom.xml<pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;insper.store&lt;/groupId&gt;\n  &lt;artifactId&gt;auth&lt;/artifactId&gt;\n  &lt;version&gt;${project.version}&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;insper.store&lt;/groupId&gt;\n  &lt;artifactId&gt;account&lt;/artifactId&gt;\n  &lt;version&gt;${project.version}&lt;/version&gt;\n&lt;/dependency&gt;\n\n&lt;!-- https://mvnrepository.com/artifact/io.jsonwebtoken/jjwt-api --&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;\n  &lt;artifactId&gt;jjwt-api&lt;/artifactId&gt;\n  &lt;version&gt;0.12.3&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;\n  &lt;artifactId&gt;jjwt-impl&lt;/artifactId&gt;\n  &lt;version&gt;0.12.3&lt;/version&gt;\n  &lt;scope&gt;runtime&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;\n  &lt;artifactId&gt;jjwt-jackson&lt;/artifactId&gt; &lt;!-- or jjwt-gson if Gson is preferred --&gt;\n  &lt;version&gt;0.12.3&lt;/version&gt;\n  &lt;scope&gt;runtime&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre> <p>Aproveitando esse ponto, vale a pena j\u00e1 incluir tamb\u00e9m no <code>pom.xml</code>.</p>"},{"location":"handout/microservices/auth/#token","title":"Token","text":"<p>Para gerar o token de acesso, no caso JWT, um servi\u00e7o foi criado, <code>JwtService.java</code>.</p> <p>Para gerar o JWT, alguns atributos s\u00e3o adicionados no <code>application.yaml</code>.</p> application.yaml<pre><code>store:\n  jwt:\n    issuer: \"In5pEr\"\n    secretKey: \"\"\n    duration: 31536000000 # 365 days in miliseconds\n</code></pre> JwtService.java<pre><code>package store.auth;\n\nimport java.util.Date;\n\nimport javax.crypto.SecretKey;\n\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.stereotype.Service;\n\nimport io.jsonwebtoken.Claims;\nimport io.jsonwebtoken.ExpiredJwtException;\nimport io.jsonwebtoken.JwtParser;\nimport io.jsonwebtoken.Jwts;\nimport io.jsonwebtoken.io.Decoders;\nimport io.jsonwebtoken.security.Keys;\nimport jakarta.annotation.PostConstruct;\n\n@Service\npublic class JwtService {\n\n    @Value(\"${store.jwt.secret-key}\")\n    private String secretKey;\n\n    @Value(\"${store.jwt.issuer}\")\n    private String issuer;\n\n    @Value(\"${store.jwt.duration}\")\n    private long duration = 1l;\n\n    private SecretKey key;\n    private JwtParser parser;\n\n    @PostConstruct\n    public void init() {\n        this.key = Keys.hmacShaKeyFor(Decoders.BASE64.decode(secretKey));\n        this.parser = Jwts.parser().verifyWith(key).build();\n    }\n\n    public String create(String id, String name, String role) {\n        String jwt = Jwts.builder()\n            .header()\n            .and()\n            .id(id)\n            .issuer(issuer)\n            .subject(name)\n            .signWith(key)\n            .claim(\"role\", role)\n            .notBefore(new Date())\n            .expiration(new Date(new Date().getTime() + duration))\n            .compact();\n        return jwt;\n    }\n\n    public String getToken(String token) {\n        final Claims claims = resolveClaims(token);\n        return Token.builder\n            .id(claims.getId())\n            .role(claims.get(\"role\", String.class))\n            .build();\n    }\n\n    private Claims resolveClaims(String token) {\n        if (token == null) throw new io.jsonwebtoken.MalformedJwtException(\"token is null\");\n        return validateClaims(parser.parseSignedClaims(token).getPayload());\n    }\n\n    private Claims validateClaims(Claims claims) throws ExpiredJwtException {\n        if (claims.getExpiration().before(new Date())) throw new ExpiredJwtException(null, claims, issuer);\n        if (claims.getNotBefore().after(new Date())) throw new ExpiredJwtException(null, claims, issuer);\n        return claims;\n    }\n\n}\n</code></pre>"},{"location":"handout/microservices/auth/#docker","title":"Docker","text":"<p>Adicione no <code>docker-compose.yaml</code> o registro desse novo microsservi\u00e7o:</p> docker-compose.yaml<pre><code>  auth:\n    build:\n      context: ../store.auth-resource/\n      dockerfile: Dockerfile\n    container_name: store-auth\n    image: store-auth:latest\n    # ports:\n    #   - 8080:8080\n    environment:\n      - eureka.client.service-url.defaultZone=http://store-discovery:8761/eureka/\n    deploy:\n      mode: replicated\n      replicas: 1\n    restart: always\n    networks:\n      - private-network\n    depends_on:\n      - discovery\n      - account\n</code></pre> NICE TO HAVE <p>O projeto da disciplina pode ter um microsservi\u00e7o de registro que valide email ou SMS para criar a conta.</p>"},{"location":"handout/microservices/discovery/","title":"Discovery","text":""},{"location":"handout/microservices/gateway/","title":"Gateway","text":"<p>O gateway tem como fun\u00e7\u00e3o ser o \u00fanico ponto de entrada de todo o sistema, ele \u00e9 respons\u00e1vel por redirecionar todas as requisi\u00e7\u00f5es aos respectivos microsservi\u00e7os. Assim bem como, de autorizar ou negar acesso ao sistema baseando-se no token de seguran\u00e7a passado pela requisi\u00e7\u00e3o.</p> <pre><code>flowchart LR\n  subgraph Client\n    direction LR\n    Web\n    Mobile\n    Desktop\n  end\n  subgraph Microservices\n    direction LR\n    gateway[\"Gateway\"]\n    subgraph Essentials\n      direction TB\n      discovery[\"Discovery\"]\n      auth[\"Auth\"]\n      config[\"Configuration\"]\n    end\n    subgraph Businesses\n      direction TB\n      ms1[\"Service 1\"]\n      ms2[\"Service 2\"]\n      ms3[\"Service 3\"]\n    end\n  end\n  Client --&gt; lb[\"Load Balance\"] --&gt; gateway --&gt; Businesses\n  gateway --&gt; auth\n  gateway --&gt; discovery</code></pre>"},{"location":"handout/microservices/gateway/#sequence-diagram","title":"Sequence Diagram","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Gateway: route(ServerHttpRequest)\n  Gateway-&gt;&gt;+AuthenticationFilter: filter(ServerWebExchange, GatewayFilterChain)\n  AuthenticationFilter-&gt;&gt;RouteValidator: isSecured.test(ServerHttpRequest)\n  RouteValidator--&gt;&gt;AuthenticationFilter: True | False\n  critical notSecured\n    AuthenticationFilter-&gt;&gt;Gateway: follow the flux\n  end\n  AuthenticationFilter-&gt;&gt;AuthenticationFilter: isAuthMissing(ServerHttpRequest)\n  critical isAuthMissing\n    AuthenticationFilter-&gt;&gt;User: unauthorized message\n  end\n  AuthenticationFilter-&gt;&gt;AuthenticationFilter: validateAuthorizationHeader()\n  critical isInvalidAuthorizationHeader\n    AuthenticationFilter-&gt;&gt;User: unauthorized message\n  end\n  AuthenticationFilter-&gt;&gt;Auth: solve(Token)\n  critical isInvalidToken\n    Auth-&gt;&gt;User: unauthorized message\n  end\n  Auth-&gt;&gt;AuthenticationFilter: returns token claims\n  AuthenticationFilter-&gt;&gt;AuthenticationFilter: updateRequestHeader(ServerHttpRequest)\n  AuthenticationFilter-&gt;&gt;Gateway: follow the flux</code></pre> pom.xml<pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n  &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n  &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n  &lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n  &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;!-- https://mvnrepository.com/artifact/com.github.ben-manes.caffeine/caffeine --&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt;\n  &lt;artifactId&gt;caffeine&lt;/artifactId&gt;\n  &lt;version&gt;3.1.8&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;insper.store&lt;/groupId&gt;\n  &lt;artifactId&gt;auth&lt;/artifactId&gt;\n  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> application.yaml<pre><code>spring:\n  application:\n    name: store-gateway\n  cloud:\n    discovery:\n      locator:\n        enabled: true\n    gateway:\n      routes:\n\n        - id: auth\n          uri: lb://store-auth\n          predicates:\n            - Path=/auth/**\n\n        # - id: product\n        #   uri: lb://store-product\n        #   predicates:\n        #     - Path=/product/**\n\n      default-filters:\n        - DedupeResponseHeader=Access-Control-Allow-Credentials Access-Control-Allow-Origin\n      globalcors:\n        corsConfigurations:\n          '[/**]':\n            allowedOrigins: \"http://localhost\"\n            allowedHeaders: \"*\"\n            allowedMethods:\n            - GET\n            - POST\n\napi:\n  endpoints:\n    open: &gt;\n      POST /auth/register/,\n      POST /auth/login/\n</code></pre> GatewayConfiguration.java<pre><code>package insper.store.gateway;\n\nimport org.springframework.cloud.client.loadbalancer.LoadBalanced;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.web.reactive.function.client.WebClient;\n\n@Configuration\npublic class GatewayConfiguration {\n\n    @Bean\n    @LoadBalanced\n    public WebClient.Builder webClient() {\n        return WebClient.builder();\n    }\n\n}\n</code></pre> RouterValidator.java<pre><code>package insper.store.gateway.security;\n\nimport java.util.List;\nimport java.util.function.Predicate;\n\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.http.server.reactive.ServerHttpRequest;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class RouterValidator {\n\n        @Value(\"${api.endpoints.open}}\") \n        private List&lt;String&gt; openApiEndpoints;\n\n        public Predicate&lt;ServerHttpRequest&gt; isSecured =\n                request -&gt; openApiEndpoints\n                        .stream()\n                        .noneMatch(uri -&gt; {\n                                String[] parts = uri.replaceAll(\"[^a-zA-Z0-9// ]\", \"\").split(\" \");\n                                return request.getMethod().toString().equalsIgnoreCase(parts[0])\n                                    &amp;&amp; request.getURI().getPath().equals(parts[1]);\n                        });\n\n}\n</code></pre> AuthenticationFilter.java<pre><code>package insper.store.gateway.security;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.cloud.gateway.filter.GatewayFilterChain;\nimport org.springframework.cloud.gateway.filter.GlobalFilter;\nimport org.springframework.http.HttpHeaders;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.http.MediaType;\nimport org.springframework.http.server.reactive.ServerHttpRequest;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.reactive.function.client.WebClient;\nimport org.springframework.web.server.ResponseStatusException;\nimport org.springframework.web.server.ServerWebExchange;\n\nimport reactor.core.publisher.Mono;\nimport store.auth.IdIn;\nimport store.auth.IdOut;\n\n@Component\npublic class AuthenticationFilter implements GlobalFilter {\n\n    private static final String HEADER_AUTHORIZATION = \"Authorization\";\n    private static final String HEADER_BEARER = \"Bearer\";\n\n    @Autowired\n    private RouterValidator routerValidator;\n\n    @Autowired\n    private WebClient.Builder webClient;\n\n    @Override\n    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {\n        ServerHttpRequest request = exchange.getRequest();\n        if (!routerValidator.isSecured.test(request)) {\n            return chain.filter(exchange);\n        }\n        if (!isAuthMissing(request)) {\n            final String[] parts = this.getAuthHeader(request).split(\" \");\n            if (parts.length != 2 || !parts[0].equals(HEADER_BEARER)) {\n                throw new ResponseStatusException(HttpStatus.FORBIDDEN, \"Authorization header format must be Bearer {token}\");\n            }\n            final String token = parts[1];\n            return webClient\n                .defaultHeader(HttpHeaders.CONTENT_TYPE, MediaType.APPLICATION_JSON_VALUE)\n                .build()\n                .post()\n                .uri(\"http://store-auth/auth/token/\")\n                .bodyValue(new IdIn(token))\n                .retrieve()\n                .toEntity(IdOut.class)\n                .flatMap(response -&gt; {\n                    if (response != null &amp;&amp; response.getBody() != null) {\n                        this.updateRequest(exchange, response.getBody().id());\n                        return chain.filter(exchange);\n                    } else {\n                        throw new ResponseStatusException(HttpStatus.UNAUTHORIZED, \"Invalid token\");\n                    }\n                });\n        }\n        throw new ResponseStatusException(HttpStatus.UNAUTHORIZED, \"Missing authorization header\");\n    }\n\n    private String getAuthHeader(ServerHttpRequest request) {\n        return request.getHeaders().getOrEmpty(HEADER_AUTHORIZATION).get(0);\n    }\n\n    private boolean isAuthMissing(ServerHttpRequest request) {\n        return !request.getHeaders().containsKey(\"Authorization\");\n    }    \n\n    private void updateRequest(ServerWebExchange exchange, String id) {\n        exchange.getRequest().mutate()\n                .header(\"id-user\", id)\n                .build();\n    }\n\n}\n</code></pre>"},{"location":"handout/microservices/roadmap/","title":"Roadmap","text":""},{"location":"handout/microservices/roadmap/#microsservico","title":"Microsservi\u00e7o","text":"<p>A fim de implementar microsservi\u00e7os em Spring Boot, aqui, \u00e9 proposto uma abordagem de modulariza\u00e7\u00e3o de cada microsservi\u00e7o, de forma que exista uma interface de comunica\u00e7\u00e3o Java a ser consumida por outros microsservi\u00e7os, tamb\u00e9m em Java, e tamb\u00e9m um compromisso de implementa\u00e7\u00e3o. Essa estrat\u00e9gia visa aumentar a produtividade do ambiente de desenvolvimento em Java, j\u00e1 que para o consumo da API por outros frameworks sempre ser\u00e1 necess\u00e1rio reescrever as assinaturas de cada endpoint.</p>"},{"location":"handout/microservices/roadmap/#modularizacao","title":"Modulariza\u00e7\u00e3o","text":"<p>Crie dois projetos Mavens:</p> <ul> <li>um de interface, e;</li> <li>outro para o micro servi\u00e7o.</li> </ul> <p>A vantagem dessa abordagem \u00e9 que a interface pode ser utilizada em outros projetos como uma biblioteca a ser consumida.</p> <p>Exemplo de uso dessa abordagem no microsservi\u00e7o Account:</p> <pre><code>classDiagram\n  namespace Interface {\n    class AccountController {\n      &lt;&lt;interface&gt;&gt;\n      create(AccountIn)\n      read(String id): AccountOut\n      update(String id, AccountIn)\n      delete(String id)\n      findByEmailAndPassword(AccountIn)\n    }\n    class AccountIn {\n      &lt;&lt;record&gt;&gt;\n      String name\n      String email\n      String password\n    }\n    class AccountOut {\n      &lt;&lt;record&gt;&gt;\n      String id\n      String name\n      String email\n    }\n  }\n  namespace Resource {\n    class AccountResource {\n      &lt;&lt;REST API&gt;&gt;\n      -accountService\n    }\n    class AccountService {\n      &lt;&lt;service&gt;&gt;\n      -accountRepository\n      create(Account)\n    }\n    class AccountRepository {\n      &lt;&lt;nterface&gt;&gt;\n      findByEmailAndHash(String, String)\n    }\n    class AccountModel {\n      &lt;&lt;entity&gt;&gt;\n      String id\n      String name\n      String email\n      String hash\n    }\n    class Account {\n      &lt;&lt;dto&gt;&gt;\n      String id\n      String name\n      String email\n      String password\n    }\n  }\n  AccountController &lt;|-- AccountResource\n  AccountResource o-- AccountService\n  AccountService o-- AccountRepository</code></pre>"},{"location":"handout/microservices/roadmap/#interface","title":"Interface","text":"<p>Para compilar e instalar a interface do microsservi\u00e7o, crie um <code>pom.xml</code> espec\u00edfico para essa interface e seus dtos (AccountIn e AccountOut).</p> Installing the microservice interface<pre><code>mvn clean install\n</code></pre>"},{"location":"handout/microservices/roadmap/#implementacao","title":"Implementa\u00e7\u00e3o","text":"<p>A implementa\u00e7\u00e3o n\u00e3o precisa ser instalada como biblioteca do reposit\u00f3rio Maven, pois \u00e9 apenas para execu\u00e7\u00e3o do microsservi\u00e7o. Por\u00e9m, o microsservi\u00e7o deve ter explic\u00edto a chamada da biblioteca de interface no seu <code>pom.xml</code>.</p> <pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;insper.store&lt;/groupId&gt;\n  &lt;artifactId&gt;account&lt;/artifactId&gt;\n  &lt;version&gt;${project.version}&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <p>O comando para empacotar o microsservi\u00e7o \u00e9:</p> Packaging the microservice<pre><code>mvn clean package\n</code></pre> <p>Adicionalmente, para executar o microsservi\u00e7o:</p> Packaging and running the microservice<pre><code>mvn clean package spring-boot:run\n</code></pre>"},{"location":"handout/microservices/roadmap/#banco-de-dados","title":"Banco de dados","text":"<p>Muitos microsservi\u00e7os podem persistir seus dados em banco de dados. Cada microsservi\u00e7o \u00e9 respons\u00e1vel pelo acesso e grava\u00e7\u00e3o de seus dados de forma aut\u00f4noma.</p> <p>Isso aumenta de forma significativa a complexidade do gerenciamento do microsservi\u00e7o, pois se torna necess\u00e1rio manter o gerenciamento da base de dados tais como: altera\u00e7\u00f5es, vers\u00f5es e roteiros de retornos.</p> <p>O Flyway \u00e9 uma biblioteca que pode ser acoplado ao framework Spring Boot a fim de ajudar na tarefa de gerenciamento e cria\u00e7\u00e3o do sistema de persit\u00eancia dos dados do microsservi\u00e7o.</p> <p>Para fazer uso dessa biblioteca, altere o <code>pom.xml</code> adicionando a depend\u00eancia da biblioteca JPA assim bem como a depend\u00eancia da biblioteca Flyway.</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.flywaydb&lt;/groupId&gt;\n    &lt;artifactId&gt;flyway-core&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.postgresql&lt;/groupId&gt;\n    &lt;artifactId&gt;postgresql&lt;/artifactId&gt;\n    &lt;version&gt;42.7.2&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <p>Altera\u00e7\u00f5es no arquivo de propriedades tamb\u00e9m s\u00e3o necess\u00e1rias, para definir o banco de dados e sua configura\u00e7\u00e3o JPA, assim bem como, a configura\u00e7\u00e3o do Flyway.</p> Exemplo baseado no microsservi\u00e7o Account<pre><code>spring:\n  datasource:\n    url: ${DATABASE_URL:jdbc:postgresql://localhost:5432/store}\n    username: ${DATABASE_USERNAME:store}\n    password: ${DATABASE_PASSWORD:store123321}\n    driver-class-name: org.postgresql.Driver\n  flyway:\n    baseline-on-migrate: true\n    schemas: account\n  jpa:\n    properties:\n      hibernate:\n        default_schema: account\n</code></pre> <p>A estrutura de organiza\u00e7\u00e3o e execu\u00e7\u00e3o de scripts de banco de dados do Flyway \u00e9 persistido na seguinte hier\u00e1rquia de diret\u00f3rios, onde cada arquivo \u00e9 executado em ordem alfanum\u00e9rica.</p> exemplo<pre><code> store.account\n\ud83d\udcc1 store.account-resource\n\u2514\u2500\u2500 \ud83d\udcc1 src\n    \u2514\u2500\u2500 \ud83d\udcc1 main\n        \u251c\u2500\u2500  java\n        \u2514\u2500\u2500 \ud83d\udcc1 resources\n            \u251c\u2500\u2500 \ud83d\udcc1 db\n            \u2502   \u2514\u2500\u2500 \ud83d\udcc1 migration\n            \u2502       \u251c\u2500\u2500  V2024.02.16.001__create_schema.sql\n            \u2502       \u2514\u2500\u2500  V2024.02.16.002__create_table_account.sql\n            \u2514\u2500\u2500  application.yaml\n</code></pre> V2024.02.16.001__create_schema.sqlV2024.02.16.002__create_table_account.sql <pre><code>CREATE SCHEMA IF NOT EXISTS account;\n</code></pre> <pre><code>CREATE TABLE account\n(\n    id_account character varying(36) NOT NULL,\n    tx_name character varying(256) NOT NULL,\n    tx_email character varying(256) NOT NULL,\n    tx_hash character varying(256) NOT NULL,\n    CONSTRAINT account_pkey PRIMARY KEY (id_account)\n);\n</code></pre>"},{"location":"handout/microservices/roadmap/#conectando-microsservicos-openfeign","title":"Conectando Microsservi\u00e7os - OpenFeign","text":"<p>Nomeando o microsservi\u00e7o dentro do sistema de discovery.</p> <pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n  &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <pre><code>@FeignClient(name = \"store-account\")\npublic interface AccountController {\n  ...\n}\n</code></pre>"},{"location":"handout/microservices/roadmap/#docker","title":"Docker","text":"<p>Para cada microsservi\u00e7o Java Spring Cloud \u00e9 aconselh\u00e1vel criar um arquivo <code>Dockerfile</code> no diret\u00f3rio raiz do projeto a fim de permitir a cria\u00e7\u00e3o adequada da imagem do microservi\u00e7o.</p> Typical Dockerfile for Java microservice<pre><code>FROM openjdk:23-slim\nVOLUME /tmp\nCOPY target/*.jar app.jar\nENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]\n</code></pre>"},{"location":"handout/microservices/roadmap/#docker-compose","title":"Docker Compose","text":"<p>O Docker Compose permite criar um cluster com todos os microsservi\u00e7os neces\u00e1rios para o funcionamento de um sistema em uma rede apartada (nat).</p> <p>Para criar um docker compose basta criar um arquivo de configura\u00e7\u00e3o chamado <code>docker-compose.yaml</code> em uma pasta que possa acessar os demais microsservi\u00e7os, como uma pasta store.docker-platform.</p> exemplo<pre><code> store.account\n store.account-resource\n\ud83d\udcc1 store.docker-platform\n\u251c\u2500\u2500  .env\n\u2514\u2500\u2500  docker-compose.yaml\n</code></pre> <p>Dentro do arquivo, cada microsservi\u00e7o \u00e9 declarado e configurado, utilizando imagem que s\u00e3o criadas no momento de execu\u00e7\u00e3o do docker engine ou imagens que est\u00e3o dispon\u00edveis em algum diret\u00f3rio (eg.: DockerHub).</p> docker-compose.yaml<pre><code># docker compose up -d --build --force-recreate\nversion: '3.8'\nname: store\n\nservices:\n\n  db-store:\n    container_name: store-db-store\n    image: postgres:latest\n    ports:\n      - 5432:5432\n    environment:\n      - POSTGRES_USER=store\n      - POSTGRES_PASSWORD=store\n      - POSTGRES_DB=store\n    volumes:\n      - $VOLUME/postgres/store/data:/var/lib/postgresql/data\n    restart: always\n    networks:\n      - private-network\n\n  account:\n    build:\n      context: ../store.account-resource/\n      dockerfile: Dockerfile\n    image: store-account:latest\n    environment:\n      - spring.datasource.url=jdbc:postgresql://store-db-store:5432/store\n      - spring.datasource.username=store\n      - spring.datasource.password=store\n    deploy:\n      mode: replicated\n      replicas: 1\n    restart: always\n    networks:\n      - private-network\n    depends_on:\n      - db-store\n\nnetworks:\n  private-network:\n    driver: bridge\n</code></pre> <p>Arquivo de configura\u00e7\u00e3o de ambiente.</p> .env<pre><code>VOLUME=./volume\nCONFIG=./config\n</code></pre> <p>Na pasta do arquivo <code>docker-compose.yaml</code> execute o comando docker para criar as imagens e subir os containers:</p> Rise up a cluster<pre><code>docker compose up -d --build\n</code></pre> Shutdown the cluster<pre><code>docker compose down\n</code></pre> <p>Referencia:</p>"},{"location":"hands-on/0/","title":"0. Prerequisites","text":"<p>To start the hands-on exercises, we need to set up our environment. This includes installing necessary tools, configuring our workspace, and ensuring we have access to the required resources.</p> <p>To set up your development environment, check the appendix Development Setup.</p> <p>After that your environment should be ready to start the exercises. We should create a root repository, to made easy to access the other microservices repositories and also the documentation.</p>"},{"location":"hands-on/0/#root-repository","title":"Root Repository","text":"<p>The root repository will serve as the central point for accessing all other microservices repositories and the documentation. It will help in organizing the project structure and managing dependencies efficiently.</p> <p>To better organize the projet, we propose to create a new organization in GitHub, called something like <code>&lt;username&gt;-studies</code>, and then create the root repository inside this organization, as well as the other microservices repositories. This way, we can easily manage access permissions and collaborate with other team members. Also, we can use the project management features of GitHub, such as issues and pull requests, to track progress and coordinate work across the different repositories.</p> <p>Documentation Hosting</p> <p>Additionally, we can use GitHub Pages to host the documentation for the project.</p> <p>Steps:</p> <ol> <li> <p>Create a new repository called <code>platform</code> inside the organization, and then clone it to your local machine. This repository will serve as the root repository for our project.</p> </li> <li> <p>Inside this root repository, we can create a directory structure to organize our microservices and documentation. For example:</p> Root Directory Structure<pre><code>\ud83d\udcc1 platform/\n\u251c\u2500\u2500 \ud83d\udcc1 api/\n\u251c\u2500\u2500 \ud83d\udcc1 docs/\n\u2502   \u2514\u2500\u2500  index.md\n\u251c\u2500\u2500 \ud83d\udcc1 web/\n\u251c\u2500\u2500 \ud83d\udcc1 docker/\n\u251c\u2500\u2500  .gitignore\n\u2514\u2500\u2500  README.md\n</code></pre> </li> </ol> <p>BONUS: MkDocs with Material</p> <p>You can use MkDocs with Material for the documentation, and then host it using GitHub Pages. This will allow us to have a well-structured and visually appealing documentation site that is easily accessible to all team members.</p> <p>To set up mkdocs with material, you can copy the configuration from the template repository and customize it according to your project's needs.</p> <p>Copy into the root repository the following files from the template repository: mkdocs.yml and requirements.txt</p> <p>The resulting directory structure will look like this:</p> Root Directory Structure<pre><code>\ud83d\udcc1 platform/\n\u251c\u2500\u2500 \ud83d\udcc1 api/\n\u251c\u2500\u2500 \ud83d\udcc1 docs/\n\u2502   \u2514\u2500\u2500  index.md\n\u251c\u2500\u2500 \ud83d\udcc1 web/\n\u251c\u2500\u2500 \ud83d\udcc1 docker/\n\u251c\u2500\u2500  .gitignore\n\u251c\u2500\u2500  README.md\n\u251c\u2500\u2500  mkdocs.yml\n\u2514\u2500\u2500  requirements.txt\n</code></pre> <p>After setting up the mkdocs configuration, you can build and serve the documentation locally using the following commands:</p>  Mac/ Linux Windows <pre><code>python3 -m venv venv\nsource venv/bin/activate\npython3 -m pip install --no-cache-dir -r requirements.txt --upgrade\nmkdocs build\nmkdocs serve\n</code></pre> <pre><code>python -m venv venv\nvenv\\Scripts\\activate\npython -m pip install --no-cache-dir -r requirements.txt --upgrade\nmkdocs build\nmkdocs serve\n</code></pre> <p>This will start a local development server, and you can access the documentation by navigating to <code>http://127.0.0.1:8000</code> in your web browser.</p> <p>Now, with no more delay, you can start the hands-on exercises!</p>"},{"location":"hands-on/1/","title":"a. Introduction","text":"<p>Main Goal</p> <p>The main goal of this section is to implement a simple CRUD (Create, Read, Update, Delete) microservice for illustration purposes.</p> <p>The Account microservice is responsible for managing user accounts, basically, almost every application has a user account system. This microservice provides the necessary endpoints to create, read, update, and delete accounts. The microservice is built using Spring Boot and follows the Domain-Driven Design (DDD) approach.</p> <p>The microservice is divided into two main modules: <code>account</code> and <code>account-service</code>:</p> <ul> <li>the <code>account</code> module contains the API definition and the data transfer objects (DTOs) for the Account microservice;</li> <li>the <code>account-service</code> module contains the service implementation, repository, and entity classes.</li> </ul> <pre><code>classDiagram\n    namespace account {\n        class AccountController {\n            +create(AccountIn accountIn): AccountOut\n            +delete(String id): void\n            +findAll(): List&lt;AccountOut&gt;\n            +findById(String id): AccountOut\n        }\n        class AccountIn {\n            -String name\n            -String email\n            -String password\n        }\n        class AccountOut {\n            -String id\n            -String name\n            -String email\n        }\n    }\n    namespace account-service {\n        class AccountResource {\n            +create(AccountIn accountIn): AccountOut\n            +delete(String id): void\n            +findAll(): List&lt;AccountOut&gt;\n            +findById(String id): AccountOut\n        }\n        class AccountService {\n            +create(AccountIn accountIn): AccountOut\n            +delete(String id): void\n            +findAll(): List&lt;AccountOut&gt;\n            +findById(String id): AccountOut\n        }\n        class AccountRepository {\n            +create(AccountIn accountIn): AccountOut\n            +delete(String id): void\n            +findAll(): List&lt;AccountOut&gt;\n            +findById(String id): AccountOut\n        }\n        class Account {\n            -String id\n            -String name\n            -String email\n            -String password\n            -String sha256\n        }\n        class AccountModel {\n            +create(AccountIn accountIn): AccountOut\n            +delete(String id): void\n            +findAll(): List&lt;AccountOut&gt;\n            +findById(String id): AccountOut\n        }\n    }\n    &lt;&lt;Interface&gt;&gt; AccountController\n    AccountController ..&gt; AccountIn\n    AccountController ..&gt; AccountOut\n\n    &lt;&lt;Interface&gt;&gt; AccountRepository\n    AccountController &lt;|-- AccountResource\n    AccountResource *-- AccountService\n    AccountService *-- AccountRepository\n    AccountService ..&gt; Account\n    AccountService ..&gt; AccountModel\n    AccountRepository ..&gt; AccountModel</code></pre> <p>Java Advantages</p> <p>This approach allows the separation of concerns and the organization of the codebase into different modules, making it easier to maintain and scale the application. Also, it creates a facility to reuse the microservice by other microservices in the future - builts in Java.</p> <p>The construction of the Account microservice follows the Clean Architecture approach, which promotes the total decoupling of business rules from interface layers. The diagram below illustrates the flow of data among the layers of the Account microservice:</p> <pre><code>sequenceDiagram\n    title Clean architecture's approach \n    Actor Request\n    Request -&gt;&gt;+ Controller: JSON\n    Controller -&gt;&gt;+ Service: parser (AccountIn -&gt; Account)\n    Service -&gt;&gt;+ Repository: parser (Account -&gt; AccountModel)\n    Repository -&gt;&gt;+ Database: \n    Database -&gt;&gt;- Repository: \n    Repository -&gt;&gt;- Service: parser (Account &lt;- AccountModel)\n    Service -&gt;&gt;- Controller: parser (AccountOut &lt;- Account)\n    Controller -&gt;&gt;- Request: JSON</code></pre> <p>To develop of the Account microservice, the steps are as follows:</p> <ul> <li> <p>1. Controller</p> <p>Create the interface for the Account microservice in the <code>account</code> module, defining the API endpoints and the data transfer objects (DTOs);</p> <p>Controller</p> </li> <li> <p>2. Service</p> <p>Implement the service layer in the <code>account-service</code> module, creating the necessary classes to handle the business logic and the data persistence;</p> <p>Service</p> </li> <li> <p>3. Containerization</p> <p>Create the Dockerfile for the Account microservice, and build the Docker image for the microservice;</p> <p>Containerization</p> </li> <li> <p>4. Repository</p> <p>Implement the persistence layer for <code>account-service</code> module, creating the necessary classes to handle the data persistence;</p> <p>Repository</p> </li> </ul>"},{"location":"hands-on/1/containerization/","title":"d. Containerization","text":"<p>As we have seen in the previous hands-on, the microservices are implemented as Spring Boot applications. To run the microservices, we need to prepare the environment by installing the database to persist the data. For that, we will use a Docker Compose file to create a PostgreSQL container, as well as, a cluster to isolate the microservices from external access, creating a secure environment - trusted layer.</p> <p>A Docker Compose file is a YAML file that defines how Docker containers should behave in production. The file contains the configuration for the database, the microservices, and the network configuration.</p> <p>The bellow diagram illustrates the architecture of the system, that will be created using Docker Compose, where the microservices are isolated from the external access, creating a trusted layer. The microservices can only access the database, and the external access is blocked.</p> <pre><code>flowchart LR\n    subgraph api [Trusted Layer]\n        direction TB\n        account e3@==&gt; db@{ shape: cyl, label: \"Database\" }\n    end\n    internet e1@==&gt;|request| account:::red\n    e1@{ animate: true }\n    e3@{ animate: true }\n    classDef red fill:#fcc</code></pre> <p>At diagram, the <code>account</code> microservice is the business logic layer that interacts with the database.</p> <p>The directory structure of the project looks like something as follows:</p> <pre><code>\ud83d\udcc1 api/\n\u251c\u2500\u2500 \ud83d\udcc1 account/\n\u251c\u2500\u2500 \ud83d\udcc1 account-service/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 src/\n\u2502   \u2514\u2500\u2500  Dockerfile\n\u251c\u2500\u2500  .env\n\u2514\u2500\u2500  compose.yaml\n</code></pre> <p>The <code>compose.yaml</code> file contains the configuration for the database and the microservices, as well as, the network configuration. The <code>.env</code> file contains the environment variables for the database, such as the username, password, and database name. The <code>Dockerfile</code> file contains the configuration for the microservice, such as the base image, the dependencies, and the command to run the application.</p> <p>The content of the files are as follows:</p> compose.yaml.envDockerfile <pre><code>name: store\n\nservices:\n\n  db:\n    image: postgres:17\n    ports:\n      - 5432:5432\n    volumes:\n      - ${VOLUME_DB}:/var/lib/postgresql/data\n    environment:\n      POSTGRES_USER: ${DB_USER:-store}\n      POSTGRES_PASSWORD: ${DB_PASSWORD:-devpass}\n      POSTGRES_DB: ${DB_NAME:-store}\n\n  account:\n    build:\n      context: ./account-service\n      dockerfile: Dockerfile\n    ports:\n      - 8080:8080\n    depends_on:\n      - db\n</code></pre> <pre><code>DB_USER=store\nDB_PASSWORD=5t0r3\nDB_NAME=store\nVOLUME_DB=./volume/db\n</code></pre> <pre><code>FROM eclipse-temurin:25\nVOLUME /tmp\nCOPY target/*.jar /app.jar\nENTRYPOINT [\"java\", \"-jar\", \"/app.jar\"]\n</code></pre> <p>In this configuration, we use the <code>postgres:17</code> image to create a PostgreSQL container, and we set the environment variables for the database using the <code>.env</code> file.</p> <p>To run the application, we need to execute the following command:</p> <pre><code>docker compose up -d --build\n</code></pre> <p>Yet, to check if the application is running, we can execute the following command:</p> <pre><code>docker compose ps -a\n</code></pre> <p>Done! In the next hands-on, we will connect to the database and execute some queries to check if the data is being persisted correctly.</p> <p>Repository</p>"},{"location":"hands-on/1/controller/","title":"b. Controller","text":"<p>The interface of the Account microservice is defined in the <code>account</code> module, which contains the API definition and the data transfer objects (DTOs) for the Account microservice.</p> <p>The main purpose of the section is to create the following API endpoints:</p> <pre><code>classDiagram\n    namespace account {\n        class AccountController {\n            +create(AccountIn accountIn): AccountOut\n            +delete(String id): void\n            +findAll(): List&lt;AccountOut&gt;\n            +findById(String id): AccountOut\n        }\n        class AccountIn {\n            -String name\n            -String email\n            -String password\n        }\n        class AccountOut {\n            -String id\n            -String name\n            -String email\n        }\n    }</code></pre>"},{"location":"hands-on/1/controller/#1-repository","title":"1. Repository","text":"<ul> <li> <p>a. At github, create a new repository for the Account interface. Example: <code>account</code>.</p> </li> <li> <p>b. Then, clone this repository as a submodule to your local machine. To do this, run the following commands at the root of the project:</p> <pre><code>git submodule add &lt;repository_url&gt; api/account\n</code></pre> </li> </ul> <p>This will create a new directory called <code>account</code> inside the <code>api</code> directory, which will contain the code for the Account interface. The resulting directory structure will look like this:</p> <pre><code>\ud83d\udcc1 platform/\n\u2514\u2500\u2500 \ud83d\udcc1 api/\n    \u2514\u2500\u2500 \ud83d\udcc1 account/\n</code></pre>"},{"location":"hands-on/1/controller/#2-code","title":"2. Code","text":"<p>To code this interface module, we will use the Spring Boot framework, through the Spring Initializr, at [https://start.spring.io/], which is a web-based tool that allows us to generate a Spring Boot project with the necessary dependencies and configurations. </p> Spring Initializr <p>Note:</p> <ul> <li>Project: Maven</li> <li>Language: Java</li> <li>Spring Boot: 4.0.3 (stable version for now)</li> <li>Group: store (the company name, for example)</li> <li>Artifact: account (the microservice name)</li> <li>Package name: store.account</li> <li>Packaging: Jar</li> <li>Configurarion: YAML</li> <li>Java: 25 (LTS version for now)</li> </ul> <p>Additionally, we need to add the following dependencies:</p> <ul> <li> <p>Lombok: a Java library that helps to reduce boilerplate code by generating getters, setters, constructors, and other common methods at compile time using annotations.</p> </li> <li> <p>OpenFeign: a declarative web service client that simplifies the process of making HTTP requests to other microservices. It allows us to define interfaces for our API clients and automatically generates the implementation at runtime.</p> </li> </ul> <p>Then, download the zip file and extract it to the <code>api/account</code> directory. The resulting directory structure will look like this:</p> <pre><code>\ud83d\udcc1 api/\n\u2514\u2500\u2500 \ud83d\udcc1 account/\n    \u251c\u2500\u2500 \ud83d\udcc1 src/\n    \u2502   \u251c\u2500\u2500 \ud83d\udcc1 main/\n    \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 java/\n    \u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc1 store/\n    \u2502   \u2502           \u2514\u2500\u2500 \ud83d\udcc1 account/\n    \u2502   \u2502               \u2514\u2500\u2500  AccountApplication.java\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc1 resources/\n    \u2502       \u2514\u2500\u2500  application.yaml\n    \u2514\u2500\u2500  pom.xml\n</code></pre> <p>In this case, the <code>AccountApplication</code> class is useless, since this module is only for the interface, and will not be run as a standalone application. Therefore, we can delete this class and the <code>application.yaml</code> file. Also, we can delete the <code>src/test</code> directory, since we will not be writing tests for this module. Still, we do not need the <code>src/main/resources</code> directory, since we will not be adding any resources to this module. Therefore, we can delete this directory as well. The resulting directory structure will look like this:</p> <p>Now, this time to code the interface, which consists of the <code>AccountController</code> class, which defines the API endpoints for the Account microservice, and the <code>AccountIn</code> and <code>AccountOut</code> classes, which are the DTOs for the input and output of the API endpoints, respectively. The resulting directory structure will look like this:</p> <pre><code>\ud83d\udcc1 api/\n\u2514\u2500\u2500 \ud83d\udcc1 account/\n    \u251c\u2500\u2500 \ud83d\udcc1 src/\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc1 main/\n    \u2502       \u2514\u2500\u2500 \ud83d\udcc1 java/\n    \u2502           \u2514\u2500\u2500 \ud83d\udcc1 store/\n    \u2502               \u2514\u2500\u2500 \ud83d\udcc1 account/\n    \u2502                   \u251c\u2500\u2500  AccountController.java\n    \u2502                   \u251c\u2500\u2500  AccountIn.java\n    \u2502                   \u2514\u2500\u2500  AccountOut.java\n    \u2514\u2500\u2500  pom.xml\n</code></pre> <p>A possible implementation of the <code>AccountController</code>, <code>AccountIn</code>, and <code>AccountOut</code> classes is shown below:</p> <p>Source</p> pom.xmlAccountControllerAccountInAccountOut <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;parent&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n        &lt;version&gt;4.0.3&lt;/version&gt;\n        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\n    &lt;/parent&gt;\n\n    &lt;groupId&gt;store&lt;/groupId&gt;\n    &lt;artifactId&gt;account&lt;/artifactId&gt;\n    &lt;version&gt;1.0.0&lt;/version&gt;\n    &lt;name&gt;account&lt;/name&gt;\n\n    &lt;properties&gt;\n        &lt;java.version&gt;25&lt;/java.version&gt;\n        &lt;spring-cloud.version&gt;2025.1.0&lt;/spring-cloud.version&gt;\n        &lt;maven.compiler.proc&gt;full&lt;/maven.compiler.proc&gt;\n    &lt;/properties&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n\n    &lt;/dependencies&gt;\n\n    &lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;annotationProcessorPaths&gt;\n                        &lt;path&gt;\n                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n                        &lt;/path&gt;\n                    &lt;/annotationProcessorPaths&gt;\n                    &lt;source&gt;${java.version}&lt;/source&gt;\n                    &lt;target&gt;${java.version}&lt;/target&gt;\n                    &lt;release&gt;${java.version}&lt;/release&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n&lt;/project&gt;\n</code></pre> AccountController.java<pre><code>package store.account;\n\nimport java.util.List;\n\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.DeleteMapping;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestBody;\n\n@FeignClient(\n    name=\"account\",\n    url=\"http://account:8080\"\n)\npublic interface AccountController {\n\n    @PostMapping(\"/accounts\")\n    public ResponseEntity&lt;Void&gt; create(\n        @RequestBody AccountIn in\n    );\n\n    @DeleteMapping(\"/accounts/{id}\")\n    public ResponseEntity&lt;Void&gt; delete(\n        @PathVariable String id\n    );\n\n    @GetMapping(\"/accounts/health-check\")\n    public ResponseEntity&lt;Void&gt; healthCheck();\n\n    @GetMapping(\"/accounts\")\n    public ResponseEntity&lt;List&lt;AccountOut&gt;&gt; findAll();\n\n    @GetMapping(\"/accounts/{id}\")\n    public ResponseEntity&lt;AccountOut&gt; findById(\n        @PathVariable String id\n    );\n\n}\n</code></pre> AccountIn.java<pre><code>package store.account;\n\nimport lombok.Builder;\n\n@Builder\npublic record AccountIn(\n\n    String name,\n    String email,\n    String password\n\n) {\n\n}\n</code></pre> AccountOut.java<pre><code>package store.account;\n\nimport lombok.Builder;\n\n@Builder\npublic record AccountOut(\n\n    String id,\n    String name,\n    String email\n\n) {\n\n}\n</code></pre>"},{"location":"hands-on/1/controller/#3-package-and-install","title":"3. Package and Install","text":"<p>After coding the interface, we need to install the package to the local Maven repository, so that it can be used by other modules in the project. To do this, run the following command at the root of the project:</p> <pre><code>mvn clean install\n</code></pre> <p>Done! The Account interface is now ready to be used by other modules in the project.</p> <p>Let's move on to the next section, where we will implement the Account microservice using the interface we just created.</p> <p>Service</p>"},{"location":"hands-on/1/repository/","title":"d. Repository","text":"<p>Now, with the controller implemented, we can move on to the service layer of the Account microservice. The service layer is responsible for the business logic of the microservice, and it interacts with the repository layer to handle the data persistence of the Account entity. The service layer is implemented in the <code>AccountService</code> class, which contains the methods for creating, deleting, finding, and updating accounts. The <code>AccountService</code> class uses the <code>AccountRepository</code> to handle the data persistence of the Account entity, and the <code>AccountParser</code> to handle the parsing of the input and output of the API endpoints.</p> <p>From previous hands-on, we have already see that this microservice uses clean architecture, which means that the service layer is independent of the controller layer and the repository layer. This allows us to easily test the business logic of the service layer without having to worry about the details of the controller layer or the repository layer. The following diagram illustrates the architecture of the Account microservice, showing the relationships between the different layers and classes:</p> <pre><code>sequenceDiagram\n    title Clean architecture's approach \n    Actor Request\n    Request -&gt;&gt;+ Controller: JSON\n    Controller -&gt;&gt;+ Service: parser (AccountIn -&gt; Account)\n    Service -&gt;&gt;+ Repository: parser (Account -&gt; AccountModel)\n    Repository -&gt;&gt;+ Database: \n    Database -&gt;&gt;- Repository: \n    Repository -&gt;&gt;- Service: parser (Account &lt;- AccountModel)\n    Service -&gt;&gt;- Controller: parser (AccountOut &lt;- Account)\n    Controller -&gt;&gt;- Request: JSON</code></pre> <p>The relationships between the different layers is done though the use of different DTOs (Data Transfer Objects). Then, to translate between the different layers, we use parsers, which are responsible for converting the DTOs to the entities and vice versa.</p> <ul> <li> <p>The <code>AccountParser</code> class is responsible for this translation, and it contains the methods for converting the <code>AccountIn</code> DTO to the <code>Account</code> entity, and the <code>Account</code> entity to the <code>AccountOut</code> DTO.</p> </li> <li> <p>Also <code>AccountModel</code> is the class that represents the database model of the Account entity, which is used by the <code>AccountRepository</code> to handle the data persistence of the Account entity. The <code>AccountModel</code> class contains the attributes of the Account entity and it is annotated with JPA annotations to define the mapping between the class and the database table.</p> </li> </ul>"},{"location":"hands-on/1/repository/#1-the-object-relational-mapping-orm","title":"1. The Object-Relational Mapping (ORM)","text":"<p>This project uses a Relational Database (PostgreSQL) to store the data of the Account entity. But, the Java programming language is an object-oriented programming language, which means that we need a way to map the relational data to the object-oriented data</p> <p>Object-Relational Mapping (ORM) is a programming technique that allows developers to interact with a relational database using an object-oriented programming language. It provides a way to map database tables to classes and database records to objects, allowing developers to work with data in a more intuitive and natural way. In the context of the Account microservice, we will use an ORM framework, JPA, to handle the data persistence for the Account entity, which will allow us to easily create, read, update, and delete accounts in the database.</p> <p>Here, we can see the code that solves the data persistence concerns of the Account microservice, including the <code>AccountModel</code> class, which represents the database model of the Account entity, and the <code>AccountRepository</code> interface, which is responsible for the data persistence of the Account entity using JPA.</p>"},{"location":"hands-on/1/repository/#2-database-migrations","title":"2. Database Migrations","text":"<p>Once we have the ORM set up, we need to manage our database schema changes. As our application evolves, we may need to add new tables, modify existing tables, or change the data types of columns. To manage these changes, we will use a database migration tool called Flyway<sup>1</sup>.</p> <p>Flyway is a database migration tool that allows us to manage and version our database schema changes. It provides a way to define and execute database migrations, which are scripts that modify the database schema, such as creating tables, adding columns, or changing data types. In the context of the Account microservice, we will use Flyway to manage our database migrations, ensuring that our database schema is always up-to-date and consistent across different environments.</p> <p>In the code, we have a <code>db/migration</code> directory, which contains the migration scripts for the Account microservice. Each migration script is named in a specific format, starting with a version number (e.g., <code>V2026.02.27.001</code>) followed by a description of the migration (e.g., <code>create_schema</code>). These migration scripts will be executed in order by Flyway to ensure that our database schema is always up-to-date.</p>"},{"location":"hands-on/1/repository/#3-code","title":"3. Code","text":"<p>Let's go code the implementation of the Account microservice, which consists of a lot of classes. The resulting directory structure will look like this:</p> <pre><code>\ud83d\udcc1 api/\n\u251c\u2500\u2500 \ud83d\udcc1 account/\n\u251c\u2500\u2500 \ud83d\udcc1 account-service/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 src/\n\u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 main/\n\u2502   \u2502       \u251c\u2500\u2500 \ud83d\udcc1 java/\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 \ud83d\udcc1 store/\n\u2502   \u2502       \u2502       \u2514\u2500\u2500 \ud83d\udcc1 account/\n\u2502   \u2502       \u2502           \u251c\u2500\u2500  Account.java\n\u2502   \u2502       \u2502           \u251c\u2500\u2500  AccountApplication.java\n\u2502   \u2502       \u2502           \u251c\u2500\u2500  AccountModel.java\n\u2502   \u2502       \u2502           \u251c\u2500\u2500  AccountParser.java\n\u2502   \u2502       \u2502           \u251c\u2500\u2500  AccountRepository.java\n\u2502   \u2502       \u2502           \u251c\u2500\u2500  AccountResource.java\n\u2502   \u2502       \u2502           \u2514\u2500\u2500  AccountService.java\n\u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc1 resources/\n\u2502   \u2502           \u251c\u2500\u2500 \ud83d\udcc1 db/\n\u2502   \u2502           \u2502   \u2514\u2500\u2500 \ud83d\udcc1 migration/\n\u2502   \u2502           \u2502       \u251c\u2500\u2500  V2026.02.27.001__create_schema.sql\n\u2502   \u2502           \u2502       \u251c\u2500\u2500  V2026.02.27.002__create_table_account.sql\n\u2502   \u2502           \u2502       \u2514\u2500\u2500  V2026.02.27.003__create_index_email.sql\n\u2502   \u2502           \u2514\u2500\u2500  application.yaml\n\u2502   \u2514\u2500\u2500  pom.xml\n\u2514\u2500\u2500  compose.yaml\n</code></pre> <p>Where, respecting the clean architecture, we have the following classes:</p> Class Description <code>Account</code> This class represents the Account entity, which is the main entity of the Account microservice. It contains the attributes of the Account entity, such as <code>id</code>, <code>name</code>, <code>email</code>, <code>password</code>, and <code>sha256</code>. <code>AccountModel</code> This class represents the Account model, which is responsible for the persistence logic of the Account microservice. It contains the methods for creating, deleting, finding, and updating accounts. <code>AccountParser</code> This class is responsible for parsing the input and output of the API endpoints, converting the <code>AccountIn</code> and <code>AccountOut</code> DTOs to the <code>Account</code> entity, and vice versa. <code>AccountRepository</code> This interface is responsible for the data persistence of the Account entity, using an Object-Relational Mapping (ORM) framework to interact with the database. <code>AccountResource</code> This class is responsible for the API endpoints of the Account microservice, implementing the <code>AccountController</code> interface defined in the <code>account</code> module, and using the <code>AccountService</code> to handle the business logic of the API endpoints. <code>AccountService</code> This class is responsible for the business logic of the Account microservice, using the <code>AccountRepository</code> to handle the data persistence of the Account entity, and the <code>AccountParser</code> to handle the parsing of the input and output of the API endpoints. <p>Source</p> compose.yamlpom.xmlapplication.yamlAccount.javaAccountModel.javaAccountParser.javaAccountRepository.javaAccountResource.javaAccountService.javaV2026.02.27.001__create_schema.sqlV2026.02.27.002__create_table_account.sqlV2026.02.27.003__create_index_email.sql <pre><code>name: store\n\nservices:\n\n  db:\n    image: postgres:17\n    ports:\n      - 5432:5432\n    volumes:\n      - ${VOLUME_DB}:/var/lib/postgresql/data\n    environment:\n      POSTGRES_USER: ${DB_USER:-store}\n      POSTGRES_PASSWORD: ${DB_PASSWORD:-devpass}\n      POSTGRES_DB: ${DB_NAME:-store}\n\n  account:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    environment:\n      DATABASE_HOST: db # Refferences the service name defined in this file\n      DATABASE_PORT: 5432 # Default PostgreSQL port\n      DATABASE_DB: ${DB_NAME:-store} # Optional: Use the same DB name as defined for the db service\n      DATABASE_USERNAME: ${DB_USER:-store} # Optional: Use the same username as defined for the db service\n      DATABASE_PASSWORD: ${DB_PASSWORD:-devpass} # Optional\n    ports:\n      - 8080:8080\n    depends_on:\n      - db\n</code></pre> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n\n    &lt;parent&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n        &lt;version&gt;4.0.3&lt;/version&gt;\n        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\n    &lt;/parent&gt;\n\n    &lt;groupId&gt;store&lt;/groupId&gt;\n    &lt;artifactId&gt;account-service&lt;/artifactId&gt;\n    &lt;version&gt;1.0.0&lt;/version&gt;\n    &lt;name&gt;account-service&lt;/name&gt;\n\n    &lt;properties&gt;\n        &lt;java.version&gt;25&lt;/java.version&gt;\n        &lt;spring-cloud.version&gt;2025.1.0&lt;/spring-cloud.version&gt;\n        &lt;maven.compiler.proc&gt;full&lt;/maven.compiler.proc&gt;\n    &lt;/properties&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-webmvc&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;store&lt;/groupId&gt;\n            &lt;artifactId&gt;account&lt;/artifactId&gt;\n            &lt;version&gt;${project.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.postgresql&lt;/groupId&gt;\n            &lt;artifactId&gt;postgresql&lt;/artifactId&gt;\n            &lt;scope&gt;runtime&lt;/scope&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-flyway&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.flywaydb&lt;/groupId&gt;\n            &lt;artifactId&gt;flyway-database-postgresql&lt;/artifactId&gt;\n            &lt;scope&gt;runtime&lt;/scope&gt;\n        &lt;/dependency&gt;\n\n    &lt;/dependencies&gt;\n    &lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;annotationProcessorPaths&gt;\n                        &lt;path&gt;\n                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n                        &lt;/path&gt;\n                    &lt;/annotationProcessorPaths&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;excludes&gt;\n                        &lt;exclude&gt;\n                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n                        &lt;/exclude&gt;\n                    &lt;/excludes&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n&lt;/project&gt;\n</code></pre> <pre><code>server:\n  port: 8080\n\nspring:\n\n  application:\n    name: account\n\n  mvc:\n    problemdetails:\n      enabled: true\n\n  datasource:\n    url: jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT}/${DATABASE_DB}\n    username: ${DATABASE_USERNAME}\n    password: ${DATABASE_PASSWORD}\n    driver-class-name: org.postgresql.Driver\n\n  flyway:\n    baseline-on-migrate: true\n    schemas: accounts\n\n  jpa:\n    properties:\n      hibernate:\n        default_schema: accounts\n</code></pre> <pre><code>package store.account;\n\nimport java.util.List;\n\nimport lombok.Builder;\nimport lombok.Data;\nimport lombok.experimental.Accessors;\n\n@Data @Builder\n@Accessors(fluent = true)\npublic class Account {\n\n    private String id;\n    private String name;\n    private String email;\n    private String password;\n\n}\n</code></pre> <pre><code>package store.account;\n\nimport jakarta.persistence.Column;\nimport jakarta.persistence.Entity;\nimport jakarta.persistence.GeneratedValue;\nimport jakarta.persistence.GenerationType;\nimport jakarta.persistence.Id;\nimport jakarta.persistence.Table;\nimport lombok.AllArgsConstructor;\nimport lombok.NoArgsConstructor;\nimport lombok.Setter;\nimport lombok.experimental.Accessors;\n\n@Entity\n@Table(name = \"accounts\")\n@Setter @Accessors(chain = true, fluent = true)\n@NoArgsConstructor @AllArgsConstructor\npublic class AccountModel {\n\n    @Id\n    @Column(name = \"id\")\n    @GeneratedValue(strategy = GenerationType.UUID)\n    private String id;\n\n    @Column(name = \"name\")\n    private String name;\n\n    @Column(name = \"email\")\n    private String email;\n\n    public AccountModel(Account a) {\n        this.id = a.id();\n        this.name = a.name();\n        this.email = a.email();\n    }\n\n    public Account to() {\n        return Account.builder()\n            .id(this.id)\n            .name(this.name)\n            .email(this.email)\n            .build();\n    }\n\n}\n</code></pre> <pre><code>package store.account;\n\nimport java.util.List;\n\npublic class AccountParser {\n\n    public static Account to(AccountIn in) {\n        return in == null ? null :\n            Account.builder()\n                .name(in.name())\n                .email(in.email())\n                .password(in.password())\n                .build();\n    }\n\n    public static AccountOut to(Account a) {\n        return a == null ? null :\n            AccountOut.builder()\n                .id(a.id())\n                .name(a.name())\n                .email(a.email())\n                .build();\n    }\n\n    public static List&lt;AccountOut&gt; to(List&lt;Account&gt; as) {\n        return as == null ? null :\n            as.stream().map(AccountParser::to).toList();\n    }\n\n}\n</code></pre> <pre><code>package store.account;\n\nimport java.util.Optional;\n\nimport org.springframework.data.repository.CrudRepository;\nimport org.springframework.stereotype.Repository;\n\n@Repository\npublic interface AccountRepository extends CrudRepository&lt;AccountModel, String&gt; {\n\n    AccountModel findByEmail(String email);\n    Optional&lt;AccountModel&gt; findByEmailAndSha256(String email, String sha256);\n\n}\n</code></pre> <pre><code>\n</code></pre> <pre><code>package store.account;\n\nimport java.nio.charset.StandardCharsets;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.Base64;\nimport java.util.List;\nimport java.util.stream.StreamSupport;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.stereotype.Service;\nimport org.springframework.web.server.ResponseStatusException;\n\n@Service\npublic class AccountService {\n\n    private Logger looger = LoggerFactory.getLogger(AccountService.class);\n\n    @Autowired\n    private AccountRepository accountRepository;\n\n    public Account create(Account account) {\n        if (null == account.password()) {\n            throw new ResponseStatusException(HttpStatus.BAD_REQUEST,\n                \"Password is mandatory!\"\n            );\n        }\n        // clean special caracters\n        account.password(account.password().trim());\n        if (account.password().length() &lt; 4) {\n            throw new ResponseStatusException(HttpStatus.BAD_REQUEST,\n                \"Password is too short!\"\n            );\n        }\n        if (null == account.email()) {\n            throw new ResponseStatusException(HttpStatus.BAD_REQUEST,\n                \"Email is mandatory!\"\n            );\n        }\n\n        if (accountRepository.findByEmail(account.email()) != null)\n            throw new ResponseStatusException(HttpStatus.BAD_REQUEST,\n                \"Email already have been registered!\"\n            );\n\n        account.sha256(hash(account.password()));\n\n        return accountRepository.save(\n            new AccountModel(account)\n        ).to();\n    }\n\n    public List&lt;Account&gt; findAll() {\n        return StreamSupport.stream(\n            accountRepository.findAll().spliterator(), false)\n            .map(AccountModel::to)\n            .toList();\n    }\n\n    public Account findById(String id) {\n        return accountRepository.findById(id).map(AccountModel::to).orElse(null);\n    }\n\n    public Account findByEmailAndPassword(String email, String password) {\n        String sha256 = hash(password);\n        return accountRepository.findByEmailAndSha256(email, sha256).map(AccountModel::to).orElse(null);\n    }\n\n    public void delete(String id) {\n        accountRepository.delete(new AccountModel().id(id));\n    }\n\n    private String hash(String pass) {\n        looger.debug(\"calculing the hash\");\n        try {\n            MessageDigest digest = MessageDigest.getInstance(\"SHA-256\");\n            byte[] encodedHash = digest.digest(\n                pass.getBytes(StandardCharsets.UTF_8)\n            );\n            return Base64.getEncoder().encodeToString(encodedHash);\n        } catch (NoSuchAlgorithmException e) {\n            throw new ResponseStatusException(HttpStatus.INTERNAL_SERVER_ERROR, e.getMessage(), e);\n        }\n    }\n\n}\n</code></pre> <pre><code>\n</code></pre> <pre><code>\n</code></pre> <pre><code>\n</code></pre> <ol> <li>Running the Microservice</li> </ol> <p>To run the Account microservice, we can use the <code>docker-compose</code> command to start the microservice and its dependencies (e.g., the PostgreSQL database). Make sure you are in the root directory of the project, where the <code>compose.yaml</code> file is located, and run the following command:</p> <pre><code>docker compose up --build\n</code></pre> <p>Note that the <code>--build</code> flag is used to build the Docker images before starting the containers, which is necessary if you have made changes to the code or the Dockerfile.</p> <p>Also, we can monitoring the logs of the microservice to see if it is running correctly. See there that the Flyway migrations are being executed, and that the microservice is starting up without any errors. You should see logs indicating that the microservice is up and running, and that it is connected to the database. In additional, you can also check the database to see if the migrations have been executed correctly, and that the tables have been created as expected.</p> <ol> <li> <p>Going inside the container:</p> Entering the container<pre><code>docker exec -it account-service bash\n</code></pre> </li> <li> <p>Going inside the PostgreSQL database:</p> Entering the PostgreSQL database<pre><code>psql -U store -d store\n</code></pre> </li> <li> <p>Verifying the migrations:</p> List the schemas<pre><code>\\dn\n</code></pre> List the tables<pre><code>\\dt *.*\n</code></pre> </li> </ol> <p>Yet, if you want to monitor the logs of the microservice without going inside the container, you can use the <code>docker logs</code> command to view the logs of the container. This will allow you to see the logs in real-time, and you can use it to monitor the startup process of the microservice, as well as any errors or issues that may arise.</p> Monitoring the logs<pre><code>docker logs -f account-service\n</code></pre> <p>Done!</p> <ol> <li> <p>Criando Migrations com Flyway no seu projeto Java Spring &amp; PostgreSQL \u21a9</p> </li> </ol>"},{"location":"hands-on/1/service/","title":"c. Service","text":"<p>The implementation of the Account microservice is defined in the <code>account-service</code> module, which contains the implementation of the API defined in the <code>account</code> module, as well as, the database access and the business logic for the Account microservice. </p> <pre><code>classDiagram\n    namespace account {\n        class AccountController {\n            +create(AccountIn accountIn): AccountOut\n            +delete(String id): void\n            +findAll(): List&lt;AccountOut&gt;\n            +findById(String id): AccountOut\n        }\n        class AccountIn {\n            -String name\n            -String email\n            -String password\n        }\n        class AccountOut {\n            -String id\n            -String name\n            -String email\n        }\n    }\n    namespace account-service {\n        class AccountResource {\n            +create(AccountIn accountIn): AccountOut\n            +delete(String id): void\n            +findAll(): List&lt;AccountOut&gt;\n            +findById(String id): AccountOut\n        }\n        class AccountService {\n            +create(AccountIn accountIn): AccountOut\n            +delete(String id): void\n            +findAll(): List&lt;AccountOut&gt;\n            +findById(String id): AccountOut\n        }\n        class AccountRepository {\n            +create(AccountIn accountIn): AccountOut\n            +delete(String id): void\n            +findAll(): List&lt;AccountOut&gt;\n            +findById(String id): AccountOut\n        }\n        class Account {\n            -String id\n            -String name\n            -String email\n            -String password\n            -String sha256\n        }\n        class AccountModel {\n            +create(AccountIn accountIn): AccountOut\n            +delete(String id): void\n            +findAll(): List&lt;AccountOut&gt;\n            +findById(String id): AccountOut\n        }\n    }\n    &lt;&lt;Interface&gt;&gt; AccountController\n    AccountController ..&gt; AccountIn\n    AccountController ..&gt; AccountOut\n\n    &lt;&lt;Interface&gt;&gt; AccountRepository\n    AccountController &lt;|-- AccountResource\n    AccountResource *-- AccountService\n    AccountService *-- AccountRepository\n    AccountService ..&gt; Account\n    AccountService ..&gt; AccountModel\n    AccountRepository ..&gt; AccountModel</code></pre>"},{"location":"hands-on/1/service/#1-repository","title":"1. Repository","text":"<p>Create the repository for the Account interface on GitHub, and clone it as a submodule to your local machine;</p> <pre><code>git submodule add &lt;repository_url&gt; api/account-service\n</code></pre> <pre><code>\ud83d\udcc1 api/\n\u251c\u2500\u2500 \ud83d\udcc1 account/\n\u2514\u2500\u2500 \ud83d\udcc1 account-service/\n</code></pre>"},{"location":"hands-on/1/service/#2-code","title":"2. Code","text":"<p>Now, we will code the implementation of the Account microservice, which consists of a lot of classes. The resulting directory structure will look like this:</p> <pre><code>\ud83d\udcc1 api/\n\u2514\u2500\u2500 \ud83d\udcc1 account-service/\n    \u251c\u2500\u2500 \ud83d\udcc1 src/\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc1 main/\n    \u2502       \u251c\u2500\u2500 \ud83d\udcc1 java/\n    \u2502       \u2502   \u2514\u2500\u2500 \ud83d\udcc1 store/\n    \u2502       \u2502       \u2514\u2500\u2500 \ud83d\udcc1 account/\n    \u2502       \u2502           \u251c\u2500\u2500  AccountApplication.java\n    \u2502       \u2502           \u2514\u2500\u2500  AccountResource.java\n    \u2502       \u2514\u2500\u2500 \ud83d\udcc1 resources/\n    \u2502           \u2514\u2500\u2500  application.yaml\n    \u2514\u2500\u2500  pom.xml\n</code></pre> Class Description <code>AccountResource</code> This class is responsible for the API endpoints of the Account microservice, implementing the <code>AccountController</code> interface defined in the <code>account</code> module, and using the <code>AccountService</code> to handle the business logic of the API endpoints. <code>AccountApplication</code> This class is the main class of the Account microservice, which is responsible for running the Spring Boot application. It contains the <code>main</code> method, which is the entry point of the application. <p>To code this microservice, we will use the Spring Boot framework, through the Spring Initializr, at [https://start.spring.io/], which is a web-based tool that allows us to generate a Spring Boot project with the necessary dependencies and configurations. </p> Spring Initializr <p>Note:</p> <ul> <li>Project: Maven</li> <li>Language: Java</li> <li>Spring Boot: 4.0.3 (stable version for now)</li> <li>Group: store (the company name, for example)</li> <li>Artifact: account-service (the implementation name)</li> <li>Package name: store.account</li> <li>Packaging: Jar</li> <li>Configurarion: YAML</li> <li>Java: 25 (LTS version for now)</li> </ul> <p>Additionally, we need to add the following dependencies:</p> <ul> <li> <p>Spring Web: a dependency that allows us to create RESTful web services using the Spring framework. It provides the necessary tools and libraries to handle HTTP requests and responses, as well as, to define API endpoints and controllers.</p> </li> <li> <p>Lombok: a Java library that helps to reduce boilerplate code by generating getters, setters, constructors, and other common methods at compile time using annotations.</p> </li> <li> <p>OpenFeign: a declarative web service client that simplifies the process of making HTTP requests to other microservices. It allows us to define interfaces for our API clients and automatically generates the implementation at runtime.</p> </li> </ul> <p>For now, we will just create the <code>AccountResource</code> and <code>AccountApplication</code> classes, and the <code>application.yaml</code> configuration file. We will implement the business logic and the data persistence in the next sections.</p> <p>At <code>AccountResource.java</code>, the only endpoint implemented for now is <code>health-check</code>, which is a simple endpoint that returns a <code>200 OK</code> status code, indicating that the microservice is up and running.</p> <p>Source</p> pom.xmlapplication.yamlAccountApplication.javaAccountResource.java <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n\n    &lt;parent&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n        &lt;version&gt;4.0.3&lt;/version&gt;\n        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\n    &lt;/parent&gt;\n\n    &lt;groupId&gt;store&lt;/groupId&gt;\n    &lt;artifactId&gt;account-service&lt;/artifactId&gt;\n    &lt;version&gt;1.0.0&lt;/version&gt;\n    &lt;name&gt;account-service&lt;/name&gt;\n\n    &lt;properties&gt;\n        &lt;java.version&gt;25&lt;/java.version&gt;\n        &lt;spring-cloud.version&gt;2025.1.0&lt;/spring-cloud.version&gt;\n        &lt;maven.compiler.proc&gt;full&lt;/maven.compiler.proc&gt;\n    &lt;/properties&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-webmvc&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;store&lt;/groupId&gt;\n            &lt;artifactId&gt;account&lt;/artifactId&gt;\n            &lt;version&gt;${project.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n\n    &lt;/dependencies&gt;\n    &lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;annotationProcessorPaths&gt;\n                        &lt;path&gt;\n                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n                        &lt;/path&gt;\n                    &lt;/annotationProcessorPaths&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;excludes&gt;\n                        &lt;exclude&gt;\n                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n                        &lt;/exclude&gt;\n                    &lt;/excludes&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n&lt;/project&gt;\n</code></pre> <pre><code>server:\n  port: 8080\n\nspring:\n  application:\n    name: account\n</code></pre> <pre><code>package store.account;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class AccountApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(AccountApplication.class, args);\n    }\n\n}\n</code></pre> <pre><code>package store.account;\n\nimport java.util.List;\n\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class AccountResource implements AccountController {\n\n    @Override\n    public ResponseEntity&lt;Void&gt; create(AccountIn in) {\n        // TODO Auto-generated method stub\n        return null;\n    }\n\n    @Override\n    public ResponseEntity&lt;Void&gt; delete(String id) {\n        // TODO Auto-generated method stub\n        return ResponseEntity.noContent().build();\n    }\n\n    @Override\n    public ResponseEntity&lt;Void&gt; healthCheck() {\n        return ResponseEntity.ok().build();\n    }\n\n    @Override\n    public ResponseEntity&lt;List&lt;AccountOut&gt;&gt; findAll() {\n        // TODO Auto-generated method stub\n        return null;\n    }\n\n    @Override\n    public ResponseEntity&lt;AccountOut&gt; findById(String id) {\n        // just an example\n        AccountOut out = AccountOut.builder()\n            .name(\"John\")\n            .email(\"JAlbert@xpto.gov\")\n            .id(\"1345\")\n            .build();\n        return ResponseEntity.ok(\n            out\n        );\n    }\n\n}\n</code></pre>"},{"location":"hands-on/1/service/#3-package-and-run","title":"3. Package and Run","text":"<pre><code>mvn clean package\njava -jar target/account-service-1.0.0.jar\n</code></pre> <p>or</p> <pre><code>mvn clean package spring-boot:run\n</code></pre> <p>Check the health of the microservice by sending a GET request to the <code>health-check</code> endpoint:</p> <pre><code>curl -X GET http://localhost:8080/health-check\n</code></pre> <p>If everything is working correctly, you should receive a <code>200 OK</code> status code in the response, indicating that the microservice is up and running.</p> <p>Done! The Account Microservice is now ready to be used in the project.</p> <p>Let's move on to the next section, where we will containerize the Account microservice using Docker, and run it using Docker Compose.</p> <p>Containerization</p>"},{"location":"hands-on/2/","title":"2. Gateway","text":"<p>The main functionality of Gateway Microservice is to route the incoming requests to the appropriate microservice, therefore, it is the entry point for all the incoming requests. In counterpart, each microservice have to expose their own port and endpoints to the internet, which is not a good practice. The Gateway Microservice will act as a reverse proxy and route the incoming requests to the appropriate microservice. Also, it will also handle the authentication and authorization of the incoming requests.</p> <pre><code>flowchart LR\n    subgraph api [Trusted Layer]\n        direction TB\n        gateway e2@==&gt; account\n        gateway e4@==&gt; others\n        account --&gt; db@{ shape: cyl, label: \"Database\" }\n        others --&gt; db\n    end\n    internet e1@==&gt;|request| gateway:::red\n    e1@{ animate: true }\n    e2@{ animate: true }\n    e4@{ animate: true }\n    classDef red fill:#fcc</code></pre> <p>The key functionalities of Gateway Microservice are:</p> <ul> <li>Routing: it will route the incoming requests to the appropriate microservice.</li> <li>Authentication/Authorization: it will handle the authentication and the authorization of the incoming requests.</li> </ul>"},{"location":"hands-on/2/#gateway-service","title":"Gateway-Service","text":"<pre><code>\ud83d\udcc1 api\n\u2514\u2500\u2500 \ud83d\udcc1 gateway-service/\n    \u251c\u2500\u2500 \ud83d\udcc1 src/\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc1 main/\n    \u2502       \u251c\u2500\u2500 \ud83d\udcc1 java/\n    \u2502       \u2502   \u2514\u2500\u2500 \ud83d\udcc1 store/\n    \u2502       \u2502       \u2514\u2500\u2500 \ud83d\udcc1 gateway/\n    \u2502       \u2502           \u251c\u2500\u2500  GatewayApplication.java\n    \u2502       \u2502           \u251c\u2500\u2500  GatewayResource.java\n    \u2502       \u2502           \u2514\u2500\u2500 \ud83d\udcc1 security\n    \u2502       \u2502               \u2514\u2500\u2500  CorsFilter.java\n    \u2502       \u2514\u2500\u2500 \ud83d\udcc1 resources/\n    \u2502           \u2514\u2500\u2500  application.yaml\n    \u251c\u2500\u2500  pom.xml\n    \u2514\u2500\u2500  Dockerfile\n</code></pre> Source pom.xmlapplication.yamlGatewayApplication.javaGatewayResource.javaCorsFilter.javaDockerfile <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;parent&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n        &lt;version&gt;4.0.1&lt;/version&gt;\n        &lt;relativePath/&gt;\n    &lt;/parent&gt;\n\n    &lt;groupId&gt;store&lt;/groupId&gt;\n    &lt;artifactId&gt;gateway-service&lt;/artifactId&gt;\n    &lt;version&gt;1.0.0&lt;/version&gt;\n\n    &lt;properties&gt;\n        &lt;java.version&gt;25&lt;/java.version&gt;\n        &lt;spring-cloud.version&gt;2025.1.0&lt;/spring-cloud.version&gt;\n        &lt;maven.compiler.proc&gt;full&lt;/maven.compiler.proc&gt;\n    &lt;/properties&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-gateway-server-webflux&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n        &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n\n    &lt;/dependencies&gt;\n\n    &lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;excludes&gt;\n                        &lt;exclude&gt;\n                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n                        &lt;/exclude&gt;\n                    &lt;/excludes&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;${java.version}&lt;/source&gt;\n                    &lt;target&gt;${java.version}&lt;/target&gt;\n                    &lt;release&gt;${java.version}&lt;/release&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n&lt;/project&gt;\n</code></pre> <pre><code>server:\n  port: 8080\n\nspring:\n\n  application:\n    name: gateway\n\n  mvc:\n    problemdetails:\n      enabled: true\n\n  cloud:\n    gateway:\n      server:\n        webflux:\n          routes:\n\n            - id: insper\n              uri: https://www.insper.edu.br\n              predicates:\n                - Path=/insper/**\n\n            - id: account\n              uri: http://account:8080\n              predicates:\n                - Path=/account/**\n\n            - id: auth\n              uri: http://auth:8080\n              predicates:\n                - Path=/auth/**\n\n          globalcors:\n            corsConfigurations:\n              '[/**]':\n                allowedOrigins: ${CORS_ALLOWED_ORIGINS}\n                allowedHeaders: \"*\"\n                allowedMethods: \"*\"\n                allowCredentials: ${CORS_ALLOW_CREDENTIALS:true}\n\nlogging:\n  level:\n    root: info\n    store: debug\n</code></pre> <pre><code>package store.gateway;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class GatewayApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(GatewayApplication.class, args);\n    }\n\n}\n</code></pre> <pre><code>package store.gateway;\n\nimport java.net.InetAddress;\nimport java.util.Map;\n\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class GatewayResource {\n\n    @GetMapping(\"/health-check\")\n    public ResponseEntity&lt;Map&lt;String, String&gt;&gt; healthCheck() {\n        String ip = \"\";\n        try {\n            ip = InetAddress.getLocalHost().getHostAddress();\n        } catch (Exception e) {\n            ip = e.getMessage();\n        }\n        return ResponseEntity.ok()\n            .body(Map.of(\n                \"osArch\", System.getProperty(\"os.arch\"),\n                \"osName\", System.getProperty(\"os.name\"),\n                \"osVersision\", System.getProperty(\"os.version\"),\n                \"hostAddress\", ip\n            ));\n    }\n\n    @GetMapping(\"/\")\n    public ResponseEntity&lt;String&gt; hello() {\n        return ResponseEntity.ok()\n            .body(\"API by In5p3R\");\n    }\n\n}\n</code></pre> <pre><code>\n</code></pre> <pre><code>FROM eclipse-temurin:25\nVOLUME /tmp\nCOPY target/*.jar /app.jar\nENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]\n</code></pre>"},{"location":"hands-on/3/","title":"Index","text":"<p>A secutiry of the system is a very important aspect of the system. All security systems are based on authentication and authorization.</p> <ul> <li> <p>Authentication is the process of verifying the identity of a user.</p> </li> <li> <p>Authorization is the process of verifying what the user has access to.</p> </li> </ul> <pre><code>flowchart LR\n    subgraph api [Trusted Layer]\n        direction TB\n        gateway --&gt; account\n        gateway --&gt; others\n        gateway e4@==&gt; auth:::red\n        auth e2@==&gt; account\n        account --&gt; db@{ shape: cyl, label: \"Database\" }\n        others --&gt; db\n    end\n    internet e1@==&gt;|request| gateway:::orange\n    e1@{ animate: true }\n    e2@{ animate: true }\n    e4@{ animate: true }\n    classDef red fill:#fcc\n    classDef orange fill:#FCBE3E</code></pre> <pre><code>classDiagram\n    namespace auth {\n        class AuthController {\n            +register(RegisterIn RegisterIn): TokenOut\n            +login(LoginIn loginIn): TokenOut\n        }\n        class RegisterIn {\n            -String name\n            -String email\n            -String password\n        }\n        class LoginIn {\n            -String name\n            -String email\n        }\n        class TokenOut {\n            -String token\n        }\n        class SolveOut {\n            -String idAccount\n        }\n    }\n    namespace auth-service {\n        class AuthResource {\n            +register(RegisterIn RegisterIn) TokenOut\n            +login(LoginIn loginIn) TokenOut\n        }\n        class AuthService {\n            +register(Register) Regiter\n            +login(LoginIn loginIn) String\n        }\n        class Register {\n            -String id\n            -String name\n            -String email\n            -String password\n        }\n    }\n    &lt;&lt;Interface&gt;&gt; AuthController\n    AuthController ..&gt; RegisterIn\n    AuthController ..&gt; LoginIn\n    AuthController ..&gt; TokenOut\n\n    AuthController &lt;|-- AuthResource\n    AuthResource *-- AuthService\n    AuthService ..&gt; Register</code></pre>"},{"location":"hands-on/3/#auth","title":"Auth","text":"<pre><code>\ud83d\udcc1 api\n\u2514\u2500\u2500 \ud83d\udcc1 auth\n    \u251c\u2500\u2500 \ud83d\udcc1 src\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc1 main\n    \u2502       \u2514\u2500\u2500 \ud83d\udcc1 java\n    \u2502           \u2514\u2500\u2500 \ud83d\udcc1 store\n    \u2502               \u2514\u2500\u2500 \ud83d\udcc1 auth\n    \u2502                   \u251c\u2500\u2500  AuthController.java\n    \u2502                   \u251c\u2500\u2500  LoginIn.java\n    \u2502                   \u251c\u2500\u2500  RegisterIn.java\n    \u2502                   \u2514\u2500\u2500  TokenOut.java\n    \u2514\u2500\u2500  pom.xml\n</code></pre> Source pom.xmlAuthController.javaLoginIn.javaRegisterIn.javaTokenOut.java <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;parent&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n        &lt;version&gt;4.0.1&lt;/version&gt;\n        &lt;relativePath/&gt;\n    &lt;/parent&gt;\n\n    &lt;groupId&gt;store&lt;/groupId&gt;\n    &lt;artifactId&gt;auth&lt;/artifactId&gt;\n    &lt;version&gt;1.0.0&lt;/version&gt;\n\n    &lt;properties&gt;\n        &lt;java.version&gt;25&lt;/java.version&gt;\n        &lt;spring-cloud.version&gt;2025.1.0&lt;/spring-cloud.version&gt;\n        &lt;maven.compiler.proc&gt;full&lt;/maven.compiler.proc&gt;\n    &lt;/properties&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n\n    &lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;${java.version}&lt;/source&gt;\n                    &lt;target&gt;${java.version}&lt;/target&gt;\n                    &lt;release&gt;${java.version}&lt;/release&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n&lt;/project&gt;\n</code></pre> <pre><code>package store.auth;\n\nimport java.util.Map;\n\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestBody;\nimport org.springframework.web.bind.annotation.RequestHeader;\n\n@FeignClient(name = \"auth\", url = \"http://auth:8080\")\npublic interface AuthController {\n\n    @PostMapping(\"/auth/register\")\n    public ResponseEntity&lt;Void&gt; register(\n        @RequestBody RegisterIn in,\n        @RequestHeader(\"Origin\") String origin\n    );\n\n    @PostMapping(\"/auth/login\")\n    public ResponseEntity&lt;Void&gt; login(\n        @RequestBody LoginIn in,\n        @RequestHeader(\"Origin\") String origin\n    );\n\n    @PostMapping(\"/auth/logout\")\n    public ResponseEntity&lt;Void&gt; logout(\n        @RequestHeader(\"Origin\") String origin\n    );\n\n    @PostMapping(\"/auth/solve\")\n    public ResponseEntity&lt;Map&lt;String, String&gt;&gt; solve(\n        @RequestBody TokenOut in\n    );\n\n}\n</code></pre> <pre><code>package store.auth;\n\nimport lombok.Builder;\n\n@Builder\npublic record LoginIn(\n    String email,\n    String password\n) {\n\n}\n</code></pre> <pre><code>package store.auth;\n\nimport lombok.Builder;\n\n@Builder\npublic record RegisterIn(\n    String name,\n    String email,\n    String password\n) {\n\n}\n</code></pre> <pre><code>package store.auth;\n\nimport lombok.Builder;\n\n@Builder\npublic record TokenOut (\n    String jwt\n) {\n\n}\n</code></pre>"},{"location":"hands-on/3/#auth-service","title":"Auth-Service","text":"<pre><code>\ud83d\udcc1 api\n\u2514\u2500\u2500 \ud83d\udcc1 auth-service\n    \u251c\u2500\u2500 \ud83d\udcc1 src\n    \u2502   \u251c\u2500\u2500 \ud83d\udcc1 main\n    \u2502   \u2502   \u2514\u2500\u2500 \ud83d\udcc1 java\n    \u2502   \u2502       \u2514\u2500\u2500 \ud83d\udcc1 store\n    \u2502   \u2502           \u2514\u2500\u2500 \ud83d\udcc1 auth\n    \u2502   \u2502               \u251c\u2500\u2500  AuthApplication.java\n    \u2502   \u2502               \u251c\u2500\u2500  AuthResource.java\n    \u2502   \u2502               \u251c\u2500\u2500  AuthService.java\n    \u2502   \u2502               \u2514\u2500\u2500  JwtService.java\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc1 resources\n    \u2502       \u2514\u2500\u2500  application.yaml\n    \u251c\u2500\u2500  pom.xml\n    \u2514\u2500\u2500  Dockerfile\n</code></pre> Source pom.xmlapplication.yamlAuthApplication.javaAuthResource.javaAuthService.javaJwtService.javaDockerfile <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;parent&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n        &lt;version&gt;4.0.1&lt;/version&gt;\n        &lt;relativePath/&gt;\n    &lt;/parent&gt;\n\n    &lt;groupId&gt;store&lt;/groupId&gt;\n    &lt;artifactId&gt;auth-service&lt;/artifactId&gt;\n    &lt;version&gt;1.0.0&lt;/version&gt;\n\n    &lt;properties&gt;\n        &lt;java.version&gt;25&lt;/java.version&gt;\n        &lt;spring-cloud.version&gt;2025.1.0&lt;/spring-cloud.version&gt;\n        &lt;maven.compiler.proc&gt;full&lt;/maven.compiler.proc&gt;\n    &lt;/properties&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;${project.groupId}&lt;/groupId&gt;\n            &lt;artifactId&gt;auth&lt;/artifactId&gt;\n            &lt;version&gt;${project.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;${project.groupId}&lt;/groupId&gt;\n            &lt;artifactId&gt;account&lt;/artifactId&gt;\n            &lt;version&gt;${project.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n\n        &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n\n        &lt;!-- https://mvnrepository.com/artifact/io.jsonwebtoken/jjwt-api --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;\n            &lt;artifactId&gt;jjwt-api&lt;/artifactId&gt;\n            &lt;version&gt;[0.13,)&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;\n            &lt;artifactId&gt;jjwt-impl&lt;/artifactId&gt;\n            &lt;version&gt;[0.13,)&lt;/version&gt;\n            &lt;scope&gt;runtime&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;\n            &lt;artifactId&gt;jjwt-jackson&lt;/artifactId&gt; &lt;!-- or jjwt-gson if Gson is preferred --&gt;\n            &lt;version&gt;[0.13,)&lt;/version&gt;\n            &lt;scope&gt;runtime&lt;/scope&gt;\n        &lt;/dependency&gt;\n\n    &lt;/dependencies&gt;\n\n    &lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;excludes&gt;\n                        &lt;exclude&gt;\n                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n                        &lt;/exclude&gt;\n                    &lt;/excludes&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;${java.version}&lt;/source&gt;\n                    &lt;target&gt;${java.version}&lt;/target&gt;\n                    &lt;release&gt;${java.version}&lt;/release&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n&lt;/project&gt;\n</code></pre> <pre><code>server:\n  port: 8080\n\nspring:\n  application:\n    name: auth\n\n  mvc:\n    problemdetails:\n      enabled: true\n\nstore:\n  jwt:\n    secretKey: ${STORE_JWT_SECRET_KEY:changeit}\n  token:\n    duration: ${STORE_TOKEN_DURATION:3600000} # 1 hour in milliseconds\n    https: ${STORE_TOKEN_HTTPS:true}\n\nlogging:\n  level:\n    root: info\n    store: debug\n</code></pre> <pre><code>package store.auth;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.openfeign.EnableFeignClients;\n\n@EnableFeignClients(basePackages = {\n    \"store.account\"\n})\n@SpringBootApplication\npublic class AuthApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(AuthApplication.class, args);\n    }\n\n}\n</code></pre> <pre><code>package store.auth;\n\nimport java.time.Duration;\nimport java.util.Map;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.http.HttpHeaders;\nimport org.springframework.http.ResponseCookie;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.RestController;\nimport org.springframework.web.servlet.support.ServletUriComponentsBuilder;\n\nimport store.account.AccountOut;\n\n@RestController\npublic class AuthResource implements AuthController {\n\n    private Logger logger = LoggerFactory.getLogger(AuthResource.class);\n\n    @Autowired\n    private AuthService authService;\n\n    @Override\n    public ResponseEntity&lt;Void&gt; register(RegisterIn in, String origin) {\n        final String jwt = authService.register(\n            in.name(), in.email(), in.password()\n        );\n        return ResponseEntity.created(\n                ServletUriComponentsBuilder.fromCurrentRequest().build().toUri()\n            )\n            .header(HttpHeaders.SET_COOKIE, buildTokenCookie(jwt, origin, authService.getTokenDuration()).toString())\n            .build();\n    }\n\n    @Override\n    public ResponseEntity&lt;Void&gt; login(LoginIn in, String origin) {\n        final String jwt = authService.login(\n            in.email(),\n            in.password()\n        );\n        ResponseEntity&lt;Void&gt; response = ResponseEntity\n            .ok()\n            .header(HttpHeaders.SET_COOKIE, buildTokenCookie(jwt, origin, authService.getTokenDuration()).toString())\n            .build();\n        logger.debug(\"Response: \" + response);\n        return response;\n    }\n\n    @Override\n    public ResponseEntity&lt;Void&gt; logout(String origin) {\n        return ResponseEntity.ok()\n            .header(HttpHeaders.SET_COOKIE, buildTokenCookie(null, origin, 0l).toString())\n            .build();\n    }\n\n    @Override\n    public ResponseEntity&lt;Map&lt;String, String&gt;&gt; solve(TokenOut in) {\n        AccountOut account = authService.solve(in.jwt());\n        return ResponseEntity.ok(\n            Map.of(\n                \"idAccount\", account.id()\n            )\n        );\n    }\n\n    private ResponseCookie buildTokenCookie(String content, String origin, Long duration) {\n        return ResponseCookie.from(AuthService.AUTH_COOKIE_TOKEN, content)\n            .httpOnly(true)\n            .sameSite(\"None\")\n            .secure(authService.getTokenHTTPS()) // true em HTTPS\n            .path(\"/\")\n            .maxAge(Duration.ofMillis(duration))\n            .build();\n        // .header(\"Access-Control-Allow-Origin\", origin)\n        // .header(\"Access-Control-Allow-Credentials\", \"true\")\n    }\n\n}\n</code></pre> <pre><code>package store.auth;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.stereotype.Service;\nimport org.springframework.web.server.ResponseStatusException;\n\nimport store.account.AccountController;\nimport store.account.AccountIn;\nimport store.account.AccountOut;\n\n@Service\npublic class AuthService {\n\n    public static final String AUTH_COOKIE_TOKEN = \"__store_jwt_token\";\n\n    private Logger logger = LoggerFactory.getLogger(AuthService.class);\n\n    @Value(\"${store.token.duration}\")\n    private Long tokenDuration;\n\n    @Value(\"${store.token.https}\")\n    private Boolean tokenHTTPS;\n\n    @Autowired\n    private AccountController accountController;\n\n    @Autowired\n    private JwtService jwtService;\n\n    public String register(String name, String email, String password) {\n\n        logger.debug(\n            String.format(\n                \"registrando uma conta: [%s] for [%s]\",\n                name, email\n            )\n        );\n\n        // Salvar no servico de Account\n        AccountOut account = accountController.create(AccountIn.builder()\n            .name(name)\n            .email(email)\n            .password(password)\n            .build()\n        ).getBody();\n\n        // Gera um token\n        String jwtString = jwtService.generate(account, tokenDuration);\n\n        // Retorna o token\n        return jwtString;\n    }\n\n    public String login(String email, String password) {\n\n        logger.debug(String.format(\"required login for %s:%s\", email, password));\n\n        // Verify credentials\n        ResponseEntity&lt;AccountOut&gt; response = accountController.findByEmailAndPassword(\n            AccountIn.builder()\n                .email(email)\n                .password(password)\n                .build()\n        );\n        if (!response.hasBody()) {\n            logger.debug(String.format(\"user not found\"));\n            throw new ResponseStatusException(HttpStatus.UNAUTHORIZED);\n        }\n\n        AccountOut account = response.getBody();\n        logger.debug(String.format(\"found user\", account));\n\n        // generate token\n        return jwtService.generate(account, tokenDuration);\n    }\n\n    public AccountOut solve(String jwt) {\n        return AccountOut.builder()\n            .id(jwtService.getId(jwt))\n            .build();\n    }\n\n    public Long getTokenDuration() {\n        return tokenDuration;\n    }\n\n    public Boolean getTokenHTTPS() {\n        return tokenHTTPS;\n    }\n\n}\n</code></pre> <pre><code>package store.auth;\n\nimport java.util.Date;\nimport java.util.Map;\n\nimport javax.crypto.SecretKey;\n\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.stereotype.Service;\nimport org.springframework.web.server.ResponseStatusException;\n\nimport io.jsonwebtoken.Claims;\nimport io.jsonwebtoken.JwtParser;\nimport io.jsonwebtoken.Jwts;\nimport io.jsonwebtoken.io.Decoders;\nimport io.jsonwebtoken.security.Keys;\nimport store.account.AccountOut;\n\n@Service\npublic class JwtService {\n\n    @Value(\"${store.jwt.secretKey}\")\n    private String secretKey;\n\n    public String generate(AccountOut account, long duration) {\n\n        Date now = new Date();\n\n        String jwt = Jwts.builder()\n            .header()\n            .and()\n            .id(account.id())\n            .issuer(\"Insper::PMA\")\n            .claims(Map.of(\n                \"email\", account.email()\n            ))\n            .signWith(getKey())\n            .subject(account.name())\n            .notBefore(now)\n            .expiration(new Date(now.getTime() + duration)) // in miliseconds\n            .compact();\n        return jwt;\n\n    }\n\n    public String getId(String jwt) {\n        // constroe o parser\n        JwtParser parser = Jwts.parser().verifyWith(getKey()).build();\n        // recupero os atributos\n        Claims claims = parser.parseSignedClaims(jwt).getPayload();\n        Date now = new Date();\n        if (claims.getNotBefore().after(now)) {\n            throw new ResponseStatusException(\n                HttpStatus.UNAUTHORIZED,\n                \"Token is not valid yet!\"\n            );\n        }\n        if (claims.getExpiration().before(now)) {\n            throw new ResponseStatusException(\n                HttpStatus.UNAUTHORIZED,\n                \"Token is expired!\"\n            );\n        }\n        return claims.getId();\n    }\n\n    private SecretKey getKey() {\n        return Keys.hmacShaKeyFor(Decoders.BASE64.decode(secretKey));\n    }\n\n}\n</code></pre> <pre><code>FROM eclipse-temurin:25\nVOLUME /tmp\nCOPY target/*.jar /app.jar\nENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]\n</code></pre> Register <pre><code>POST /auth/register\n</code></pre> <p>Body </p><pre><code>{\n    \"name\": \"Antonio do Estudo\",\n    \"email\": \"acme@insper.edu.br\",\n    \"password\": \"123@321\"\n}\n</code></pre><p></p> <p>Sequence Diagram</p> <pre><code>sequenceDiagram\nautonumber\nactor User\nUser-&gt;&gt;+Auth: register (RegisterIn)\nAuth-&gt;&gt;+Account: create (AccountIn)\nAccount-&gt;&gt;-Auth: returns the new account (AccountOut)\nAuth-&gt;&gt;-User: returns 201 (TokenOut)</code></pre> Login <pre><code>POST /auth/login\n</code></pre> <p>Body </p><pre><code>{\n    \"email\": \"acme@bussiness.com\",\n    \"password\": \"123@321\"\n}\n</code></pre><p></p> <p>Sequence Diagram</p> <pre><code>sequenceDiagram\nautonumber\nactor User\nUser-&gt;&gt;+Auth: authenticate (LoginIn)\nAuth-&gt;&gt;+Account: findByEmailAndPassword\ncritical validated\n    Account-&gt;&gt;-Auth: returns the account\noption denied\n    Auth--&gt;&gt;User: unauthorized message\nend  \nAuth-&gt;&gt;Auth: generates a token\nAuth-&gt;&gt;-User: returns TokenOut\nUser-&gt;&gt;User: stores the token to use for the next requests</code></pre>"},{"location":"hands-on/3/#security","title":"Security","text":"<p>Security is an important aspect of software development. It involves protecting the confidentiality, integrity, and availability of data and resources. Two key concepts in security are authentication and authorization.</p>"},{"location":"hands-on/3/#authentication","title":"Authentication","text":"<p>Authentication is the process of verifying the identity of a user or system. It ensures that the user or system is who they claim to be. Common authentication methods include passwords, biometrics, and two-factor authentication. The system checks these credentials against the stored data. If the credentials are valid, the system confirms the user's identity.</p> <p>In many systems, after successful authentication, the system generates a token. This token is a piece of data that represents the user's authentication session. It's like a digital ticket that proves the user's identity for a certain period of time.</p> <p>This token is then sent back to the user. The user's client software (like a web browser) stores this token and sends it along with every subsequent request to the server (in case of stateless server). This way, the server knows that the request comes from an authenticated user without needing to ask for the credentials again.</p> <p>Here's a simplified step-by-step process:</p> <pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;+Auth Service: authentication(credentials)\n  Auth Service-&gt;&gt;Auth Service: verifies credenditals and generates a token\n  Auth Service-&gt;&gt;-User: returns the token\n  User-&gt;&gt;User: stores the token to use for the next requests</code></pre> <ol> <li>The user sends their username and password (or other credentials) to the server;</li> <li>The server verifies the credentials. If they're valid, the server generates a token.</li> <li>The server sends this token back to the user.</li> <li>The user's client software stores this token.</li> <li>For every subsequent request, the client sends this token along with the request.</li> <li>The server checks the token to ensure it's valid and hasn't expired.</li> <li>This token-based authentication process is commonly used in many modern web applications and APIs. It helps maintain the user's session and allows the server to authenticate requests without storing the user's state.</li> </ol>"},{"location":"hands-on/3/#authorization","title":"Authorization","text":"<p>Authorization is the process of granting or denying access to specific resources or actions based on the authenticated user's privileges. It determines what a user is allowed to do within a system. Authorization can be role-based, where permissions are assigned based on predefined roles, or attribute-based, where permissions are based on specific attributes of the user.</p> <p>In many systems, the token not only represents the user's identity, but also includes information about their permissions or roles. This is often done using a type of token called a JSON Web Token (JWT), which can include a payload of data.</p> <p>Here's a simplified step-by-step process:</p> <pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre> <ol> <li>After authentication, the user's client software sends a request to a server. This request includes the token.</li> <li>The server decodes the token and extracts the user's identity and permissions.</li> <li>The server checks whether the user has the necessary permissions for the requested action. This could involve checking the user's roles or other attributes against the requirements for the action.</li> <li>If the user has the necessary permissions, the server allows the action. If not, the server denies the action.</li> </ol> <p>This process allows the server to authorize actions without needing to repeatedly look up the user's permissions. It also allows for stateless servers, as the necessary information is included in every request.</p> <p>By implementing strong authentication and authorization mechanisms, software systems can ensure that only authorized users have access to sensitive data and functionalities, reducing the risk of unauthorized access and potential security breaches.</p> <p>As the platform has only one entrace point, it is</p> <p>JWT is a decentralized </p> <p>The point of entrance of API is the gateway, then as suggested by <sup>8</sup>.</p> <p>The gateway is responsible for the security of the system. It is the first point of contact for all incoming requests. The gateway is responsible for routing requests to the appropriate services and ensuring that only authorized users can access the system.</p> <pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Gateway: route(ServerHttpRequest)\n  Gateway-&gt;&gt;+AuthorizationFilter: filter(ServerWebExchange, GatewayFilterChain)\n  AuthorizationFilter-&gt;&gt;RouteValidator: isSecured.test(ServerHttpRequest)\n  RouteValidator--&gt;&gt;AuthorizationFilter: True | False\n  critical notSecured\n    AuthorizationFilter-&gt;&gt;Gateway: follow the flux\n  end\n  AuthorizationFilter-&gt;&gt;AuthorizationFilter: isAuthMissing(ServerHttpRequest)\n  critical isAuthMissing\n    AuthorizationFilter-&gt;&gt;User: unauthorized message\n  end\n  AuthorizationFilter-&gt;&gt;AuthorizationFilter: validateAuthorizationHeader()\n  critical isInvalidAuthorizationHeader\n    AuthorizationFilter-&gt;&gt;User: unauthorized message\n  end\n  AuthorizationFilter-&gt;&gt;Auth: solve(Token)\n  critical isInvalidToken\n    Auth-&gt;&gt;User: unauthorized message\n  end\n  Auth-&gt;&gt;AuthorizationFilter: returns SolveOut\n  AuthorizationFilter-&gt;&gt;AuthorizationFilter: updateRequestHeader(ServerHttpRequest)\n  AuthorizationFilter-&gt;&gt;Gateway: follow the flux</code></pre>"},{"location":"hands-on/3/#gateway-service","title":"Gateway-Service","text":"<pre><code>\ud83d\udcc1 api\n\u2514\u2500\u2500 \ud83d\udcc1 gateway-service\n    \u251c\u2500\u2500 \ud83d\udcc1 src\n    \u2502   \u2514\u2500\u2500 \ud83d\udcc1 main\n    \u2502       \u251c\u2500\u2500 \ud83d\udcc1 java\n    \u2502       \u2502   \u2514\u2500\u2500 \ud83d\udcc1 store\n    \u2502       \u2502       \u2514\u2500\u2500 \ud83d\udcc1 gateway\n    \u2502       \u2502           \u251c\u2500\u2500  GatewayApplication.java\n    \u2502       \u2502           \u251c\u2500\u2500  GatewayResource.java\n    \u2502       \u2502           \u2514\u2500\u2500 \ud83d\udcc1 security\n    \u2502       \u2502               \u251c\u2500\u2500  AuthorizationFilter.java\n    \u2502       \u2502               \u251c\u2500\u2500  CorsFilter.java\n    \u2502       \u2502               \u2514\u2500\u2500  RouterValidator.java\n    \u2502       \u2514\u2500\u2500 \ud83d\udcc1 resources\n    \u2502           \u2514\u2500\u2500  application.yaml\n    \u251c\u2500\u2500  pom.xml\n    \u2514\u2500\u2500  Dockerfile\n</code></pre> Source pom.xmlapplication.yamlGatewayApplication.javaGatewayResource.javaAuthorizationFilter.javaCorsFilter.javaRouterValidator.javaDockerfile <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;parent&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n        &lt;version&gt;4.0.1&lt;/version&gt;\n        &lt;relativePath/&gt;\n    &lt;/parent&gt;\n\n    &lt;groupId&gt;store&lt;/groupId&gt;\n    &lt;artifactId&gt;gateway-service&lt;/artifactId&gt;\n    &lt;version&gt;1.0.0&lt;/version&gt;\n\n    &lt;properties&gt;\n        &lt;java.version&gt;25&lt;/java.version&gt;\n        &lt;spring-cloud.version&gt;2025.1.0&lt;/spring-cloud.version&gt;\n        &lt;maven.compiler.proc&gt;full&lt;/maven.compiler.proc&gt;\n    &lt;/properties&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-gateway-server-webflux&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n        &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n\n    &lt;/dependencies&gt;\n\n    &lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;excludes&gt;\n                        &lt;exclude&gt;\n                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n                        &lt;/exclude&gt;\n                    &lt;/excludes&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;${java.version}&lt;/source&gt;\n                    &lt;target&gt;${java.version}&lt;/target&gt;\n                    &lt;release&gt;${java.version}&lt;/release&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n&lt;/project&gt;\n</code></pre> <pre><code>server:\n  port: 8080\n\nspring:\n\n  application:\n    name: gateway\n\n  mvc:\n    problemdetails:\n      enabled: true\n\n  cloud:\n    gateway:\n      server:\n        webflux:\n          routes:\n\n            - id: insper\n              uri: https://www.insper.edu.br\n              predicates:\n                - Path=/insper/**\n\n            - id: account\n              uri: http://account:8080\n              predicates:\n                - Path=/account/**\n\n            - id: auth\n              uri: http://auth:8080\n              predicates:\n                - Path=/auth/**\n\n          globalcors:\n            corsConfigurations:\n              '[/**]':\n                allowedOrigins: ${CORS_ALLOWED_ORIGINS}\n                allowedHeaders: \"*\"\n                allowedMethods: \"*\"\n                allowCredentials: ${CORS_ALLOW_CREDENTIALS:true}\n\nlogging:\n  level:\n    root: info\n    store: debug\n</code></pre> <pre><code>package store.gateway;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class GatewayApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(GatewayApplication.class, args);\n    }\n\n}\n</code></pre> <pre><code>package store.gateway;\n\nimport java.net.InetAddress;\nimport java.util.Map;\n\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class GatewayResource {\n\n    @GetMapping(\"/health-check\")\n    public ResponseEntity&lt;Map&lt;String, String&gt;&gt; healthCheck() {\n        String ip = \"\";\n        try {\n            ip = InetAddress.getLocalHost().getHostAddress();\n        } catch (Exception e) {\n            ip = e.getMessage();\n        }\n        return ResponseEntity.ok()\n            .body(Map.of(\n                \"osArch\", System.getProperty(\"os.arch\"),\n                \"osName\", System.getProperty(\"os.name\"),\n                \"osVersision\", System.getProperty(\"os.version\"),\n                \"hostAddress\", ip\n            ));\n    }\n\n    @GetMapping(\"/\")\n    public ResponseEntity&lt;String&gt; hello() {\n        return ResponseEntity.ok()\n            .body(\"API by In5p3R\");\n    }\n\n}\n</code></pre> <pre><code>package store.gateway.security;\n\nimport java.util.Map;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.cloud.gateway.filter.GatewayFilterChain;\nimport org.springframework.cloud.gateway.filter.GlobalFilter;\nimport org.springframework.http.HttpHeaders;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.http.MediaType;\nimport org.springframework.http.server.reactive.ServerHttpRequest;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.reactive.function.client.WebClient;\nimport org.springframework.web.server.ResponseStatusException;\nimport org.springframework.web.server.ServerWebExchange;\n\nimport reactor.core.publisher.Mono;\n\n@Component\npublic class AuthorizationFilter implements GlobalFilter {\n\n    private Logger logger = LoggerFactory.getLogger(AuthorizationFilter.class);\n    private static final String AUTH_COOKIE_TOKEN = \"__store_jwt_token\";\n    private static final String AUTH_SERVICE_TOKEN_SOLVE = \"http://auth:8080/auth/solve\";\n\n    @Autowired\n    private RouterValidator routerValidator;\n\n    @Override\n    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {\n        logger.debug(\"filter: entrou no filtro de autorizacao\");\n        ServerHttpRequest request = exchange.getRequest();\n\n        if (!routerValidator.isSecured.test(request)) {\n            logger.debug(\"filter: rota nao eh segura\");\n            return chain.filter(exchange);\n        }\n        logger.debug(\"filter: rota eh segura\");\n\n        if (request.getCookies().containsKey(AUTH_COOKIE_TOKEN)) {\n            logger.debug(\"filter: tem [\" + AUTH_COOKIE_TOKEN + \"] no cookie\");\n            String token = request.getCookies().getFirst(AUTH_COOKIE_TOKEN).getValue();\n            logger.debug(String.format(\n                \"filter: [Token]=[%s]\",\n                token\n            ));\n            if (null != token &amp;&amp; token.length() &gt; 0) {\n                return requestAuthTokenSolve(exchange, chain, token);\n            }\n        }\n        logger.debug(\"filter: access is denied!\");\n        // when access is denied\n        throw new ResponseStatusException(HttpStatus.UNAUTHORIZED);\n    }\n\n    // este metodo eh responsavel por enviar o token ao Auth Microservice\n    // a fim de interpretar o token, a chamada eh feita via Rest.\n    private Mono&lt;Void&gt; requestAuthTokenSolve(ServerWebExchange exchange, GatewayFilterChain chain, String jwt) {\n        logger.debug(\"solve: solving jwt: \" + jwt);\n        return WebClient.builder()\n            .defaultHeader(\n                HttpHeaders.CONTENT_TYPE, MediaType.APPLICATION_JSON_VALUE\n            )\n            .build()\n            .post()\n            .uri(AUTH_SERVICE_TOKEN_SOLVE)\n            .bodyValue(Map.of(\n                \"jwt\", jwt)\n            )\n            .retrieve()\n            .toEntity(Map.class)\n            .flatMap(response -&gt; {\n                if (response != null &amp;&amp; response.hasBody() &amp;&amp; response.getBody() != null) {\n                    final Map&lt;String, String&gt; map = response.getBody();\n                    String idAccount = map.get(\"idAccount\");\n                    logger.debug(\"solve: id account: \" + idAccount);\n                    ServerWebExchange authorizated = updateRequest(exchange, idAccount);\n                    return chain.filter(authorizated);\n                } else {\n                    throw new ResponseStatusException(HttpStatus.UNAUTHORIZED, \"Invalid token\");\n                }\n            });\n    }\n\n    private ServerWebExchange updateRequest(ServerWebExchange exchange, String idAccount) {\n        logger.debug(\"original headers: \" + exchange.getRequest().getHeaders().toString());\n        ServerWebExchange modified = exchange.mutate()\n            .request(\n                exchange.getRequest()\n                    .mutate()\n                    .header(\"id-account\", idAccount)\n                    .build()\n            ).build();\n        logger.debug(\"updated headers: \" + modified.getRequest().getHeaders().toString());\n        return modified;\n    }    \n\n}\n</code></pre> <pre><code>\n</code></pre> <pre><code>package store.gateway.security;\n\nimport java.util.List;\nimport java.util.function.Predicate;\n\nimport org.springframework.http.server.reactive.ServerHttpRequest;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class RouterValidator {\n\n        private List&lt;String&gt; openApiEndpoints = List.of(\n                \"POST /auth/register\",\n                \"POST /auth/login\"\n        );\n\n        public Predicate&lt;ServerHttpRequest&gt; isSecured =\n                request -&gt; openApiEndpoints\n                        .stream()\n                        .noneMatch(uri -&gt; {\n                                String[] parts = uri.replaceAll(\"[^a-zA-Z0-9// *]\", \"\").split(\" \");\n                                final String method = parts[0];\n                                final String path = parts[1];\n                                final boolean deep = path.endsWith(\"/**\");\n                                return (\"ANY\".equalsIgnoreCase(method) || request.getMethod().toString().equalsIgnoreCase(method))\n                                        &amp;&amp; (request.getURI().getPath().equals(path) || (deep &amp;&amp; request.getURI().getPath().startsWith(path.replace(\"/**\", \"\"))));\n                        });\n\n}\n</code></pre> <pre><code>FROM eclipse-temurin:25\nVOLUME /tmp\nCOPY target/*.jar /app.jar\nENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]\n</code></pre>"},{"location":"hands-on/3/#jwt-json-web-token","title":"JWT - JSON Web Token","text":"<p>JWT stands for JSON Web Token. It is a compact, URL-safe means of representing claims between two parties. JWTs are commonly used to secure the transmission of information between parties in a web environment, typically for authentication and information exchange. The JWT specification is defined by RFC 7519<sup>1</sup> and it is a decentralized approach for security (which can support horizontal scalability).</p> <p>Here are the key components and concepts of JWT:</p> <ul> <li>JSON Format: JWTs are represented as JSON objects that are easy to parse and generate. The JSON format makes them human-readable and easy to work with.</li> <li> <p>Three Parts: JWTs consist of three parts separated by dots (<code>.</code>): Header, Payload, and Signature.</p> <ul> <li> <p>Header: The header typically consists of two parts: the type of the token (JWT) and the signing algorithm being used, such as HMAC SHA256 or RSA.</p> </li> <li> <p>Payload: The payload contains the claims. Claims are statements about an entity (typically, the user) and additional data. There are three types of claims: registered, public, and private claims.</p> </li> <li> <p>Signature: To create the signature part, you take the encoded header, the encoded payload, a secret, the algorithm specified in the header, and sign that.</p> </li> </ul> </li> <li> <p>Encoding: Each of the three parts is Base64Url encoded, and the resulting strings are concatenated with periods between them. The final JWT looks like: <code>xxxxx.yyyyy.zzzzz</code>.</p> </li> <li>Stateless and Self-contained: JWTs are stateless, meaning that all the information needed is within the token itself. The server doesn't need to store the user's state. They are also self-contained, meaning that all the information needed is contained within the token.</li> <li>Use Cases: JWTs are commonly used for authentication and information exchange between parties. For example, after a user logs in, a server could generate a JWT and send it to the client. The client can then include the JWT in the headers of subsequent requests to access protected resources. The server can verify the authenticity of the JWT using the stored secret key.</li> <li>Security Considerations: While JWTs are widely used and versatile, it's important to handle them securely. For instance, the key used to sign the JWT should be kept secret, and HTTPS should be used to transmit JWTs to prevent man-in-the-middle attacks.</li> </ul> <p>Here's a simple example of a JWT created on JWT Builder<sup>2</sup>:</p> <p><code>eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9.eyJpc3MiOiJJbnNwZXIiLCJpYXQiOjE3MDMwMDgzMzgsImV4cCI6MjAxODU0MTEzOCwiYXVkIjoid3d3Lmluc3Blci5lZHUuYnIiLCJzdWIiOiJodW1iZXJ0b3JzQGluc3Blci5lZHUuYnIiLCJHaXZlbk5hbWUiOiJIdW1iZXJ0byIsIlN1cm5hbWUiOiJTYW5kbWFubiIsIkVtYWlsIjoiaHVtYmVydG9yc0BpbnNwZXIuZWR1LmJyIiwiUm9sZSI6IlByb2Zlc3NvciJ9.SsGdvR5GbYWTRbxY7IGxHt1vSxhkpRueBJWsi0lrPhJVCICp119QjU8F3QvHW0yF5tw-HhQ9RVh0l89t4M0LNw</code></p> <p>This JWT consists of three parts, decoded by <sup>3</sup>:</p> HeaderPayloadSignature <p><code>eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9</code></p> <pre><code>{\n  \"typ\": \"JWT\",\n  \"alg\": \"HS512\"\n}\n</code></pre> <p><code>eyJpc3MiOiJJbnNwZXIiLCJpYXQiOjE3MDMwMDgzMzgsImV4cCI6MjAxODU0MTEzOCwiYXVkIjoid3d3Lmluc3Blci5lZHUuYnIiLCJzdWIiOiJodW1iZXJ0b3JzQGluc3Blci5lZHUuYnIiLCJHaXZlbk5hbWUiOiJIdW1iZXJ0byIsIlN1cm5hbWUiOiJTYW5kbWFubiIsIkVtYWlsIjoiaHVtYmVydG9yc0BpbnNwZXIuZWR1LmJyIiwiUm9sZSI6IlByb2Zlc3NvciJ9</code></p> <pre><code>{\n  \"iss\": \"Insper\",\n  \"iat\": 1703008338,\n  \"exp\": 2018541138,\n  \"aud\": \"www.insper.edu.br\",\n  \"sub\": \"humbertors@insper.edu.br\",\n  \"GivenName\": \"Humberto\",\n  \"Surname\": \"Sandmann\",\n  \"Email\": \"humbertors@insper.edu.br\",\n  \"Role\": \"Professor\"\n}\n</code></pre> <p><code>SsGdvR5GbYWTRbxY7IGxHt1vSxhkpRueBJWsi0lrPhJVCICp119QjU8F3QvHW0yF5tw-HhQ9RVh0l89t4M0LNw</code></p> <pre><code>HMACSHA512(\n  base64UrlEncode(header) + \".\" +\n  base64UrlEncode(payload),\n  qwertyuiopasdfghjklzxcvbnm123456,\n)\n</code></pre> <p>JWTs are widely used in web development due to their simplicity, flexibility, and support across various programming languages and frameworks. They are commonly used in token-based authentication systems.</p>"},{"location":"hands-on/3/#addtional-material","title":"Addtional Material","text":"<ul> <li> <p>JSON Web Token</p> </li> <li> <p> Autentica\u00e7\u00e3o e Autoriza\u00e7\u00e3o com Spring Security e JWT Tokens by Fernanda Kipper</p> <p></p> </li> <li> <p>Spring Cloud Security</p> </li> <li> <p> ByeteByteGo - Why is JWT popular?</p> <p></p> </li> </ul> <ol> <li> <p>RFC 7519 - JSON Web Token (JWT), 2015.\u00a0\u21a9</p> </li> <li> <p>JWT - Builder.\u00a0\u21a9</p> </li> <li> <p>jwt.io - JWT Verification.\u00a0\u21a9</p> </li> <li> <p>Unix Time Stamp - Epoch Converter.\u00a0\u21a9</p> </li> <li> <p>DELANTHA, R., Spring Cloud Gateway security with JWT, 2023.\u00a0\u21a9</p> </li> <li> <p>Wikipedia - Pepper (cryptography).\u00a0\u21a9</p> </li> <li> <p>PGzlan, Serve your hash with Salt and Pepper for Stronger Account Security, 2023.\u00a0\u21a9</p> </li> <li> <p>DELANTHA, R., Spring Cloud Gateway security with JWT, 2023.\u00a0\u21a9</p> </li> </ol>"},{"location":"hands-on/4/","title":"Index","text":"<p>Jenkis is a continuous integration and continuous delivery (CI/CD) tool that automates the process of building, testing, and deploying software. It is widely used in DevOps practices to streamline the software development lifecycle.</p>"},{"location":"hands-on/4/#containerized-jenkins","title":"Containerized Jenkins","text":"<p>In this checkpoint, we will set up a Jenkins server using Docker Compose. This will allow us to run Jenkins in a containerized environment, making it easy to manage and deploy.</p> <pre><code>\ud83d\udcc1 api/\n\ud83d\udcc1 jenkins/\n\u2514\u2500\u2500  compose.yaml\n</code></pre> Source compose.yaml <pre><code>\n</code></pre> <p>To run this container:</p> <pre><code>docker compose up -d --build\n</code></pre> <pre><code>jenkins/# docker compose up -d --build\n\n[+] Running 2/2\n \u2714 jenkins Created              0.1s \n \u2714 Container jenkins Started    0.2s \n</code></pre> <p>Jenkins is now running on port 9080. You can access it by navigating to http://localhost:9080/ in your web browser.</p>"},{"location":"hands-on/4/#jenkins-configuration","title":"Jenkins Configuration","text":"<p>Once Jenkins is running, you will need to configure it. The first time you access Jenkins, you will be prompted to unlock it using an initial admin password.</p> <p>Admin</p> <p>Please, to avoid permission issues, run the console as administrator.</p> <p>Setting the a number of executors to 10 will allow us to run two jobs in parallel. This is useful for speeding up the build process, especially when we have multiple projects or stages that can be executed concurrently.</p> <p></p>"},{"location":"hands-on/4/#pipeline","title":"Pipeline","text":"<p>In this checkpoint, we will create a Jenkins pipeline that will build and deploy our application, Pipeline as Code. The pipeline will be defined in a <code>Jenkinsfile</code> located in the root of our project.</p> <p></p> <pre><code>\ud83d\udcc1 api/\n\u2514\u2500\u2500 \ud83d\udcc1 account/\n    \u2514\u2500\u2500  Jenkinsfile\n</code></pre> Source Jenkinsfile <pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                sh 'mvn -B -DskipTests clean install'\n            }\n        }\n    }\n\n}\n</code></pre> <p>The <code>Jenkinsfile</code> defines the stages of our pipeline, including building the application, running tests, and deploying the application - Pipeline as Code. Each stage can be customized to fit the needs of your project. The pipeline can be triggered manually or automatically based on events such as code commits or pull requests. This allows for continuous integration and continuous delivery (CI/CD) of our application.</p> <p>eg.: Pipeline for account-service:</p> <pre><code>\ud83d\udcc1 api/\n\u2514\u2500\u2500 \ud83d\udcc1 account-service/\n    \u2514\u2500\u2500  Jenkinsfile\n</code></pre> Jenkinsfile<pre><code>pipeline {\n    agent any\n    environment {\n        SERVICE = 'account'\n        NAME = \"humbertosandmann/${env.SERVICE}\"\n    }\n    stages {\n        stage('Dependecies') {\n            steps {\n                build job: 'account', wait: true\n            }\n        }\n        stage('Build') { \n            steps {\n                sh 'mvn -B -DskipTests clean package'\n            }\n        }      \n        stage('Build &amp; Push Image') {\n            steps {\n                withCredentials([usernamePassword(\n                    credentialsId: 'dockerhub-credential',\n                    usernameVariable: 'USERNAME',\n                    passwordVariable: 'TOKEN')])\n                {\n                    sh \"docker login -u $USERNAME -p $TOKEN\"\n                    sh \"docker buildx create --use --platform=linux/arm64,linux/amd64 --node multi-platform-builder-${env.SERVICE} --name multi-platform-builder-${env.SERVICE}\"\n                    sh \"docker buildx build --platform=linux/arm64,linux/amd64 --push --tag ${env.NAME}:latest --tag ${env.NAME}:${env.BUILD_ID} -f Dockerfile .\"\n                    sh \"docker buildx rm --force multi-platform-builder-${env.SERVICE}\"\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>The pipeline is defined in a declarative syntax, which makes it easy to read and understand. Each stage can contain multiple steps, which are the individual tasks that need to be performed:</p> <ol> <li> <p>The <code>environment</code> block defines environment variables that can be used throughout the pipeline. In this case, we define the <code>SERVICE</code> and <code>NAME</code> variables, which are used in the <code>Build &amp; Push Image</code> stage.</p> </li> <li> <p>The <code>Build &amp; Push Image</code> stage uses the <code>withCredentials</code> block to securely access Docker Hub credentials stored in Jenkins. The <code>docker login</code> command authenticates with Docker Hub, and the <code>docker buildx build</code> command builds and pushes the Docker image to the specified tags. The <code>docker buildx</code> command is used to build multi-platform images, allowing us to create images that can run on different architectures (e.g., ARM and AMD64). The <code>--platform</code> flag specifies the target platforms, and the <code>--push</code> flag pushes the built image to Docker Hub.</p> </li> <li> <p>The <code>docker buildx create</code> command creates a new buildx builder instance, which is used to build multi-platform images. The <code>--use</code> flag sets this builder as the default for the current shell session. The <code>--node</code> flag specifies the name of the builder node, which is used to identify the builder instance.</p> </li> <li> <p>The <code>docker buildx rm</code> command removes the builder instance after the build is complete, freeing up resources.</p> </li> </ol> <p>The pipeline can be triggered manually or automatically based on events such as code commits or pull requests. This allows for continuous integration and continuous delivery (CI/CD) of our application.</p> <p>For setting up the credentials, you can use the Jenkins UI to create a new credential of type \"Username with password\". The <code>credentialsId</code> used in the pipeline should match the ID of the credential you created.</p> <p></p> <p>Also, Jenkins could deploy the application to a Docker Compose environment. This can be done by adding a new stage to the pipeline that uses the <code>docker compose</code> command to deploy the application.</p> <ol> <li> <p>Jenkins - Jenkins documentation.\u00a0\u21a9</p> </li> </ol>"},{"location":"hands-on/5/","title":"Index","text":""},{"location":"hands-on/5/#what-is-an-orchestrator","title":"What is an Orchestrator?","text":"<p>An orchestrator is a system that automates the deployment, management, scaling, and operation of containerized applications. Containers package an application with its dependencies, making it portable across environments. Orchestrators handle critical tasks such as:</p> <ul> <li>Scheduling: Placing containers on appropriate servers.</li> <li>Scaling: Adding or removing containers based on demand.</li> <li>Networking: Managing communication between containers.</li> <li>Self-healing: Restarting failed containers or redistributing workloads.</li> <li>Service discovery: Enabling containers to find and communicate with each other.</li> </ul> <p>By abstracting infrastructure complexities, orchestrators ensure applications run reliably and efficiently, especially in large-scale, distributed systems. They are essential for enterprises managing hundreds or thousands of containers across multiple hosts, supporting cloud-native development and microservices architectures Container Orchestration - Red Hat.</p> <p>Orchestrators like Kubernetes, Docker Swarm, and Apache Mesos provide these capabilities, each with unique features and complexities. Kubernetes is the most widely adopted orchestrator, known for its robust ecosystem and community support.</p>"},{"location":"hands-on/5/#difference-between-docker-compose-and-kubernetes","title":"Difference Between Docker Compose and Kubernetes","text":"<p>Docker Compose and Kubernetes (K8s) both manage containerized applications but serve different purposes, with distinct scopes, complexities, and use cases:</p>"},{"location":"hands-on/5/#docker-compose","title":"Docker Compose","text":"<ul> <li>Purpose: Designed for single-host environments, ideal for development, testing, or small-scale production.</li> <li>Configuration: Uses a YAML file to define multi-container applications, specifying services, networks, and volumes.</li> <li>Features: Simplifies container networking and dependency management on one machine. Supports basic restart policies but lacks advanced features like auto-scaling or cluster management.</li> <li>Ease of Use: Simple to set up with a lower learning curve, making it accessible for developers.</li> <li>Use Case: Best for local development (e.g., running a web app with a database) or simple production setups where scalability isn\u2019t a priority.</li> </ul>"},{"location":"hands-on/5/#kubernetes","title":"Kubernetes","text":"<ul> <li>Purpose: Built for orchestrating containers across a cluster of multiple nodes, suited for production-grade, distributed systems.</li> <li>Configuration: Uses declarative YAML/JSON files to define desired states, with controllers ensuring the system matches the configuration.</li> <li>Features: Offers auto-scaling, load balancing, rolling updates, self-healing, service discovery, and storage orchestration.</li> <li>Complexity: More complex, requiring knowledge of concepts like pods, services, and deployments.</li> <li>Use Case: Ideal for cloud-native applications needing high availability, scalability, and resilience across multiple servers.</li> </ul>"},{"location":"hands-on/5/#key-differences","title":"Key Differences","text":"Aspect Docker Compose Kubernetes Scope Single-host Multi-host, cluster-based Scalability No auto-scaling Dynamic auto-scaling Complexity Simple, low learning curve Complex, steeper learning curve Use Case Local dev, testing, small prod Large-scale, production systems <p>Tools like Kompose can help migrate Docker Compose files to Kubernetes, easing the transition for growing applications Docker Compose vs Kubernetes - Spacelift.</p>"},{"location":"hands-on/5/#alternatives-to-kubernetes","title":"Alternatives to Kubernetes","text":"<p>Kubernetes is the leading container orchestration platform, but its complexity and resource demands may not suit every scenario. Alternatives exist for different environments\u2014on-premise, cloud, and local\u2014offering simpler, cloud-specific, or lightweight solutions. Below is a table summarizing popular alternatives with examples:</p> Environment Alternative Description Examples On-Premise Nomad A lightweight orchestrator by HashiCorp, supporting containers and non-containerized workloads. Easier to set up than Kubernetes, ideal for smaller teams. Deploying Nomad on bare-metal servers in a data center for a microservices application. Apache Mesos An open-source distributed systems kernel for container orchestration, suitable for large-scale, custom workloads. Running Mesos on on-premise infrastructure to manage a big data processing pipeline. OpenShift A Kubernetes-based platform by Red Hat with added developer and enterprise tools, supporting hybrid cloud setups. Installing OpenShift on enterprise hardware for a hybrid cloud e-commerce platform. Cloud Amazon ECS AWS\u2019s managed container orchestration service, tightly integrated with AWS services like EC2 and Fargate. Using ECS on AWS to deploy a web application with auto-scaling on EC2 instances. Google Cloud Run A serverless platform for running stateless containers, abstracting infrastructure management. Deploying a REST API on Google Cloud with automatic scaling for traffic spikes. AWS Fargate Serverless compute for containers, compatible with ECS and EKS, eliminating server management. Running a containerized analytics service on AWS without managing servers. Azure Container Instances Microsoft Azure\u2019s serverless container service for simple, isolated container deployments. Deploying a batch processing job on Azure without managing infrastructure. Google Kubernetes Engine (GKE) Managed Kubernetes service by Google Cloud, simplifying cluster management. Running a machine learning workload on Google Cloud with GKE\u2019s managed control plane. Amazon EKS Managed Kubernetes service by AWS, integrating with AWS ecosystem. Deploying a scalable web app on AWS using EKS with managed control plane. Local Docker Compose A tool for defining and running multi-container applications on a single machine, ideal for development. Running a local dev environment with a web app, database, and cache using Docker Compose. Minikube A tool to run a single-node Kubernetes cluster locally for development and testing. Testing Kubernetes deployments on a developer\u2019s laptop with Minikube. Docker Swarm Docker\u2019s native orchestration tool, simpler than Kubernetes, for managing containers across multiple hosts. Setting up a small local cluster for testing a containerized app with Docker Swarm. Kind A tool for running Kubernetes clusters in Docker containers, useful for testing Kubernetes itself. Running a local Kubernetes cluster for testing and development with Kind. Rancher Desktop A desktop application for managing Kubernetes clusters, providing a user-friendly interface. Managing local Kubernetes clusters with Rancher Desktop for development. MicroK8s A lightweight, single-package Kubernetes distribution for local development. Running a local Kubernetes cluster with MicroK8s for testing and development. k3s A lightweight Kubernetes distribution designed for resource-constrained environments. Running a small-scale Kubernetes cluster on IoT devices or edge computing."},{"location":"hands-on/5/#notes-on-alternatives","title":"Notes on Alternatives","text":"<ul> <li>Nomad and Docker Swarm prioritize simplicity, making them suitable for teams with limited resources or simpler workloads Kubernetes Alternatives - Wiz.</li> <li>OpenShift enhances Kubernetes with enterprise features but increases complexity, best for organizations needing robust tooling.</li> <li>Cloud-native options like Amazon ECS, Google Cloud Run, and AWS Fargate reduce management overhead but tie users to specific cloud providers, limiting portability.</li> <li>Local tools like Minikube and Docker Compose are not production-ready but excel in development and learning environments.</li> <li>Managed Kubernetes services (GKE, EKS) simplify Kubernetes operations but still require Kubernetes expertise, making them less of a true alternative for those avoiding K8s complexity.</li> </ul> <p>Choosing the right tool depends on factors like workload scale, team expertise, infrastructure constraints, and whether portability across clouds is needed. For small projects, Docker Compose or Nomad may suffice, while large, distributed systems often benefit from Kubernetes or cloud-native solutions like ECS.</p>"},{"location":"hands-on/5/#kubernetes_1","title":"Kubernetes","text":"<p>Kubernetes is an open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications. It provides a robust framework for running distributed systems resiliently, allowing you to manage clusters of hosts running Linux containers. A <code>cluster</code> is a set of machines (physical or virtual) that run Kubernetes and can be managed as a single entity. To manage these clusters, Kubernetes uses a set of APIs and a control plane to manage the state of the cluster.</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre> <ul> <li> <p>Deployment: This is like the manager for your application, deciding how many copies (replicas) should run and updating them when needed.</p> </li> <li> <p>ReplicaSet: It ensures the right number of Pods (the actual running containers) are always available, creating or deleting them as necessary.</p> </li> <li> <p>Pod: The smallest unit, where your application actually runs, often containing one or more containers.</p> </li> <li> <p>Container: The actual application running inside the Pod, isolated from others.</p> </li> <li> <p>Service: This is like a load balancer, directing traffic to the right Pods based on rules you set. A Service allows you to expose your application to the outside world or to other applications within the cluster. The exposed service can be of different types:</p> Types of Services Description ClusterIP The default type, which exposes the service on a cluster-internal IP. This means that the service is only reachable from within the cluster. NodePort Exposes the service on each node's IP at a static port. This allows you to access the service from outside the cluster using <code>&lt;NodeIP&gt;:&lt;NodePort&gt;</code>. LoadBalancer Creates an external load balancer in supported cloud providers, routing traffic to your service. </li> <li> <p>ConfigMap: A way to pass configuration data to your application without hardcoding it into the container.</p> </li> <li> <p>Secret: Similar to ConfigMap, but used for sensitive information like passwords or API keys, ensuring they are stored securely.</p> </li> </ul> <p>Example on the Postgres Service</p> <pre><code>\ud83d\udcc1 postgres-service\n\u2514\u2500\u2500 \ud83d\udcc1 k8s\n    \u251c\u2500\u2500  secrets.yaml\n    \u251c\u2500\u2500  configmap.yaml\n    \u251c\u2500\u2500  deployment.yaml\n    \u2514\u2500\u2500  service.yaml\n</code></pre> secrets.yamlconfigmap.yamldeployment.yamlservice.yaml <pre><code>\n</code></pre> <pre><code>kubectl apply -f ./k8s/secrets.yaml\nkubectl get secrets\n</code></pre> <pre><code>\n</code></pre> <pre><code>kubectl apply -f ./k8s/configmap.yaml\nkubectl get configmap\n</code></pre> <pre><code>\n</code></pre> <pre><code>kubectl apply -f ./k8s/deployment.yaml\nkubectl get deployments\nkubectl get pods\n</code></pre> <pre><code>\n</code></pre> <pre><code>kubectl apply -f ./k8s/service.yaml\nkubectl get services\n</code></pre> <p>Example on the Gateway Service</p> <pre><code>\ud83d\udcc1 gateway-service\n\u2514\u2500\u2500 \ud83d\udcc1 k8s\n    \u2514\u2500\u2500  k8s.yaml\n</code></pre> k8s.yaml <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gateway\n  template:\n    metadata:\n      labels:\n        app: gateway\n    spec:\n      containers:\n        - name: db\n          image: humbertosandmann/gateway:latest\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8080\n          resources:\n            requests:\n              memory: \"200Mi\"\n              cpu: \"50m\"\n            limits:\n              memory: \"300Mi\"\n              cpu: \"200m\"\n\n---\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: gateway\n  labels:\n    app: gateway\nspec:\n  type: LoadBalancer\n  ports:\n    - port: 80\n      protocol: TCP\n      targetPort: 8080\n\n  selector:\n    app: gateway\n</code></pre> <pre><code>kubectl apply -f ./k8s/k8s.yaml\nkubectl get deployments\nkubectl get pods\nkubectl get services\n</code></pre> <pre><code>NAME         TYPE           CLUSTER-IP     EXTERNAL-IP                                                              PORT(S)        AGE\ngateway      LoadBalancer   10.100.59.61   aac9dbab7421e4ec0a1b19472728b793-834724138.us-east-2.elb.amazonaws.com   80:31973/TCP   34m\nkubernetes   ClusterIP      10.100.0.1     &lt;none&gt;                                                                   443/TCP        5d5h\n</code></pre> <p>In a browser, you can access the gateway service using the external IP address:</p> <pre><code>http://aac9dbab7421e4ec0a1b19472728b793-834724138.us-east-2.elb.amazonaws.com/info # (1)!\n</code></pre> <ol> <li>Note that it is a HTTP request, not HTTPS. If you want to use HTTPS, you need to set up TLS certificates and configure the Ingress resource accordingly.</li> </ol> <p>Another way to expose the API is to use the <code>Ingress</code> resource, which allows you to define rules for routing external HTTP/S traffic to your services. This is particularly useful for managing multiple services under a single domain or subdomain. See the Ingress documentation for more details.</p> <p>Horizontal Pod Autoscaler</p> <p>The Horizontal Pod Autoscaler (HPA) automatically scales the number of pods in a deployment or replica set based on observed CPU utilization or other select metrics. It adjusts the number of replicas dynamically to ensure that the application can handle varying loads without manual intervention. To set up HPA, you need to define the target CPU utilization and the minimum and maximum number of replicas. The HPA controller continuously monitors the metrics and adjusts the number of replicas accordingly.</p> <p>Check the documentation for more details on how to set up HPA: Horizontal Pod Autoscaling and HorizontalPodAutoscaler Walkthrough.</p>"},{"location":"hands-on/5/#kubeclt","title":"Kubeclt","text":"<p>Kubernetes is a powerful container orchestration platform, and <code>kubectl</code> is its command-line tool for managing Kubernetes clusters. Below are some common commands and their descriptions to help you get started with <code>kubectl</code>.</p> <p>To install <code>kubectl</code>, follow the instructions in the Kubernetes documentation. To check if <code>kubectl</code> is installed correctly, run:</p> <pre><code>kubectl version --client\n</code></pre>"},{"location":"hands-on/5/#kubectl-cheat-sheet","title":"Kubectl Cheat Sheet","text":"Command Description <code>kubectl get all</code> List all resources in the current namespace. <code>kubectl get pods</code> List all pods in the current namespace. <code>kubectl get pod &lt;pod-name&gt; -o wide</code> Get detailed information about a specific pod. <code>kubectl get services</code> List all services in the current namespace. <code>kubectl get deployments</code> List all deployments in the current namespace. <code>kubectl describe pod &lt;pod-name&gt;</code> Show detailed information about a specific pod. <code>kubectl logs &lt;pod-name&gt;</code> View logs for a specific pod. <code>kubectl exec -it &lt;pod-name&gt; -- bash</code> Open a shell in a running pod. <code>kubectl apply -f &lt;file.yaml&gt;</code> Apply a configuration file to create/update resources. <code>kubectl delete pod &lt;pod-name&gt;</code> Delete a specific pod. <code>kubectl delete deployment &lt;deployment-name&gt;</code> Delete a specific deployment. <code>kubectl scale deployment &lt;deployment-name&gt; --replicas=&lt;number&gt;</code> Scale a deployment to a specified number of replicas. <code>kubectl port-forward &lt;pod-name&gt; &lt;local-port&gt;:&lt;pod-port&gt;</code> Forward a local port to a port on a pod. <code>kubectl get nodes</code> List all nodes in the cluster. <code>kubectl get namespaces</code> List all namespaces in the cluster. <code>kubectl get configmaps</code> List all config maps in the current namespace. <code>kubectl get secrets</code> List all secrets in the current namespace. <code>kubectl get ingress</code> List all ingress resources in the current namespace. <code>kubectl autoscale deployment &lt;deployment-name&gt; --cpu-percent=&lt;target-percentage&gt; --min=&lt;min-replicas&gt; --max=&lt;max-replicas&gt;</code> Create or update a Horizontal Pod Autoscaler for a deployment. <code>kubectl get hpa</code> List all Horizontal Pod Autoscalers in the current namespace. <code>kubectl delete hpa &lt;hpa-name&gt;</code> Delete a specific Horizontal Pod Autoscaler. <code>kubectl delete --all</code> Delete all resources in the current namespace."},{"location":"hands-on/5/#minikube","title":"Minikube","text":"<p>Minikube is a tool that makes it easy to run Kubernetes locally. It creates a single-node Kubernetes cluster on your machine, allowing you to test and develop applications in a Kubernetes environment without needing a full cloud setup.</p> <p>To install Minikube, follow the instructions in the Minikube documentation.</p>"},{"location":"hands-on/5/#minikube-cheat-sheet","title":"Minikube Cheat Sheet","text":"Command Description <code>minikube start --driver=&lt;driver&gt; --profile=&lt;profile&gt;</code> Start a Minikube cluster with a specified driver and profile. <code>minikube profile list</code> List all Minikube profiles. <code>minikube stop --all</code> Stop all Minikube clusters. <code>minikube status</code> Check the status of the Minikube cluster. <code>minikube dashboard</code> Open the Kubernetes dashboard in your web browser. <code>minikube ssh</code> SSH into the Minikube VM. <code>minikube delete</code> Delete the Minikube cluster. <code>minikube delete --all --purge</code> Delete all Minikube clusters and remove their configurations. <ol> <li> <p>What is Container Orchestration? - Red Hat \u21a9</p> </li> <li> <p>Docker Compose vs Kubernetes - Differences Explained - Spacelift \u21a9</p> </li> <li> <p>Kubernetes Alternatives for Container Orchestration - Wiz \u21a9</p> </li> <li> <p>Kubernetes Cheat Sheet - Kubernetes \u21a9</p> </li> <li> <p>Minikube Cheat Sheet - Minikube \u21a9</p> </li> <li> <p>Horizontal Pod Autoscaling - Kubernetes \u21a9</p> </li> <li> <p>HorizontalPodAutoscaler Walkthrough - Kubernetes \u21a9</p> </li> <li> <p>Kubernetes Architecture - Kubernetes \u21a9</p> </li> </ol>"},{"location":"platform/concepts/","title":"Concepts","text":""},{"location":"platform/concepts/#historical-context","title":"Historical Context","text":""},{"location":"platform/concepts/#single-block-system","title":"Single block system","text":"<p>Single block system, following the concept that a system is a blackbox schema, so many projects started in a simple single project that is a good choice to raise a system and try to use the initial features. This is a good approach for small and compact systems or for specialist systems where the speed of application matters.</p> <pre><code>---\ntitle: blackbox\n---\nflowchart LR\n  Input\n  subgraph Processing\n    direction TB\n    Storage\n    Business\n    UI\n  end\n  Output\n  Input --&gt; UI --&gt; Output</code></pre> <p>The main disadvantage of this approach is the strong coupling among business, user interface (UI), and storage. The coupling is so strong that there is a mix among all the components, which implies a high cost for maintenance.</p>"},{"location":"platform/concepts/#splitted-betweeen-data-and-program","title":"Splitted betweeen data and program","text":"<pre><code>---\ntitle: blackbox\n---\nflowchart LR\n  subgraph Processing\n    direction TB\n    subgraph Storage\n      x\n    end\n    subgraph Business\n      UI\n    end\n  end\n  Input --&gt; UI --&gt; Output\n  Business &lt;-- driver --&gt; Storage</code></pre> <p>System communicates to only an UI.</p> <p>Cobol</p>"},{"location":"platform/concepts/#multi-layer-approach","title":"Multi-layer approach","text":"<pre><code>---\ntitle: blackbox\n---\nflowchart LR\n  Input\n  subgraph Processing\n    direction TB\n    Storage\n    subgraph _\n      Businesses\n      UI\n    end\n  end\n  Output\n  Input --&gt; UI --&gt; Output\n  Business &lt;-- driver --&gt; Storage</code></pre>"},{"location":"platform/concepts/#mvc-pattern","title":"MVC Pattern","text":"<p>MVC stands for Model-View-Controller. It's a design pattern often used in web development. Here's a brief explanation of each component:</p> <ol> <li> <p>Model: This is the part of the system that handles the logic for the application data. Often model objects retrieve data (and store data) from a database.</p> </li> <li> <p>View: This is the part of the system that handles the display of the data. Most often the views are created from the model data.</p> </li> <li> <p>Controller: This is the part of the system that handles user interaction. Typically controllers read data from a view, control user input, and send input data to the model.</p> </li> </ol> <p>The idea behind MVC is that each of these components can be developed and tested independently, which can simplify the overall development process.</p> <pre><code>timeline\n    title Relevant Events\n    1991 : CORBA\n    1994 : GoF\n    1999 : J2EE 1.2 &lt;br&gt; initial specification\n    2002 : Spring\n    2006 : Java EE 5\n    2014 : Spring Boot\n    2019 : Jakarta EE 8</code></pre>"},{"location":"platform/concepts/#high-perfomance-architectures","title":"High-perfomance Architectures","text":"<p>High-performance architectures refer to the design and configuration of computer systems, networks, and software to achieve optimal speed, responsiveness, throughput, and efficiency. These architectures are specifically tailored to handle large-scale, resource-intensive, and performance-critical workloads. High-performance systems are often employed in scenarios such as data centers, cloud computing environments, scientific computing, financial services, and other applications where speed and efficiency are paramount.</p> <p>Here are key aspects and principles associated with high-performance architectures:</p>"},{"location":"platform/concepts/#parallelism-and-concurrency","title":"Parallelism and Concurrency","text":"<ul> <li>High-performance architectures often leverage parallelism and concurrency to execute multiple tasks simultaneously, improving overall throughput.</li> <li>Parallel processing involves dividing a task into smaller sub-tasks that can be processed concurrently, often across multiple processors or cores.</li> <li>Concurrency allows multiple tasks to be executed concurrently, even if they are not divided into explicit sub-tasks.</li> </ul>"},{"location":"platform/concepts/#distributed-systems","title":"Distributed Systems","text":"<ul> <li>Distributing workloads across multiple nodes in a network is a common strategy for achieving high performance.</li> <li>Distributed systems allow for horizontal scaling, where additional resources (nodes) can be added to handle increased demand.</li> </ul>"},{"location":"platform/concepts/#optimized-algorithms-and-data-structures","title":"Optimized Algorithms and Data Structures","text":"<ul> <li>Carefully designed algorithms and data structures are crucial for high performance.</li> <li>Efficient algorithms and data structures minimize computational complexity and memory usage.</li> </ul>"},{"location":"platform/concepts/#caching-and-memory-optimization","title":"Caching and Memory Optimization","text":"<ul> <li>Caching is used to store frequently accessed data in a location that allows faster retrieval, reducing the need to recompute or fetch data from slower storage.</li> <li>Memory optimization involves efficiently managing memory usage to minimize latency and improve responsiveness.</li> </ul>"},{"location":"platform/concepts/#scalability","title":"Scalability","text":"<ul> <li>High-performance architectures are designed to scale horizontally or vertically to accommodate growing workloads.</li> <li>Horizontal scalability involves adding more nodes or machines, while vertical scalability involves increasing the resources of individual nodes.</li> </ul>"},{"location":"platform/concepts/#load-balancing","title":"Load Balancing","text":"<ul> <li>Load balancing ensures that incoming requests are distributed evenly across multiple servers or resources.</li> <li>This helps prevent individual components from becoming bottlenecks and ensures optimal resource utilization.</li> </ul>"},{"location":"platform/concepts/#fault-tolerance-and-redundancy","title":"Fault Tolerance and Redundancy","text":"<ul> <li>High-performance architectures often incorporate redundancy and fault-tolerant mechanisms to ensure continuous operation in the face of hardware failures or network issues.</li> </ul>"},{"location":"platform/concepts/#specialized-hardware","title":"Specialized Hardware","text":"<ul> <li>In some cases, high-performance architectures may use specialized hardware, such as Graphics Processing Units (GPUs) or Field-Programmable Gate Arrays (FPGAs), to accelerate specific types of computations.</li> </ul>"},{"location":"platform/concepts/#optimized-network-architecture","title":"Optimized Network Architecture","text":"<ul> <li>Efficient communication between nodes is critical for high performance. Optimized network architectures, low-latency interconnects, and high-bandwidth connections contribute to overall system efficiency.</li> </ul>"},{"location":"platform/concepts/#monitoring-and-performance-tuning","title":"Monitoring and Performance Tuning","text":"<ul> <li>Continuous monitoring and performance tuning are essential to identify and address bottlenecks, optimize resource utilization, and ensure that the system is operating at peak efficiency.</li> </ul>"},{"location":"platform/concepts/#asynchronous-and-event-driven-design","title":"Asynchronous and Event-Driven Design","text":"<ul> <li>Asynchronous and event-driven architectures can improve system responsiveness by allowing components to operate independently and respond to events as they occur.</li> </ul> <p>High-performance architectures are tailored to the specific requirements of the applications they support. They often involve a combination of hardware and software optimizations to achieve the desired level of performance for a given workload. It's important to note that designing and maintaining high-performance architectures can be complex and may involve trade-offs between factors such as cost, complexity, and ease of maintenance.</p>"},{"location":"platform/concepts/#cap-theorem","title":"CAP theorem","text":"<p>CAP theorem, also known as Brewer's theorem, is a concept in distributed systems that addresses the trade-offs among three fundamental aspects: Consistency, Availability, and Partition Tolerance. It was introduced by computer scientist Eric Brewer in 2000. The CAP theorem suggests that in a distributed system, it is impossible to simultaneously achieve all three of these guarantees. A system can provide at most two out of the three.</p> <p>Here are the key components of the CAP theorem:</p>"},{"location":"platform/concepts/#consistency-c","title":"Consistency (C)","text":"<ul> <li>Definition: Every read receives the most recent write or an error. In other words, all nodes in the system see the same data at the same time.</li> <li>Implication: Ensuring consistency means that any read operation on the system will reflect the most recent write, even in the presence of concurrent operations.</li> </ul>"},{"location":"platform/concepts/#availability-a","title":"Availability (A)","text":"<ul> <li>Definition: Every request for a read or write operation receives a response without the guarantee that it contains the most recent version of the data.</li> <li>Implication: An available system can provide a response to read or write requests even if it may not reflect the most recent update. The system is operational and accessible.</li> </ul>"},{"location":"platform/concepts/#partition-tolerance-p","title":"Partition Tolerance (P)","text":"<ul> <li>Definition: The system continues to operate even when network partitions occur, meaning that communication between nodes is lost or delayed.</li> <li>Implication: In a partition-tolerant system, the network can be unreliable or experience failures, and the system can still function.</li> </ul> <p>According to the CAP theorem, a distributed system can prioritize at most two of these three guarantees, and the choice depends on the system's requirements and the nature of the application. Here are three possible scenarios:</p> <ul> <li>CA (Consistency and Availability): In scenarios where network partitions are rare and can be quickly resolved, a system may prioritize consistency and availability. This is common in traditional relational databases where consistency is crucial.</li> <li>CP (Consistency and Partition Tolerance): In scenarios where the network is unreliable, and partitions are frequent, a system may prioritize consistency and partition tolerance. This is common in systems that require strong consistency, such as many distributed databases.</li> <li>AP (Availability and Partition Tolerance): In scenarios where network partitions are common, and the system needs to remain operational, a system may prioritize availability and partition tolerance. This is common in systems where high availability and fault tolerance are critical, even if it means sacrificing strong consistency.</li> </ul> <p> </p> Source: Wikipedia - CAP Theorem <p>It's important to note that the CAP theorem provides a theoretical framework for understanding trade-offs in distributed systems but does not prescribe specific solutions. Different systems may make different choices based on their specific requirements and use cases. Additionally, advancements in distributed systems research have led to the exploration of systems that aim to provide a balance between the three aspects, challenging the strict interpretation of the CAP theorem in some cases.</p>"},{"location":"platform/concepts/#scalability_1","title":"Scalability","text":"<p>Scalability in the context of computer systems refers to the ability of a system to handle an increasing amount of work, or its potential to be enlarged to accommodate that growth. There are several types of scalability that are often discussed in the field of computing:</p>"},{"location":"platform/concepts/#vertical-scalability-scale-up","title":"Vertical Scalability (Scale-Up)","text":"Definition Vertical scalability involves adding more resources to a single node or machine in order to increase its capacity. Example Upgrading the CPU, adding more RAM, or increasing storage on a server. Pros Cons Simplicity in implementation. There's a limit to how much a single machine can be scaled vertically. it can be cost-effective for certain applications. It may also lead to downtime during upgrades."},{"location":"platform/concepts/#horizontal-scalability-scale-out","title":"Horizontal Scalability (Scale-Out)","text":"Definition Horizontal scalability involves adding more nodes or machines to a system, distributing the load across multiple machines. Example Adding more servers to a web application to handle increased traffic. Pros Cons Highly scalable, as resources can be easily added by adding more machines. Requires a distributed architecture. Can provide better fault tolerance. Some applications may not be easily parallelized."},{"location":"platform/concepts/#load-balancing_1","title":"Load Balancing","text":"Definition Load balancing involves distributing incoming network traffic or workload across multiple servers or resources to optimize resource utilization, maximize throughput, minimize response time, and avoid overloading any single resource. Example A load balancer distributing incoming web requests across multiple web servers. Pros Cons Improves overall system performance, ensures high availability, and can help with fault tolerance. Requires additional infrastructure, and the load balancer itself can become a potential bottleneck."},{"location":"platform/concepts/#elastic-scalability","title":"Elastic Scalability","text":"Definition Elastic scalability involves dynamically adjusting resources based on demand. Resources are automatically added or removed as needed. Example Cloud computing platforms that can automatically scale the number of virtual machines based on traffic. Pros Cons Efficient resource utilization, cost-effective as resources are only used when needed. Requires sophisticated monitoring and management systems."},{"location":"platform/concepts/#database-scalability","title":"Database Scalability","text":"Definition Database scalability refers to the ability of a database to handle an increasing amount of data and transactions. Vertical Database Scalability: Adding more resources to a single database server (e.g., increasing CPU, RAM). Horizontal Database Scalability: Distributing the database across multiple servers (e.g., sharding or partitioning). Pros Cons Can improve performance and handle increased data loads. Complex to implement, and horizontal scalability may require changes to the database schema."},{"location":"platform/concepts/#caching","title":"Caching","text":"Definition Caching involves storing frequently accessed data in a cache to reduce the need to fetch the same data from the original source repeatedly. Example Caching frequently used database queries or the results of computationally expensive operations. Pros Cons Improves response time, reduces load on backend systems. May lead to stale data if not managed properly. <p>Each type of scalability has its own strengths and weaknesses, and the choice of scalability approach depends on the specific requirements and constraints of the system or application being developed. Often, a combination of these scalability types is employed to achieve optimal performance and resource utilization.</p>"},{"location":"platform/concepts/#design-patterns","title":"Design Patterns","text":"<p>A design pattern in software development is a general, reusable solution to a common problem that occurs in a particular context within a software design. It's a template or a best practice that addresses a specific design or programming problem. Design patterns aren't complete solutions by themselves; rather, they provide a blueprint for solving certain types of problems.</p> <p>The concept of design patterns was popularized by the book \"Design Patterns: Elements of Reusable Object-Oriented Software,\" written by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, often referred to as the \"Gang of Four\" (GoF)<sup>1</sup>. The book categorizes design patterns into three main types:</p> <ul> <li>Creational Patterns: These patterns deal with object creation mechanisms, trying to create objects in a manner suitable to the situation. Examples include the Singleton pattern, Factory Method pattern, and Abstract Factory pattern.</li> <li>Structural Patterns: These patterns focus on the composition of classes or objects. They help in creating a structure of classes and objects, making it easier to form larger structures. Examples include the Adapter pattern, Decorator pattern, and Composite pattern.</li> <li>Behavioral Patterns: Behavioral patterns are concerned with the interaction and responsibility of objects. They define communication patterns between objects and the responsibility of one object in a given situation. Examples include Observer pattern, Strategy pattern, and Command pattern.</li> </ul> <p>Design patterns provide several benefits in software development:</p> <ul> <li>Reusability: Design patterns promote reusability of solutions to common problems. Once a design pattern is established, it can be applied to similar problems in different parts of the system.</li> <li>Scalability: Using design patterns can enhance the scalability of a system by providing proven solutions that can be applied as the system grows.</li> <li>Maintainability: Patterns make code more maintainable by providing a clear and organized structure. Developers familiar with design patterns can understand the overall architecture more easily.</li> <li>Common Vocabulary: Design patterns establish a common vocabulary for developers. When a developer mentions a particular pattern, others who are familiar with it can quickly understand the solution being implemented.</li> </ul> <p>While design patterns are valuable tools, it's essential to use them judiciously. Not every problem requires a design pattern, and using patterns unnecessarily can lead to overly complex and difficult-to-maintain code. It's important to understand the problem at hand and choose the appropriate design pattern when it genuinely adds value to the solution.</p> <ol> <li> <p>GAMMA, E.; HELM, R.; JOHNSON, R., VLISSIDES, J., Design Patterns: Elements of Reusable Object-Oriented Software, 1\u00aa ed., Addison-Wesley Professional, 1994.\u00a0\u21a9</p> </li> <li> <p> Wikipedia - CAP Theorem \u21a9</p> </li> <li> <p>Gang of Four - Gof \u21a9</p> </li> </ol>"},{"location":"platform/microservices/","title":"Microservices","text":""},{"location":"platform/microservices/#microservices-concepts","title":"Microservices Concepts","text":"<p>Microservices, also known as the microservices architecture, is an architectural style that structures an application as a collection of small autonomous services, modeled around a business domain.</p> <p>Key concepts of microservices include:</p> <ul> <li>Single Responsibility: Each microservice should have a single responsibility and should implement a single business capability.</li> <li>Independence: Microservices should be able to run and evolve independently of each other. They should be independently deployable and scalable.</li> <li>Decentralization: Microservices architecture favors decentralized governance. Teams have the freedom to choose the best technology stack that suits their service.</li> <li>Isolation of Failures: If a microservice fails, it should not impact the availability of other services.</li> <li>Data Isolation: Each microservice should have its own database to ensure that the services are loosely coupled and can evolve independently.</li> <li>Communication: Microservices communicate with each other through well-defined APIs and protocols, typically HTTP/REST with JSON or gRPC with Protobuf.</li> <li>Infrastructure Automation: Due to the distributed nature of the microservices architecture, automation of infrastructure is a must. This includes automated provisioning, scaling, and deployment.</li> <li>Observability: With many different services, it's important to have excellent monitoring and logging to detect and diagnose problems.</li> </ul>"},{"location":"platform/microservices/#domain-driven-design","title":"Domain Driven Design","text":"<p>Domain-Driven Design (DDD) is a software development approach that emphasizes collaboration between technical experts and domain experts. The goal is to create software that is a deep reflection of the underlying domain, which is the specific area of business or activity that the software is intended to support.</p> <p>Key concepts of DDD include:</p> <ul> <li>Ubiquitous Language: A common language established between developers and domain experts, used to describe all aspects of the domain.</li> <li>Bounded Context: A boundary within which a particular model is defined and applicable.</li> <li>Entities: Objects that have a distinct identity that persists over time and across different representations.</li> <li>Value Objects: Objects that are defined by their attributes, not their identity.</li> <li>Aggregates: Clusters of entities and value objects that are treated as a single unit.</li> <li>Repositories: They provide a way to obtain references to aggregates.</li> <li>Domain Events: Events that domain experts care about.</li> <li>Services: Operations that don't naturally belong to any entity or value object.</li> </ul> <p>By focusing on the domain and domain logic, DDD provides techniques to develop complex systems targeting real-world scenarios. It helps to reduce the complexity by dividing the system into manageable and interconnected parts.</p> <p> </p> Source: System Design 101 - Microservice Architecture"},{"location":"platform/microservices/#design-a-microservice-platform","title":"Design a Microservice Platform","text":"<pre><code>flowchart LR\n  subgraph Client\n    direction LR\n    Web\n    Mobile\n    Desktop\n  end\n  subgraph Microservices\n    direction LR\n    gateway[\"Gateway\"]\n    subgraph Essentials\n      direction TB\n      discovery[\"Discovery\"]\n      auth[\"Auth\"]\n      config[\"Configuration\"]\n    end\n    subgraph Businesses\n      direction TB\n      ms1[\"Service 1\"]\n      ms2[\"Service 2\"]\n      ms3[\"Service 3\"]\n    end\n  end\n  Client --&gt; lb[\"Load Balance\"] --&gt; gateway --&gt; Businesses\n  gateway --&gt; auth\n  gateway --&gt; discovery\n  click gateway \"../gateway/\" \"Gateway\"\n  click discovery \"../discovery/\" \"Discovery\"\n  click auth \"../auth-service/\" \"Auth\"\n  click config \"../config/\" \"Configuration\"\n  click lb \"../load-balancing/\" \"Load Balance\"</code></pre> <ol> <li> <p>XU, A., System Design 101.\u00a0\u21a9</p> </li> <li> <p>Wikipedia - Domain Driven Design \u21a9</p> </li> </ol>"},{"location":"platform/database/caching/","title":"Caching","text":"<p>Spring Boot Cache</p> <p>https://docs.spring.io/spring-framework/docs/4.1.5.RELEASE/spring-framework-reference/html/cache.html</p> <p>Redis</p> <p>https://medium.com/nstech/programa%C3%A7%C3%A3o-reativa-com-spring-boot-webflux-e-mongodb-chega-de-sofrer-f92fb64517c3</p>"},{"location":"platform/database/caching/#handout-redis","title":"Handout Redis","text":""},{"location":"platform/database/flyway/","title":"Flyway","text":""},{"location":"platform/database/flyway/#flyway","title":"Flyway","text":"<p>Flyway is an open-source database migration tool that strongly favors simplicity and convention over configuration. It is designed to simplify the process of versioning a database, similar to how Git versions source code. </p> <p>With Flyway, you can apply version control to your database which allows you to migrate it to a newer version and also revert changes if needed. Flyway uses SQL scripts or Java-based migrations to evolve your database schema in a way that is controllable and predictable.</p> <p>Key features of Flyway include:</p> <ul> <li>Version control for your database: Allows you to track changes and apply version control to your database, similar to how you would with your source code.</li> <li>Support for SQL and Java-based migrations: You can use SQL for simple changes, and Java for complex migrations.</li> <li>Repeatable migrations: You can use this feature to manage objects in your database that can't be easily handled with versioned migrations, like stored procedures and views.</li> <li>Multiple database support: Flyway supports a wide variety of databases including MySQL, PostgreSQL, SQL Server, and more.</li> </ul> <p>https://www.baeldung.com/liquibase-vs-flyway</p> <ol> <li> <p>https://www.baeldung.com/database-migrations-with-flyway\u00a0\u21a9</p> </li> </ol>"},{"location":"platform/messaging/concepts/","title":"Concepts","text":"<p>https://medium.com/@thiagolenz/tutorial-spring-boot-e-rabbitmq-como-fazer-e-porqu%C3%AA-4a6cc34a3bd1</p> <p>https://www.simplilearn.com/kafka-vs-rabbitmq-article</p> <p>https://mmarcosab.medium.com/criando-consumer-e-produkafka-com-spring-boot-b427cc2f841d</p>"},{"location":"platform/security/concepts/","title":"Concepts","text":"<p>Security is an important aspect of software development. It involves protecting the confidentiality, integrity, and availability of data and resources. Two key concepts in security are authentication and authorization.</p>"},{"location":"platform/security/concepts/#authentication","title":"Authentication","text":"<p>Authentication is the process of verifying the identity of a user or system. It ensures that the user or system is who they claim to be. Common authentication methods include passwords, biometrics, and two-factor authentication. The system checks these credentials against the stored data. If the credentials are valid, the system confirms the user's identity.</p> <p>In many systems, after successful authentication, the system generates a token. This token is a piece of data that represents the user's authentication session. It's like a digital ticket that proves the user's identity for a certain period of time.</p> <p>This token is then sent back to the user. The user's client software (like a web browser) stores this token and sends it along with every subsequent request to the server (in case of stateless server). This way, the server knows that the request comes from an authenticated user without needing to ask for the credentials again.</p> <p>Here's a simplified step-by-step process:</p> <pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;+Auth Server: authentication(credentials)\n  Auth Server-&gt;&gt;Auth Server: verifies credenditals and generates a token\n  Auth Server-&gt;&gt;-User: returns the token\n  User-&gt;&gt;User: stores the token to use for the next requests</code></pre> <ol> <li>The user sends their username and password (or other credentials) to the server;</li> <li>The server verifies the credentials. If they're valid, the server generates a token.</li> <li>The server sends this token back to the user.</li> <li>The user's client software stores this token.</li> <li>For every subsequent request, the client sends this token along with the request.</li> <li>The server checks the token to ensure it's valid and hasn't expired.</li> <li>This token-based authentication process is commonly used in many modern web applications and APIs. It helps maintain the user's session and allows the server to authenticate requests without storing the user's state.</li> </ol>"},{"location":"platform/security/concepts/#authorization","title":"Authorization","text":"<p>Authorization is the process of granting or denying access to specific resources or actions based on the authenticated user's privileges. It determines what a user is allowed to do within a system. Authorization can be role-based, where permissions are assigned based on predefined roles, or attribute-based, where permissions are based on specific attributes of the user.</p> <p>In many systems, the token not only represents the user's identity, but also includes information about their permissions or roles. This is often done using a type of token called a JSON Web Token (JWT), which can include a payload of data.</p> <p>Here's a simplified step-by-step process:</p> <pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Server: request with token\n  Auth Server-&gt;&gt;Auth Server: decodes the token and extracts claims\n  Auth Server-&gt;&gt;Auth Server: verifies permissions\n  critical allowed\n    Auth Server-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Server--&gt;&gt;User: unauthorized message\n  end  </code></pre> <ol> <li>After authentication, the user's client software sends a request to a server. This request includes the token.</li> <li>The server decodes the token and extracts the user's identity and permissions.</li> <li>The server checks whether the user has the necessary permissions for the requested action. This could involve checking the user's roles or other attributes against the requirements for the action.</li> <li>If the user has the necessary permissions, the server allows the action. If not, the server denies the action.</li> </ol> <p>This process allows the server to authorize actions without needing to repeatedly look up the user's permissions. It also allows for stateless servers, as the necessary information is included in every request.</p> <p>By implementing strong authentication and authorization mechanisms, software systems can ensure that only authorized users have access to sensitive data and functionalities, reducing the risk of unauthorized access and potential security breaches.</p> <p>As the platform has only one entrace point, it is</p> <p>JWT is a decentralized </p> <p>The point of entrance of API is the gateway, then as suggested by <sup>1</sup>.</p>"},{"location":"platform/security/concepts/#auth-service","title":"Auth Service","text":"<ul> <li>Responsabilities:<ul> <li>Registration:</li> <li>Authentication:</li> <li>Authorization:</li> </ul> </li> </ul> <p>Two Maven Projects</p> <ul> <li> <p>Interfaces</p> </li> <li> <p>Implemmentation: resource</p> </li> </ul> <pre><code>classDiagram\n  namespace Interface {\n    class AuthController {\n      &lt;&lt;interface&gt;&gt;\n      register(RegisterIn)\n      authenticate(CredentialIn)\n      identify(String)\n    }\n    class RegisterIn {\n      &lt;&lt;record&gt;&gt;\n      String firstName\n      String lastName\n      String email\n      String password\n    }\n    class CredentialIn {\n      &lt;&lt;record&gt;&gt;\n      String email\n      String password\n    }\n  }\n  namespace Resource {\n    class AuthResource {\n      &lt;&lt;REST API&gt;&gt;\n      -authService\n    }\n    class AuthService {\n      &lt;&lt;service&gt;&gt;\n      -registerRepository\n      -userRepository\n      register(Register)\n      authenticate(Credential)\n      identify(Session)\n    }\n    class RegisterRepository {\n      &lt;&lt;interface&gt;&gt;\n    }\n    class RegisterEntity {\n      &lt;&lt;entity&gt;&gt;\n    }\n    class UserRepository {\n      &lt;&lt;interface&gt;&gt;\n    }\n    class UserEntity {\n      &lt;&lt;entity&gt;&gt;\n    }\n  }\n  AuthController &lt;|-- AuthResource\n  AuthResource o-- AuthService\n  AuthService o-- RegisterRepository\n  AuthService o-- UserRepository\n  RegisterRepository \"1\" --&gt; \"0..*\" RegisterEntity\n  UserRepository \"1\" --&gt; \"0..*\" UserEntity</code></pre>"},{"location":"platform/security/concepts/#addtional-material","title":"Addtional Material","text":"<ul> <li> <p>JSON Web Token</p> </li> <li> <p> Autentica\u00e7\u00e3o e Autoriza\u00e7\u00e3o com Spring Security e JWT Tokens by Fernanda Kipper</p> <p></p> </li> </ul> <ol> <li> <p>DELANTHA, R., Spring Cloud Gateway security with JWT, 2023.\u00a0\u21a9</p> </li> </ol>"},{"location":"platform/security/jwt/","title":"Jwt","text":""},{"location":"platform/security/jwt/#jwt-json-web-token","title":"JWT - JSON Web Token","text":"<p>JWT stands for JSON Web Token. It is a compact, URL-safe means of representing claims between two parties. JWTs are commonly used to secure the transmission of information between parties in a web environment, typically for authentication and information exchange. The JWT specification is defined by RFC 7519<sup>1</sup> and it is a decentralized approach for security (which can support horizontal scalability).</p> <p>Here are the key components and concepts of JWT:</p> <ul> <li>JSON Format: JWTs are represented as JSON objects that are easy to parse and generate. The JSON format makes them human-readable and easy to work with.</li> <li> <p>Three Parts: JWTs consist of three parts separated by dots (<code>.</code>): Header, Payload, and Signature.</p> <ul> <li> <p>Header: The header typically consists of two parts: the type of the token (JWT) and the signing algorithm being used, such as HMAC SHA256 or RSA.</p> </li> <li> <p>Payload: The payload contains the claims. Claims are statements about an entity (typically, the user) and additional data. There are three types of claims: registered, public, and private claims.</p> </li> <li> <p>Signature: To create the signature part, you take the encoded header, the encoded payload, a secret, the algorithm specified in the header, and sign that.</p> </li> </ul> </li> <li> <p>Encoding: Each of the three parts is Base64Url encoded, and the resulting strings are concatenated with periods between them. The final JWT looks like: <code>xxxxx.yyyyy.zzzzz</code>.</p> </li> <li>Stateless and Self-contained: JWTs are stateless, meaning that all the information needed is within the token itself. The server doesn't need to store the user's state. They are also self-contained, meaning that all the information needed is contained within the token.</li> <li>Use Cases: JWTs are commonly used for authentication and information exchange between parties. For example, after a user logs in, a server could generate a JWT and send it to the client. The client can then include the JWT in the headers of subsequent requests to access protected resources. The server can verify the authenticity of the JWT using the stored secret key.</li> <li>Security Considerations: While JWTs are widely used and versatile, it's important to handle them securely. For instance, the key used to sign the JWT should be kept secret, and HTTPS should be used to transmit JWTs to prevent man-in-the-middle attacks.</li> </ul> <p>Here's a simple example of a JWT created on JWT Builder<sup>2</sup>:</p> <p><code>eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9.eyJpc3MiOiJJbnNwZXIiLCJpYXQiOjE3MDMwMDgzMzgsImV4cCI6MjAxODU0MTEzOCwiYXVkIjoid3d3Lmluc3Blci5lZHUuYnIiLCJzdWIiOiJodW1iZXJ0b3JzQGluc3Blci5lZHUuYnIiLCJHaXZlbk5hbWUiOiJIdW1iZXJ0byIsIlN1cm5hbWUiOiJTYW5kbWFubiIsIkVtYWlsIjoiaHVtYmVydG9yc0BpbnNwZXIuZWR1LmJyIiwiUm9sZSI6IlByb2Zlc3NvciJ9.SsGdvR5GbYWTRbxY7IGxHt1vSxhkpRueBJWsi0lrPhJVCICp119QjU8F3QvHW0yF5tw-HhQ9RVh0l89t4M0LNw</code></p> <p>This JWT consists of three parts, decoded by <sup>3</sup>:</p> HeaderPayloadSignature <p><code>eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9</code></p> <pre><code>{\n  \"typ\": \"JWT\",\n  \"alg\": \"HS512\"\n}\n</code></pre> <p><code>eyJpc3MiOiJJbnNwZXIiLCJpYXQiOjE3MDMwMDgzMzgsImV4cCI6MjAxODU0MTEzOCwiYXVkIjoid3d3Lmluc3Blci5lZHUuYnIiLCJzdWIiOiJodW1iZXJ0b3JzQGluc3Blci5lZHUuYnIiLCJHaXZlbk5hbWUiOiJIdW1iZXJ0byIsIlN1cm5hbWUiOiJTYW5kbWFubiIsIkVtYWlsIjoiaHVtYmVydG9yc0BpbnNwZXIuZWR1LmJyIiwiUm9sZSI6IlByb2Zlc3NvciJ9</code></p> <pre><code>{\n  \"iss\": \"Insper\",\n  \"iat\": 1703008338,\n  \"exp\": 2018541138,\n  \"aud\": \"www.insper.edu.br\",\n  \"sub\": \"humbertors@insper.edu.br\",\n  \"GivenName\": \"Humberto\",\n  \"Surname\": \"Sandmann\",\n  \"Email\": \"humbertors@insper.edu.br\",\n  \"Role\": \"Professor\"\n}\n</code></pre> <p><code>SsGdvR5GbYWTRbxY7IGxHt1vSxhkpRueBJWsi0lrPhJVCICp119QjU8F3QvHW0yF5tw-HhQ9RVh0l89t4M0LNw</code></p> <pre><code>HMACSHA512(\n  base64UrlEncode(header) + \".\" +\n  base64UrlEncode(payload),\n  qwertyuiopasdfghjklzxcvbnm123456,\n)\n</code></pre> <p>JWTs are widely used in web development due to their simplicity, flexibility, and support across various programming languages and frameworks. They are commonly used in token-based authentication systems.</p>"},{"location":"platform/security/jwt/#addtional-material","title":"Addtional Material","text":"<ul> <li> <p>Spring Cloud Security</p> </li> <li> <p> ByeteByteGo - Why is JWT popular?</p> <p></p> </li> </ul> <ol> <li> <p>RFC 7519 - JSON Web Token (JWT), 2015.\u00a0\u21a9</p> </li> <li> <p>JWT - Builder.\u00a0\u21a9</p> </li> <li> <p>jwt.io - JWT Verification.\u00a0\u21a9</p> </li> <li> <p>Unix Time Stamp - Epoch Converter.\u00a0\u21a9</p> </li> <li> <p>DELANTHA, R., Spring Cloud Gateway security with JWT, 2023.\u00a0\u21a9</p> </li> <li> <p>Wikipedia - Pepper (cryptography).\u00a0\u21a9</p> </li> <li> <p>PGzlan, Serve your hash with Salt and Pepper for Stronger Account Security, 2023.\u00a0\u21a9</p> </li> </ol>"},{"location":"versions/terms-and-conditions/","title":"Terms and Conditions","text":"<p>Agreement to</p> <p>The following terms and conditions apply to the course.</p> <p>By participating in the course, you agree to abide by these terms.</p>"},{"location":"versions/terms-and-conditions/#general","title":"General","text":"<ul> <li>Previously, the participants were required to read the material in advance to enhance your understanding and engagement during the lectures;</li> <li>All deliverables must be submitted in the format specified: GitHub Pages. No other formats will be accepted. - there exists a template for the course that you can use to create your GitHub Pages - Template;</li> <li>There is a strict policy against plagiarism. Any form of plagiarism will result in a zero grade for the activity and may lead to further disciplinary actions as per the university's academic integrity policies;</li> <li>The course is designed to be completed in a single semester, and all activities are structured to fit within this timeframe;</li> </ul>"},{"location":"versions/terms-and-conditions/#individual-activities","title":"Individual activities","text":"<ul> <li>The deadline for each activity is not extended, and it is expected that you complete them within the timeframe provided in the course schedule - NO EXCEPTIONS will be made for late submissions.</li> <li>All deliverables for individual activities should be submitted through the course platform.</li> </ul>"},{"location":"versions/terms-and-conditions/#team-projects","title":"Team projects","text":"<p>Team projects are an essential part of this course, allowing you to collaborate with your peers and apply the concepts learned in a practical setting.</p> <p>Format of Deliverables</p> <p>All deliverables for team projects must be submitted in the format of GitHub Pages. This includes the project report, code, and any other relevant materials. The use of GitHub Pages allows for easy sharing and collaboration among team members.</p>"},{"location":"versions/2024.1/","title":"2024.1","text":"Info <p> Prof. Humberto Sandmann</p> <p> humbertors@insper.edu.br</p> <p>Students</p> <p></p> <p>Meetings</p> Evento Dia In\u00edcio T\u00e9rmino Aula Qua. 09h45 11h45 Aula Sex. 07h30 09h30 Atendimento Seg. 12h00 13h30 <p>Grades</p> FinalIndividualTeam \\[ \\text{Final Grade} = \\left\\{\\begin{array}{lll}     \\text{Individual} \\geq 5 \\bigwedge \\text{Team} \\geq 5 &amp;     \\implies &amp;     \\displaystyle \\frac{ \\text{Individual} + \\text{Team} } {2}     \\\\     \\\\     \\text{Otherwise} &amp;     \\implies &amp;     \\min\\left(\\text{Individual}, \\text{Team}\\right)     \\end{array}\\right. \\] Avalia\u00e7\u00e3o Descri\u00e7\u00e3o Data Nota (%) Roteiros M\u00e9dia aritm\u00e9tica dos 2 roteiros de maiores notas. 60.0 Roteiro 1 Testes - Roteiro 2 Bottlenecks 22.mai Roteiro 3 Cloud 22.mai Participa\u00e7\u00e3o Nota geral atribu\u00edda ao grupo distribu\u00edda aos membros pelo pr\u00f3prio grupo, apenas notas inteiras \\([0; 10]\\) 40.0 Avalia\u00e7\u00e3o Descri\u00e7\u00e3o Data Nota (%) Checkpoints CP1 Montar um Spring Cloud 05.abr 7.5 CP2 Testes e Pipeline 19.abr 7.5 CP3 K8s 10.mai 7.5 CP4 Platform as a Product 22.mai 7.5 Apresenta\u00e7\u00e3o 10.0 Projeto 60.0 <p>Individual</p> Roteiro 1Roteiro 2Roteiro 3Participa\u00e7\u00e3o <p>Testes</p> <ul> <li> Roteiros de testes de funcionalidades ou de testes de carga</li> <li> Documenta\u00e7\u00e3o dos resultados obtidos</li> </ul> <p>Bottlenecks</p> <ul> <li> <p> Implementa\u00e7\u00e3o de um microservi\u00e7o de bottleneck para o projeto:</p> <ul> <li>Mensageria<ul> <li>RabbitMQ</li> <li>Kafka</li> <li>Spring e Kafka, Giuliana Bezerra</li> </ul> </li> <li>Resili\u00eancia<ul> <li>Spring Cloud Circuit Breaker</li> </ul> </li> <li>Configura\u00e7\u00e3o<ul> <li>Spring Cloud Config</li> </ul> </li> <li>In-Memory Database<ul> <li>Redis, Giuliana Bezerra</li> </ul> </li> <li>Payments (sandboxes)<ul> <li>PayPal</li> <li>Hearland</li> <li>Mercado Pago</li> </ul> </li> <li>Jenkins<ul> <li>SonarQube</li> <li>Dependency Analyzes</li> </ul> </li> </ul> </li> </ul> <p>Cloud</p> <ul> <li> Roteiro de publica\u00e7\u00e3o de um microsservi\u00e7o em Cloud</li> </ul> <ul> <li> Contribui\u00e7\u00f5es no GitHub dos participantes</li> <li> Documenta\u00e7\u00e3o das reuni\u00f5es (dayly, retro, etc)</li> <li> Nota geral atribu\u00edda pelo professor mas dividida pelo grupo</li> </ul> <p>Team</p> Checkpoint 1Checkpoint 2Checkpoint 3Checkpoint 4Apresenta\u00e7\u00e3oProjeto <p>Desenvolvimento Spring Cloud</p> <ul> <li> Servi\u00e7o de discovery</li> <li> Servi\u00e7o de gateway</li> <li> Servi\u00e7o de autentica\u00e7\u00e3o e autoriza\u00e7\u00e3o</li> <li> 3 microsservi\u00e7os com persist\u00eancia de dados</li> <li> Comunica\u00e7\u00e3o entre, ao menos 2, microsservi\u00e7os, al\u00e9m de: Gateway \\(\\rightarrow\\) Auth \\(\\rightarrow\\) Account</li> <li> Monitoramento com dashboard de microsservi\u00e7os</li> <li> Documenta\u00e7\u00e3o das APIs padr\u00e3o Swagger</li> <li> Cluster em Docker Compose para deploy dos microsservi\u00e7os</li> </ul> <p>Testes e Pipeline</p> <ul> <li> Plano de testes</li> <li> Script Jenkins - Pipeline as Code</li> </ul> <p>K8s</p> <ul> <li> Release no Minikube</li> <li> Scripts declarativos dos servi\u00e7os</li> </ul> <p>Platform as a Service</p> <ul> <li> Plano de uso da plataforma como um produto (PaaS)</li> <li> Vislumbrar uso da plataforma por terceiros</li> </ul> <ul> <li> Storytelling (come\u00e7o, meio, fim)</li> <li> Flu\u00eddez</li> <li> Qualidade do material apresentado</li> <li> Tempo</li> <li> Participa\u00e7\u00e3o</li> </ul> <ul> <li> Checkpoint 1</li> <li> Checkpoint 2</li> <li> Checkpoint 3</li> <li> Checkpoint 4</li> <li> Planejamento</li> <li> Documenta\u00e7\u00e3o (markdown)</li> <li> Frontend (funcionalidades b\u00e1sicas: login, registro, dashboard, etc)</li> </ul> <p>Planning</p> <p></p>"},{"location":"versions/2024.1/#repositories","title":"Repositories","text":"<p>Dev</p> Microservice Context Interface Service Discovery Infra platform.241.store.discovery Gateway Infra platform.241.store.gateway Postgres Database platform.241.store.db Account Business platform.241.store.account platform.241.store.account-resource Auth Business platform.241.store.auth platform.241.store.auth-resource <p>Ops</p> Description Repositories Commands Docker Compose API platform.241.store.docker-api <code>docker compose up --build</code> <code>docker compose down</code> Jenkins Pipelines platform.241.store.ops <code>docker compose up --build</code> <code>docker compose down</code> http://localhost:9000"},{"location":"versions/2025.1/","title":"2025.1","text":""},{"location":"versions/2025.1/#instructor","title":"Instructor","text":"<p> Prof. Humberto Sandmann</p> <p> humbertors@insper.edu.br</p>"},{"location":"versions/2025.1/#students","title":"Students","text":""},{"location":"versions/2025.1/#meetings","title":"Meetings","text":"Evento Dia In\u00edcio T\u00e9rmino Aula Qua. 13h30 15h30 Aula Sex. 13h30 15h30 Atendimento Qua. 09h30 11h00"},{"location":"versions/2025.1/#grade","title":"Grade","text":"FinalIndividualTeam \\[ \\text{Final Grade} = \\left\\{\\begin{array}{lll}     \\text{Individual} \\geq 5 \\bigwedge \\text{Team} \\geq 5 &amp;     \\implies &amp;     \\displaystyle \\frac{ \\text{Individual} + \\text{Team} } {2}     \\\\     \\\\     \\text{Otherwise} &amp;     \\implies &amp;     \\min\\left(\\text{Individual}, \\text{Team}\\right)     \\end{array}\\right. \\] Tarefa Descri\u00e7\u00e3o Peso Checkpoint 1 CRUD Microservice 10% Checkpoint 2 Gateway 15% Checkpoint 3 Security 15% Checkpoint 4 DevOps 15% Checkpoint 5 Orchestration 15% Bootnecks InMemory DatabaseMessage QueuesObservabilityCode qualityOAuth2Payments (sandboxes) 20% Documentation README with MkDocs 10% <p>Entrega</p> <ul> <li>A entrega de um checkpoint implica, OBRIGATORIAMENTE, na entrega do checkpoint anterior;</li> <li>Trabalho em grupo deve ser documentado no GitHub.</li> </ul> Tarefas Descri\u00e7\u00e3o Peso AWS Configurar AWS 5% EKS Disponibilizar a aplica\u00e7\u00e3o 15% Testes Testes de carga 20% CI/CD Jenkins 10% Custos An\u00e1lise de custos 15% PaaS Plano de uso da plataforma 15% Apresenta\u00e7\u00e3o Storytelling 20%"},{"location":"versions/2025.1/#planning","title":"Planning","text":""},{"location":"versions/2025.2/","title":"2025.2","text":""},{"location":"versions/2025.2/#instructors","title":"Instructors","text":"<p> [  Instructor : Humberto Sandmann] </p> <p> [  Student Assistant : Gi\u00falia Gomes Vallente] </p>"},{"location":"versions/2025.2/#students","title":"Students","text":"<p>Template</p> <p>Template to deliver the project: https://hsandmann.github.io/documentation.template/.</p> <ul> <li> <p>Individual</p> <p>Deadline to register: September 24, 2025.</p> <p> Individual registration.</p> <p>Form to register individual students: https://forms.gle/mG6riaBW99vHxRpc7.</p> </li> <li> <p>Group</p> <p>Deadline to register: September 24, 2025.</p> <p> Teams from 2 up to 3 members.</p> <p>Form to register student groups: https://forms.gle/B2QuGVsacetXfkeg7.</p> <p>This is MANDATORY to organize the teams and the AWS accounts.</p> </li> </ul>"},{"location":"versions/2025.2/#meetings","title":"Meetings","text":"Aula Qua. 12h00  14h00 Atendimento Sex. 09h40  11h10 Aula Sex. 12h00  14h00"},{"location":"versions/2025.2/#grade","title":"Grade","text":"2026-02-27T17:23:48.934380 image/svg+xml Matplotlib v3.10.8, https://matplotlib.org/  Final Individual Team \\[ \\text{Final Grade} = \\left\\{\\begin{array}{lll}     \\text{Individual} \\geq 5 \\bigwedge \\text{Team} \\geq 5 &amp;     \\implies &amp;     \\displaystyle \\frac{ \\text{Individual} + \\text{Team} } {2}     \\\\     \\\\     \\text{Otherwise} &amp;     \\implies &amp;     \\min\\left(\\text{Individual}, \\text{Team}\\right)     \\end{array}\\right. \\] Tarefa Descri\u00e7\u00e3o Peso Checkpoint 1 Product 15% Checkpoint 2 Order 15% Checkpoint 3 Exchange 10% Checkpoint 4 DevOps 15% Checkpoint 5 Orchestration 15% Bootnecks InMemory DatabaseMessage QueuesObservabilityCode qualityOAuth2Payments (sandboxes) 20% Documentation README with MkDocs 10% <p>Entrega</p> <ul> <li>A entrega de um checkpoint implica, OBRIGATORIAMENTE, na entrega do checkpoint anterior;</li> <li>Trabalho em grupo deve ser documentado no GitHub.</li> </ul> Tarefas Descri\u00e7\u00e3o Peso AWS Configurar AWS 5% EKS Disponibilizar a aplica\u00e7\u00e3o 15% Testes Testes de carga 20% CI/CD Jenkins 10% Custos An\u00e1lise de custos 15% PaaS Plano de uso da plataforma 15% Apresenta\u00e7\u00e3o Storytelling e documenta\u00e7\u00e3o 20% <p>Entrega</p> <ul> <li>Trabalho em grupo deve ser documentado no GitHub. Um template est\u00e1 dispon\u00edvel para auxiliar na documenta\u00e7\u00e3o: template de entrega.</li> </ul>"},{"location":"versions/2025.2/#planning","title":"Planning","text":""},{"location":"versions/2025.2/#repositories","title":"Repositories","text":"<p>Principal:  https://github.com/repo-classes/pma.25.2</p> Microservice Interface Implementation Account account account-service Auth auth auth-service Gateway gateway-service"},{"location":"versions/2026.1/","title":"2026.1","text":""},{"location":"versions/2026.1/#meetings","title":"Meetings","text":"Aula Qua. 12h00  14h00 Aula Sex. 12h00  14h00 Atendimento Ter. 12h00  13h30"},{"location":"versions/2026.1/#instructors","title":"Instructors","text":"<p> [  Instructor : Humberto Sandmann] </p> <p> [  Student Assistant : Lucas Abatepietro] </p>"},{"location":"versions/2026.1/#students","title":"Students","text":""},{"location":"versions/2026.1/#grade","title":"Grade","text":"\\[ \\text{Final Grade} = \\left\\{\\begin{array}{lll}     \\text{Individual} \\geq 5 \\bigwedge \\text{Team} \\geq 5 &amp;     \\implies &amp;     \\displaystyle \\frac{ \\text{Individual} + \\text{Team} } {2}     \\\\     \\\\     \\text{Otherwise} &amp;     \\implies &amp;     \\min\\left(\\text{Individual}, \\text{Team}\\right)     \\end{array}\\right. \\] 2026-02-27T17:23:49.099118 image/svg+xml Matplotlib v3.10.8, https://matplotlib.org/ <ol> <li> <p>Quizzes: the course will have 3 quizzes, the quiz with the lowest grade will be dropped. And, the final quiz grade will be the uniform average of the two best grade quizzes:</p> \\[ \\text{Quizzes} = \\frac{\\text{Q1} + \\text{Q2} + \\text{Q3} - \\min(\\text{Q1}, \\text{Q2}, \\text{Q3})}{2} \\] </li> <li> <p>Microservice: the students will have to implement a microservice. The grade is a concept grade, based on <code>Notas da Engenharia</code>:</p> Concept Grade A (+) 9 (10) B (+) 7 (8) C (+) 5 (6) D 4 I 0 </li> <li> <p>Team: the team have to be composed by 2 up to 3 members. The team grade will be the same for all members of the team. The team grade will be based on the project delivery and documentation.</p> <p>Group Registration</p> <p> Deadline to register: March 6th, 2026.</p> <p> Teams from 2 up to 3 members.</p> <p> Create a repository on GitHub to share the project code and documentation.</p> <p> Form to register student groups: https://forms.gle/DoRxGcnx5vb5ggkYA.</p> <p> This is MANDATORY to organize the teams and the AWS accounts.</p> <p>Repository name</p> <p>The repository name should be something profissional, for example: <code>platform</code>, <code>microservices</code>, etc.</p> <p>Also, the repository should linked to GitHub authors.</p> </li> <li> <p>Documentation: the project documentation will be evaluated based on the quality of the documentation and the completeness of the documentation. The documentation should be complete and should cover all the aspects of the project, including the architecture, the design decisions, the implementation details, and the testing strategy. The documentation should be clear and concise, and should be easy to understand. The documentation should be well-structured and should follow the best practices of software documentation. The purpose of the documentation is to provide a portfolio about the subject to potential employers or collaborators.</p> <p>Documentation Requirements</p> <p> Deadline to deliver: May 22th, 2026.</p> <p> The project documentation HAVE TO be hosted on GitHub Pages and should be public;</p> <p> The format to publish the documentation is mkdocs, the documentation should be published in the GitHub Pages;</p> <p> A template based on material is available to assist with the documentation: delivery template.</p> <p>Template</p> <p>A template based on material is available to assist with the documentation: delivery template.</p> <ol> <li>Fork the template repository;</li> <li>Clone the forked repository;</li> <li>Edit the documentation;</li> <li>Push the changes to the forked repository;</li> <li>Publish the documentation on GitHub Pages.</li> </ol> <p>There is instructions more accurate on Using this template.</p> </li> </ol>"},{"location":"versions/2026.1/#planning","title":"Planning","text":""},{"location":"versions/2026.1/#repositories","title":"Repositories","text":"<p>Principal:  https://github.com/repo-classes/pma.261</p> Microservice Interface Implementation Account account account-service Auth auth auth-service Gateway gateway-service"},{"location":"versions/2026.1/planning/","title":"Planning","text":"<p>The marjority web systems have to be design and implemented to be scalable, reliable and secure. In this course, students will learn how to design and implement web applications using microservices architecture, containerization, and cloud computing. The course will cover topics such as design patterns, monitoring and traceability of applications, security (authentication and authorization), messaging, distributed data, orchestration of cloud computing, management systems, monitoring and configuration of virtualized resources, integration between development and operation (DevOps), utilization of cloud platforms for production (Cloud Computing), automation aspects of system management in cloud \u2013 DevOps, serverless computing \u2013 FaaS - function as a service, utilization of Platform as a Service for business: Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS), service level agreement (SLA) management and costs of project and operation of systems in cloud.</p> <p>The course will be delivered in a project-based learning format, where students will work in teams to design and implement a web application using microservices architecture and cloud computing. The course will also include lectures, hands-on labs, and guest speakers from the industry.</p> <p>The route to deliver a robust and scalable web application using microservices architecture and cloud computing will be as follows:</p> <ol> <li>Introduction to microservices architecture and design patterns;</li> <li>Building microservices with RESTful APIs;</li> <li>Containerization with Docker;</li> <li>Security considerations for microservices architecture;</li> <li>Orchestration with Kubernetes;</li> <li>Cloud computing with AWS;</li> <li>DevOps practices for continuous integration and continuous deployment (CI/CD);</li> <li>Monitoring and traceability of applications;</li> <li>Messaging and distributed data management;</li> <li>Service level agreement (SLA) management and cost analysis for cloud computing.</li> </ol>"},{"location":"versions/2026.1/planning/#multilayer-architecture","title":"Multilayer Architecture","text":"<p>At the initial of internet era, the most common architecture for web applications ran on a single server, where all components of the application were tightly coupled and deployed as a single unit. This architecture is known as monolithic architecture. However, as applications grew in complexity and scale, this architecture became difficult to maintain and scale.</p> <pre><code>graph TD\n    A[Monolithic Architecture] --&gt; B[Presentation Layer]\n    A --&gt; C[Business Logic Layer]\n    A --&gt; D[Data Access Layer]</code></pre> <p>To address these challenges, the multilayer architecture was introduced, which separates the application into different layers, such as presentation, business logic, and data access layers. This architecture allows for better separation of concerns and makes it easier to maintain and scale the application.</p> <p>the monolithic architecture, where all components of the application were tightly coupled and deployed as a single unit. However, as applications grew in complexity and scale, this architecture became difficult to maintain and scale. To address these challenges, the multilayer architecture was introduced, which separates the application into different layers, such as presentation, business logic, and data access layers. This architecture allows for better separation of concerns and makes it easier to maintain and scale the application.</p> <p>## E-commerce Application</p> <p>In this course, students will work on a project to design and implement an e-commerce application using microservices architecture and cloud computing. The application will consist of several microservices, such as product catalog, order management, payment processing, and user authentication. Each microservice will be developed and deployed independently, allowing for better scalability and maintainability. The application will also utilize cloud computing services, such as AWS, for hosting and managing the application.</p> <p>Product Catalog Service: This microservice will be responsible for managing the product catalog, including adding, updating, and deleting products. It will also provide APIs for retrieving product information.</p> <p>Order Management Service: This microservice will handle the order management functionality, including creating and managing orders, processing payments, and handling returns.</p> <p>Customer Service: This microservice will manage customer information, including registration, authentication, and profile management.</p> <p>Exchange Service: This microservice will handle the exchange of products' prices, including currency conversion and price updates.</p> <p>Payment Processing Service: This microservice will handle payment processing, including integrating with payment gateways and managing payment transactions.</p> <p>Infrastructure:</p> <p>Virtual Infrastructure: This includes the virtual servers, storage devices, and networking equipment that are used to host the application. Docker Compose Rede e Sub-redes IPs e Portas Seguran\u00e7a e Firewall</p> <p>Software Architecture: This includes the design and implementation of the microservices, including the use of design patterns, security considerations, and messaging. Maven - package management Design Patterns - Singleton, Factory, Observer, etc. Security - Authentication and Authorization JWT - JSON Web Tokens Messaging - RabbitMQ, Kafka</p> <p>CAP Theorem Vertical e Horizontal Scaling Load Balancing Auto Scaling Observability DevOps e CI/CD Orquestra\u00e7\u00e3o de Cont\u00eaineres Kubernetes AWS Elastic Kubernetes Service (EKS) AWS Elastic Container Service (ECS) AWS Lambda AWS CloudFormation</p>"}]}